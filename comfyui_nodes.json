  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:12 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:13 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:14 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:15 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:16 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:17 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:18 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:19 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:20 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:21 --:--:--     0
  0     0    0     0    0     0      0      0 --:--:--  0:00:22 --:--:--     0
100  967k  100  967k    0     0  43713      0  0:00:22  0:00:22 --:--:--  225k
{"KSampler": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model used for denoising the input latent."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000, "tooltip": "The number of steps used in the denoising process."}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01, "tooltip": "The Classifier-Free Guidance scale balances creativity and adherence to the prompt. Higher values result in images more closely matching the prompt however too high values will negatively impact quality."}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"], {"tooltip": "The algorithm used when sampling, this can affect the quality, speed, and style of the generated output."}], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"], {"tooltip": "The scheduler controls how noise is gradually removed to form the image."}], "positive": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to include in the image."}], "negative": ["CONDITIONING", {"tooltip": "The conditioning describing the attributes you want to exclude from the image."}], "latent_image": ["LATENT", {"tooltip": "The latent image to denoise."}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The amount of denoising applied, lower values will maintain the structure of the initial image allowing for image to image sampling."}]}}, "input_order": {"required": ["model", "seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "denoise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSampler", "display_name": "KSampler", "description": "Uses the provided model, positive and negative conditioning to denoise the latent image.", "python_module": "nodes", "category": "sampling", "output_node": false, "output_tooltips": ["The denoised latent."]}, "CheckpointLoaderSimple": {"input": {"required": {"ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"], {"tooltip": "The name of the checkpoint (model) to load."}]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderSimple", "display_name": "Load Checkpoint", "description": "Loads a diffusion model checkpoint, diffusion models are used to denoise latents.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The model used for denoising latents.", "The CLIP model used for encoding text prompts.", "The VAE model used for encoding and decoding images to and from latent space."]}, "CLIPTextEncode": {"input": {"required": {"text": ["STRING", {"multiline": true, "dynamicPrompts": true, "tooltip": "The text to be encoded."}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}}, "input_order": {"required": ["text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "CLIPTextEncode", "display_name": "CLIP Text Encode (Prompt)", "description": "Encodes a text prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.", "python_module": "nodes", "category": "conditioning", "output_node": false, "output_tooltips": ["A conditioning containing the embedded text used to guide the diffusion model."]}, "CLIPSetLastLayer": {"input": {"required": {"clip": ["CLIP"], "stop_at_clip_layer": ["INT", {"default": -1, "min": -24, "max": -1, "step": 1}]}}, "input_order": {"required": ["clip", "stop_at_clip_layer"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPSetLastLayer", "display_name": "CLIP Set Last Layer", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "VAEDecode": {"input": {"required": {"samples": ["LATENT", {"tooltip": "The latent to be decoded."}], "vae": ["VAE", {"tooltip": "The VAE model used for decoding the latent."}]}}, "input_order": {"required": ["samples", "vae"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VAEDecode", "display_name": "VAE Decode", "description": "Decodes latent images back into pixel space images.", "python_module": "nodes", "category": "latent", "output_node": false, "output_tooltips": ["The decoded image."]}, "VAEEncode": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"]}}, "input_order": {"required": ["pixels", "vae"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncode", "display_name": "VAE Encode", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "VAEEncodeForInpaint": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "mask": ["MASK"], "grow_mask_by": ["INT", {"default": 6, "min": 0, "max": 64, "step": 1}]}}, "input_order": {"required": ["pixels", "vae", "mask", "grow_mask_by"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeForInpaint", "display_name": "VAE Encode (for Inpainting)", "description": "", "python_module": "nodes", "category": "latent/inpaint", "output_node": false}, "VAELoader": {"input": {"required": {"vae_name": [["vae-ft-mse-840000-ema-pruned.safetensors", "pixel_space"]]}}, "input_order": {"required": ["vae_name"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["VAE"], "name": "VAELoader", "display_name": "Load VAE", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "EmptyLatentImage": {"input": {"required": {"width": ["INT", {"default": 512, "min": 16, "max": 16384, "step": 8, "tooltip": "The width of the latent images in pixels."}], "height": ["INT", {"default": 512, "min": 16, "max": 16384, "step": 8, "tooltip": "The height of the latent images in pixels."}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentImage", "display_name": "Empty Latent Image", "description": "Create a new batch of empty latent images to be denoised via sampling.", "python_module": "nodes", "category": "latent", "output_node": false, "output_tooltips": ["The empty latent image batch."]}, "LatentUpscale": {"input": {"required": {"samples": ["LATENT"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 8}], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["samples", "upscale_method", "width", "height", "crop"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentUpscale", "display_name": "Upscale Latent", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentUpscaleBy": {"input": {"required": {"samples": ["LATENT"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "scale_by": ["FLOAT", {"default": 1.5, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "upscale_method", "scale_by"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentUpscaleBy", "display_name": "Upscale Latent By", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentFromBatch": {"input": {"required": {"samples": ["LATENT"], "batch_index": ["INT", {"default": 0, "min": 0, "max": 63}], "length": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["samples", "batch_index", "length"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentFromBatch", "display_name": "Latent From Batch", "description": "", "python_module": "nodes", "category": "latent/batch", "output_node": false}, "RepeatLatentBatch": {"input": {"required": {"samples": ["LATENT"], "amount": ["INT", {"default": 1, "min": 1, "max": 64}]}}, "input_order": {"required": ["samples", "amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "RepeatLatentBatch", "display_name": "Repeat Latent Batch", "description": "", "python_module": "nodes", "category": "latent/batch", "output_node": false}, "SaveImage": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to save."}], "filename_prefix": ["STRING", {"default": "ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImage", "display_name": "Save Image", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "nodes", "category": "image", "output_node": true}, "PreviewImage": {"input": {"required": {"images": ["IMAGE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewImage", "display_name": "Preview Image", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "nodes", "category": "image", "output_node": true}, "LoadImage": {"input": {"required": {"image": [["1761597930315.jpg", "1761597930346.jpg", "1761597930367.jpg", "1761597930396.jpg", "1761597930425.jpg", "1761597930453.jpg", "1761597930480.jpg", "1761597930508.jpg", "1761597930536.jpg", "1761597930561.jpg", "1761597930675.png", "1761597930784.png", "1761597930893.png", "1761597931005.png", "1761597931165.png", "1761597931254.png", "1761597931291.jpg", "1761597931314.jpg", "1761597931353.jpg", "1761597931384.jpg", "1761597931486.png", "1761597931583.png", "1761597931678.png", "1761597931766.png", "1761597931903.png", "1761597932001.png", "1761597952317.jpg", "1761597952336.jpg", "1761597952353.jpg", "1761597952370.jpg", "1761597952387.jpg", "1761597952405.jpg", "1761597952422.jpg", "1761597952441.jpg", "1761597952457.jpg", "1761597952474.jpg", "1761597952611.png", "1761597952709.png", "1761597952805.png", "1761597952905.png", "1761597953027.png", "1761597953119.png", "1761597953153.jpg", "1761597953170.jpg", "1761597953193.jpg", "1761597953220.jpg", "1761597953316.png", "1761597953410.png", "1761597953505.png", "1761597953578.png", "1761597953674.png", "1761597953772.png", "1761598611514.jpg", "1761598611634.jpg", "1761598611658.jpg", "1761598611766.jpg", "1761598611853.jpg", "1761598611881.jpg", "1761598611901.jpg", "1761598611929.jpg", "1761598611949.jpg", "1761598611979.jpg", "1761598612099.png", "1761598612214.png", "1761598612317.png", "1761598612425.png", "1761598612555.png", "1761598612656.png", "1761598612706.jpg", "1761598612731.jpg", "1761598612760.jpg", "1761598612867.jpg", "1761598612966.png", "1761598613063.png", "1761598613160.png", "1761598613237.png", "1761598613354.png", "1761598613473.png", "1761676691867.png", "1761676935253.png", "1761676949497.png", "1761677110108.png", "1761677126210.png", "1761677171515.png", "1761677185583.png", "1761677396874.png", "1761677410966.png", "1761677452180.png", "1761677466228.png", "1761677482001.png", "1761677496095.png", "1761677510725.png", "1761677526772.png", "1761677540848.png", "1761677555235.png", "1761677569789.png", "1761677585850.png", "1761677599221.png", "1761677615293.png", "1761677628675.png", "1761677644440.png", "1761677659116.png", "1761677675185.png", "1761677690204.png", "1761677705324.png", "1761677719127.png", "1761677735167.png", "1761677749222.png", "1761677763904.png", "1761677779059.png", "1761677794026.png", "1761677809813.png", "1761677824261.png", "1761677839945.png", "1761677854640.png", "1761677867936.png", "1761677882801.png", "1761677898717.png", "1761677912999.png", "1761677928514.png", "1761677943317.png", "1761677958573.png", "1761677974048.png", "1761677988119.png", "1761678004194.png", "1761678019147.png", "1761678032330.png", "1761678047269.png", "1761678062739.png", "1761678078809.png", "1761681696042.png", "1761681714148.png", "1761681730192.png", "1761681746312.png", "1761681762855.png", "1761681780944.png", "1761681798349.png", "1761681814220.png", "1761681832262.png", "1761681847865.png", "1761681865288.png", "1761682297504.png", "1761682315554.png", "1761683677514.png", "1761683695605.png", "1761684439441.png", "1761684457513.png", "1761684472593.png", "1761684489675.png", "1762252054938.png", "1762252062974.png", "1762252073014.png", "1762252083057.png", "1762252091739.png", "1762252100680.png", "1762252109837.png", "1762252116750.png", "1762252127759.png", "1762252135781.png", "1762252146328.png", "1762252155360.png", "1762252164410.png", "1762252175335.png", "1762252182313.png", "1762252192352.png", "1762252200925.png", "1762252209838.png", "1762252219000.png", "1762252227932.png", "1762252237026.png", "1762252246926.png", "1762252255475.png", "1762252266512.png", "1762252275620.png", "1762252284571.png", "1762252293678.png", "1762252303514.png", "1762252312108.png", "1762252321098.png", "1762252330196.png", "1762252341185.png", "1762252348095.png", "1762252358094.png", "1762252366668.png", "1762252377723.png", "1762252386756.png", "1762252395805.png", "1762252404662.png", "1762252414723.png", "1762252423310.png", "1762252432425.png", "1762252441384.png", "1762252452432.png", "1762252461224.png", "1762252471262.png", "1762252480147.png", "1762252488973.png", "1762252499987.png", "1762252509010.png", "1762252517832.png", "1762252527886.png", "1762252536787.png", "1762252545639.png", "1762252556666.png", "1762252565622.png", "1762252574764.png", "1762252584632.png", "1762252593431.png", "1762252604294.png", "1762252613310.png", "1762252622305.png", "1762252633347.png", "1762252641250.png", "1762252652096.png", "1762252660906.png", "1762252669956.png", "1762252680945.png", "1762252687918.png", "1762252697961.png", "1762252708764.png", "1762252717686.png", "1762252726623.png", "1762252737811.png", "1762252746711.png", "1762252756767.png", "1762252765483.png", "1762252776386.png", "1762252785409.png", "1762252794509.png", "1762252802970.png", "1762252813462.png", "1762252822136.png", "1762252833115.png", "1762252842076.png", "1762292337386.png", "1762292351653.png", "1762293739548.png", "1762293753617.png", "1762293852196.png", "1762293860316.png", "1762293870354.png", "1762293878376.png", "1762293887081.png", "1762293896008.png", "1762293904456.png", "1762293912552.png", "1762293922586.png", "1762293930615.png", "1762293939536.png", "1762293948313.png", "1762293956698.png", "1762293964789.png", "1762293974836.png", "1762293982849.png", "1762293991799.png", "1762294000563.png", "1762294009079.png", "1762294019765.png", "1762294027791.png", "1762294037192.png", "1762294046054.png", "1762294054883.png", "1762294063320.png", "1762294071975.png", "1762294080028.png", "1762294089432.png", "1762294098355.png", "1762294107109.png", "1762294115550.png", "1762294124193.png", "1762294132251.png", "1762294141673.png", "1762294162652.png", "1762294177430.png", "1762294189923.png", "1762294200576.png", "1762294210586.png", "1762294218059.png", "1762294226935.png", "1762294235703.png", "1762294244164.png", "1762294252975.png", "1762294262840.png", "1762294270413.png", "1762294281208.png", "1762294289940.png", "1762294298564.png", "1762294307257.png", "1762294317129.png", "1762294324712.png", "1762294333504.png", "1762294342185.png", "1762294350856.png", "1762294359529.png", "1762294369519.png", "1762294378994.png", "1762294387747.png", "1762294396431.png", "1762294405122.png", "1762294413763.png", "1762294422102.png", "1762294431224.png", "1762294439952.png", "1762294448644.png", "1762294457366.png", "1762294466071.png", "1762294476501.png", "1762294483473.png", "1762294494187.png", "1762294502923.png", "1762294511629.png", "1762294520323.png", "1762294528798.png", "1762294537724.png", "1762294546445.png", "1762294555184.png", "1762294565891.png", "1762294574585.png", "1762294583070.png", "1762294592000.png", "1762294600729.png", "1762294609433.png", "1762294618146.png", "1762294626854.png", "1762294635303.png", "1762294644258.png", "1762294653196.png", "1762294661675.png", "1762294670387.png", "1762294679125.png", "1762294689607.png", "1762294698501.png", "1762294707448.png", "1762294715906.png", "1762294724625.png", "1762294733369.png", "1762294741849.png", "1762294750766.png", "1762294759716.png", "1762294768179.png", "1762294776846.png", "1762294785648.png", "1762294794094.png", "1762294802978.png", "1762294811936.png", "1762294822426.png", "1762294831105.png", "1762294839955.png", "1762294848358.png", "1762294857215.png", "1762294866282.png", "1762294874652.png", "1762294883337.png", "1762294892311.png", "1762294902613.png", "1762294911428.png", "1762294920518.png", "1762294928901.png", "1762294937546.png", "1762294946533.png", "1762294954840.png", "1762294963668.png", "1762294972736.png", "1762294981193.png", "1762294991810.png", "1762295000752.png", "1762295009247.png", "1762295017930.png", "1762295027001.png", "1762295035442.png", "1762295044072.png", "1762295053057.png", "1762295061548.png", "1762295070243.png", "1762295079237.png", "1762295087702.png", "1762295098348.png", "1762295105374.png", "1762295115841.png", "1762295124543.png", "1762295133520.png", "1762295141962.png", "1762295150639.png", "1762295159664.png", "1762295168115.png", "1762295176761.png", "1762295185818.png", "1762295194494.png", "1762295204882.png", "1762295213940.png", "1762295222667.png", "1762295231001.png", "1762295240088.png", "1762295248833.png", "1762295257142.png", "1762295266230.png", "1762295274911.png", "1762295283380.png", "1762436455476.png", "1762436464899.png", "1762436483643.png", "1762436491053.png", "1762436500112.png", "1762436509151.png", "1762436519294.png", "1762436527140.png", "1762436536019.png", "1762436545301.png", "1762436554310.png", "1762436563381.png", "1762436573554.png", "1762436581377.png", "1762436590384.png", "1762436599517.png", "1762436608695.png", "1762436617588.png", "1762436627811.png", "1762436635625.png", "1762436644741.png", "1762436654529.png", "1762436663278.png", "1762436671887.png", "1762436680129.png", "1762436690024.png", "1762436698979.png", "1762436708742.png", "1762436717580.png", "1762436726202.png", "1762436734441.png", "1762436744342.png", "1762436753236.png", "1762436762979.png", "1762436771833.png", "1762436780515.png", "1762436788687.png", "1762436798590.png", "1762436807474.png", "1762436815237.png", "1762436824078.png", "1762436832740.png", "1762436843054.png", "1762436850832.png", "1762436860038.png", "1762436869519.png", "1762436878359.png", "1762436886983.png", "1762436897308.png", "1762436905082.png", "1762436914300.png", "1762436923768.png", "1762436932676.png", "1762436941271.png", "1762436949582.png", "1762436959305.png", "1762436968538.png", "1762436976009.png", "1762436986920.png", "1762436995508.png", "1762437058091.png", "1762437068131.png", "1762437076184.png", "1762437084282.png", "1762437094343.png", "1762437102396.png", "1762437244770.png", "1762437258354.png", "1762437267092.png", "1762437275115.png", "1762437284559.png", "1762437293289.png", "1762437302843.png", "1762437311379.png", "1762437320864.png", "1762437328863.png", "1762437338364.png", "1762443945640.png", "1762443991484.png", "1762444001527.png", "1762444012775.png", "1762444022318.png", "1762444033230.png", "1762444044255.png", "1762444055074.png", "1762444067156.png", "1762444078404.png", "1762444090301.png", "1762444101232.png", "1762444111991.png", "1762444122777.png", "1762444134802.png", "1762444146160.png", "1762444157626.png", "1762444168336.png", "1762444179462.png", "1762444190237.png", "1762444200240.png", "1762444211588.png", "1762444223473.png", "1762444231506.png", "1762444242477.png", "1762444253704.png", "1762444265772.png", "1762444277238.png", "1762444289270.png", "1762444301320.png", "1762444312568.png", "1762444323575.png", "1762444335603.png", "1762444346900.png", "1762444358954.png", "1762444371003.png", "1762444382012.png", "1762444393098.png", "1762444405007.png", "1762444416472.png", "1762444428507.png", "1762444440579.png", "1762444451955.png", "1762444462980.png", "1762444474999.png", "1762444486430.png", "1762444498522.png", "1762444510569.png", "1762444522231.png", "1762444533303.png", "1762444544421.png", "1762444556481.png", "1762444568538.png", "1762444577719.png", "1762444589792.png", "1762444600723.png", "1762444611840.png", "1762444623907.png", "1762444635668.png", "1762444647052.png", "1762444659094.png", "1762444667124.png", "1762444679193.png", "1762444691224.png", "1762444703051.png", "1762444712568.png", "1762444726720.png", "1762444738739.png", "1762444750817.png", "1762444762851.png", "1762444772899.png", "1762444784960.png", "1762444796420.png", "1762444808468.png", "1762444820524.png", "1762444832567.png", "1762444844598.png", "1762444856072.png", "1762444867745.png", "1762444879789.png", "1762444891818.png", "1762444903884.png", "1762444915809.png", "1762444927597.png", "1762444939147.png", "1762444951230.png", "1762444961268.png", "1762444973333.png", "1762444985172.png", "1762444996796.png", "1762445008487.png", "1762445020494.png", "1762445032514.png", "1762445042605.png", "1762445054685.png", "1762445066228.png", "1762445078242.png", "1762445090273.png", "1762445102305.png", "1762445114344.png", "1762445126398.png", "1762445138036.png", "1762445149643.png", "1762445161687.png", "1762445173727.png", "1762445185772.png", "1762445195937.png", "1762445207427.png", "1762445219349.png", "1762445231400.png", "1762445243451.png", "1762445255477.png", "1762445267528.png", "1762445279319.png", "1762445290953.png", "1762445303016.png", "1762445315040.png", "1762445327022.png", "1762445339095.png", "1762445350868.png", "1762445362838.png", "1762445374892.png", "1762445386910.png", "1762445398625.png", "1762445410341.png", "1762445422375.png", "1762445434443.png", "1762445446483.png", "1762445456457.png", "1762445468516.png", "1762445480246.png", "1762445492286.png", "1762445504369.png", "1762445516093.png", "1762445528145.png", "1762445540003.png", "1762445551892.png", "1762445563934.png", "1762445575985.png", "1762445587712.png", "1762445599773.png", "1762445611544.png", "1762445623279.png", "1762445635353.png", "1762445646567.png", "1762445658092.png", "1762445670136.png", "1762445682196.png", "1762445693797.png", "1762445705851.png", "1762445717234.png", "1762445729979.png", "1762445741732.png", "1762445753626.png", "1762445765458.png", "1762445777532.png", "1762445787565.png", "1762445799555.png", "1762445811616.png", "1762445823657.png", "1762445835095.png", "1762445845044.png", "1762445856997.png", "1762445869064.png", "1762445881120.png", "1762445893174.png", "1762445904710.png", "1762445916752.png", "1762445927248.png", "1762445939288.png", "1762445951353.png", "1762445963390.png", "1762445974545.png", "1762445986609.png", "1762445998648.png", "1762446010676.png", "1762446022723.png", "1762446034756.png", "1762446046500.png", "1762446056533.png", "1762446068688.png", "1762446082432.png", "1762446094489.png", "1762446106544.png", "1762446118605.png", "1762446130641.png", "1762446142711.png", "1762446154441.png", "1762446166493.png", "1762446180653.png", "1762446192744.png", "1762446204801.png", "1762446216827.png", "1762446228865.png", "1762446240887.png", "1762446252501.png", "1762446264566.png", "1762446276601.png", "1762446288509.png", "1762446300481.png", "1762446312417.png", "1762446324014.png", "1762446336027.png", "1762446348060.png", "1762446360077.png", "1762446372139.png", "1762446384196.png", "1762446396072.png", "1762446408122.png", "1762446420161.png", "1762446432083.png", "1762446444154.png", "1762446456203.png", "1762446468247.png", "1762446480303.png", "1762446492185.png", "1762446504251.png", "1762446516285.png", "1762446528430.png", "1762446540490.png", "1762446552421.png", "1762446564485.png", "1762446576524.png", "1762446588654.png", "1762446602822.png", "1762446614856.png", "1762446626939.png", "1762446638992.png", "1762446651018.png", "1762446663084.png", "1762446677146.png", "1762446689226.png", "1762446701260.png", "1762446713325.png", "1762446725371.png", "1762446737439.png", "1762446749691.png", "1762446761742.png", "1762446773806.png", "1762446785856.png", "1762446797905.png", "1762446811984.png", "1762446824027.png", "1762446836100.png", "1762446850111.png", "1762446862148.png", "1762446874224.png", "1762446886257.png", "1762446898316.png", "1762446912352.png", "1762446924293.png", "1762446934437.png", "1762446946573.png", "1762446960903.png", "1762446972953.png", "1762446985023.png", "1762446997094.png", "1762447009167.png", "1762447021237.png", "1762447033293.png", "1762447045358.png", "1762447057385.png", "1762447069441.png", "1762447081318.png", "1762447093372.png", "1762447105447.png", "1762447117501.png", "1762447129539.png", "1762447141579.png", "1762447153625.png", "1762447165668.png", "1762447177730.png", "1762447190190.png", "1762447202238.png", "1762447214296.png", "1762447224338.png", "1762447234390.png", "1762447246438.png", "1762447260768.png", "1762447272819.png", "1762447284873.png", "1762447296921.png", "1762447310984.png", "1762447323052.png", "1762447335004.png", "1762447347135.png", "1762447359259.png", "1762447373681.png", "1762447385739.png", "1762447397795.png", "1762447410023.png", "1762447422092.png", "1762447436126.png", "1762447448164.png", "1762447460488.png", "1762447474560.png", "1762447486600.png", "1762447498674.png", "1762447510730.png", "1762447522845.png", "1762447536721.png", "1762447548704.png", "1762447560743.png", "1762447572759.png", "1762447584840.png", "1762447599421.png", "1762447611500.png", "1762447623548.png", "1762447635585.png", "1762447647700.png", "1762447662174.png", "1762447674218.png", "1762447686266.png", "1762447698329.png", "1762447712769.png", "1762447724830.png", "1762447736870.png", "1762447748939.png", "1762447761254.png", "1762447775299.png", "1762447787353.png", "1762447799414.png", "1762447811463.png", "1762447825582.png", "1762447837602.png", "1762447849680.png", "1762447863769.png", "1762447875808.png", "1762447887849.png", "1762447902544.png", "1762447914587.png", "1762447922625.png", "1762447934693.png", "1762447946740.png", "1762447958827.png", "1762447970728.png", "1762447985086.png", "1762447997145.png", "1762448007197.png", "1762448019252.png", "1762448031312.png", "1762448043361.png", "1762448054794.png", "1762448066857.png", "1762448079534.png", "1762448094104.png", "1762448106184.png", "1762448118775.png", "1762448132968.png", "1762448145013.png", "1762448157101.png", "1762448171557.png", "1762448181578.png", "1762448193637.png", "1762448207953.png", "1762448220277.png", "1762448232358.png", "1762448246532.png", "1762448258815.png", "1762448271328.png", "1762448285399.png", "1762448297452.png", "1762448309507.png", "1762448323674.png", "1762448335719.png", "1762448348337.png", "1762448362960.png", "1762448375020.png", "1762448387080.png", "1762448399127.png", "1762448411149.png", "1762448423253.png", "1762448435298.png", "1762448449826.png", "1762448461888.png", "1762448476147.png", "1762448488443.png", "1762448501080.png", "1762448515563.png", "1762448527635.png", "1762448542448.png", "1762448554519.png", "1762448566626.png", "1762448579254.png", "1762448593704.png", "1762448605726.png", "1762448617783.png", "1762448629817.png", "1762448644080.png", "1762448654365.png", "1762448666442.png", "1762448680874.png", "1762448692903.png", "1762448704939.png", "1762448717342.png", "1762448731394.png", "1762448743609.png", "1762448755784.png", "1762448768434.png", "1762448780470.png", "1762448794706.png", "1762448806721.png", "1762448819268.png", "1762448833544.png", "1762448845604.png", "1762448858132.png", "1762448870261.png", "1762448884511.png", "1762448896585.png", "1762448908615.png", "1762448920681.png", "1762448935027.png", "1762448947100.png", "1762448959450.png", "1762448971516.png", "1762448983595.png", "1762448995752.png", "1762449010384.png", "1762449022447.png", "1762449034488.png", "1762449046542.png", "1762449061270.png", "1762449073313.png", "1762449085371.png", "1762449097661.png", "1762449110090.png", "1762449124407.png", "1762449136453.png", "1762449148479.png", "1762449160548.png", "1762449172723.png", "1762449184780.png", "1762449199252.png", "1762449211903.png", "1762449226066.png", "1762449238106.png", "1762449251020.png", "1762449263162.png", "1762449275501.png", "1762449289822.png", "1762449302022.png", "1762449316205.png", "1762449326253.png", "1762449340921.png", "1762449352966.png", "1762449365029.png", "1762449377058.png", "1762449391449.png", "1762449403759.png", "1762449417844.png", "1762449429897.png", "1762449441963.png", "1762449456012.png", "1762449466052.png", "1762449478118.png", "1762449493203.png", "1762449505249.png", "1762449517313.png", "1762449530331.png", "1762449542616.png", "1762449556846.png", "1762449568908.png", "1762449580960.png", "1762449593022.png", "1762449605105.png", "1762449617279.png", "1762449629356.png", "1762449644197.png", "1762449654345.png", "1762449669040.png", "1762449681700.png", "1762449694103.png", "1762449708293.png", "1762449720334.png", "1762449732450.png", "1762449746552.png", "1762449758564.png", "1762449770623.png", "1762449784702.png", "1762449796740.png", "1762449808989.png", "1762449823893.png", "1762449835911.png", "1762449847996.png", "1762449860056.png", "1762449874705.png", "1762449886738.png", "1762449898819.png", "1762449911404.png", "1762449923453.png", "1762449935514.png", "1762449949559.png", "1762449962245.png", "1762449976876.png", "1762449989147.png", "1762450001198.png", "1762450013258.png", "1762450025297.png", "1762450037492.png", "1762450051583.png", "1762450063921.png", "1762450078012.png", "1762450090896.png", "1762450105350.png", "1762450117415.png", "1762450127518.png", "1762450139566.png", "1762450151640.png", "1762450163685.png", "1762450175727.png", "1762450190180.png", "1762450202375.png", "1762450214523.png", "1762450228862.png", "1762450241665.png", "1762450255965.png", "1762450268420.png", "1762450281387.png", "1762450295922.png", "1762450308119.png", "1762450321155.png", "1762450335885.png", "1762450348323.png", "1762450363555.png", "1762450375705.png", "1762450388422.png", "1762450403222.png", "1762450415590.png", "1762450427949.png", "1762450443680.png", "1762450456188.png", "1762450468807.png", "1762450483585.png", "1762450495778.png", "1762450509070.png", "1762450521131.png", "1762450535537.png", "1762450547804.png", "1762450560442.png", "1762450575581.png", "1762450587884.png", "1762450602747.png", "1762450615117.png", "1762450627533.png", "1762450642660.png", "1762450654874.png", "1762450669235.png", "1762450681744.png", "1762450696245.png", "1762450709028.png", "1762450724232.png", "1762450736547.png", "1762450749613.png", "1762450762302.png", "1762450776705.png", "1762450789239.png", "1762450802092.png", "1762450814534.png", "1762450829244.png", "1762450842322.png", "1762450857036.png", "1762450869657.png", "1762450882400.png", "1762450896801.png", "1762450908874.png", "1762450922100.png", "1762450937018.png", "1762450949135.png", "1762450964295.png", "1762450976503.png", "1762450989266.png", "1762451003956.png", "1762451011982.png", "1762451024513.png", "1762451038861.png", "1762451051495.png", "1762451066452.png", "1762451079618.png", "1762451094596.png", "1762451106761.png", "1762451119563.png", "1762451134387.png", "1762451146913.png", "1762451159752.png", "1762451174731.png", "1762451187057.png", "1762451200134.png", "1762451215315.png", "1762451227950.png", "1762451243171.png", "1762451255495.png", "1762451269682.png", "1762451281989.png", "1762451294479.png", "1762451307191.png", "1762451322609.png", "1762451334907.png", "1762451347116.png", "1762451360247.png", "1762451375372.png", "1762451387535.png", "1762451401306.png", "1762451415933.png", "1762451428384.png", "1762451441586.png", "1762451456406.png", "1762451468705.png", "1762451484000.png", "1762451496523.png", "1762451509213.png", "1762451524619.png", "1762451537016.png", "1762451549927.png", "1762451564750.png", "1762451577448.png", "1762451590418.png", "1762451603584.png", "1762451618058.png", "1762451631054.png", "1762451644021.png", "1762451658917.png", "1762451671901.png", "1762451685988.png", "1762451700802.png", "1762451713996.png", "1762451726331.png", "1762451738692.png", "1762451754495.png", "1762451766924.png", "1762451779911.png", "1762451792978.png", "1762451807794.png", "1762451820742.png", "1762451833548.png", "1762451846418.png", "1762451861477.png", "1762451874441.png", "1762451887208.png", "1762451902521.png", "1762451915288.png", "1762451928054.png", "1762451943762.png", "1762451956197.png", "1762451969338.png", "1762451985146.png", "1762451997708.png", "1762452012063.png", "1762452025367.png", "1762452039633.png", "1762452052314.png", "1762452065062.png", "1762452079313.png", "1762452092481.png", "1762452105643.png", "1762452120510.png", "1762452133685.png", "1762452146174.png", "1762452160863.png", "1762452173119.png", "1762452185538.png", "1762452200515.png", "1762452213926.png", "1762452228688.png", "1762452240748.png", "1762452252902.png", "1762452264962.png", "1762452277046.png", "1762452289383.png", "1762452303756.png", "1762452315872.png", "1762452328032.png", "1762452342796.png", "1762452354853.png", "1762452367152.png", "1762452381585.png", "1762452394222.png", "1762452408497.png", "1762452420860.png", "1762452433235.png", "1762452447303.png", "1762452459607.png", "1762452472029.png", "1762452486232.png", "1762452498289.png", "1762452508347.png", "1762452520558.png", "1762452532591.png", "1762452544920.png", "1762452559649.png", "1762452572141.png", "1762452586411.png", "1762452598473.png", "1762452610556.png", "1762452623280.png", "1762452637753.png", "1762452649936.png", "1762452661994.png", "1762452676081.png", "1762452688534.png", "1762452700972.png", "1762452716226.png", "1762452728393.png", "1762452740891.png", "1762452753685.png", "1762452768484.png", "1762452780922.png", "1762452793887.png", "1762452808228.png", "1762452820843.png", "1762452834018.png", "1762452848287.png", "1762452860834.png", "1762452873698.png", "ref_1761675962550.png", "ref_1761675962556.png", "ref_1761676578515.jpg", "ref_1761676578522.jpg", "ref_1761676918964.jpg", "ref_1761676918971.jpg", "ref_1761677093765.jpg", "ref_1761677093772.jpg", "ref_1761677155187.jpg", "ref_1761677155194.jpg", "ref_1761677380523.jpg", "ref_1761677380531.jpg", "ref_1761677435842.jpg", "ref_1761677435848.jpg", "ref_1761677457580.jpg", "ref_1761677457587.jpg", "ref_1761677466424.jpg", "ref_1761677506365.jpg", "ref_1761677506371.jpg", "ref_1761677510905.jpg", "ref_1761677549374.jpg", "ref_1761677549380.jpg", "ref_1761677560609.jpg", "ref_1761677560616.jpg", "ref_1761677569970.jpg", "ref_1761677586033.jpg", "ref_1761677608576.jpg", "ref_1761677608583.jpg", "ref_1761677615479.jpg", "ref_1761677628861.jpg", "ref_1761677644719.jpg", "ref_1761677674547.jpg", "ref_1761677674552.jpg", "ref_1761677675279.jpg", "ref_1761677690504.jpg", "ref_1761677705333.jpg", "ref_1761677719136.jpg", "ref_1761677735428.jpg", "ref_1761677749234.jpg", "ref_1761677763914.jpg", "ref_1761677779267.jpg", "ref_1761677794037.jpg", "ref_1761677810025.jpg", "ref_1761677824273.jpg", "ref_1761677839952.jpg", "ref_1761677854648.jpg", "ref_1761677867943.jpg", "ref_1761677883017.jpg", "ref_1761677898725.jpg", "ref_1761677913016.jpg", "ref_1761677928541.jpg", "ref_1761677943349.jpg", "ref_1761677958604.jpg", "ref_1761677974061.jpg", "ref_1761677988125.jpg", "ref_1761679807688.jpg", "ref_1761679807694.jpg", "ref_1761679839752.jpg", "ref_1761679839759.jpg", "ref_1761679850806.jpg", "ref_1761679850813.jpg", "ref_1761680549411.jpg", "ref_1761680549418.jpg", "ref_1761680828065.jpg", "ref_1761680828072.jpg", "ref_1761681062317.jpg", "ref_1761681062325.jpg", "ref_1761681506836.jpg", "ref_1761681506842.jpg", "ref_1761681514818.jpg", "ref_1761681534712.jpg", "ref_1761681534718.jpg", "ref_1761681593543.jpg", "ref_1761681679110.jpg", "ref_1761681679116.jpg", "ref_1761681693307.jpg", "ref_1761681693314.jpg", "ref_1761681696262.jpg", "ref_1761681714373.jpg", "ref_1761681747833.jpg", "ref_1761681767320.jpg", "ref_1761681767328.jpg", "ref_1761681781136.jpg", "ref_1761681798562.jpg", "ref_1761682276723.jpg", "ref_1761682276730.jpg", "ref_1761683611429.jpg", "ref_1761683656877.jpg", "ref_1761683656884.jpg", "ref_1761684422074.jpg", "ref_1761684422080.jpg", "ref_1761684425773.jpg", "ref_1761684425967.jpg", "ref_1761684426390.jpg", "ref_1761686305604.png", "ref_1761686845955.png", "ref_1761687073556.png", "ref_1761687106319.png", "ref_1761687650660.png", "ref_1761687775951.png", "ref_1761687877915.png", "ref_1761688081767.jpg", "ref_1761688081774.jpg", "ref_1761688086824.jpg", "ref_1761688087108.jpg", "ref_1761688361982.jpg", "ref_1761739664856.jpg", "ref_1761739664863.jpg", "ref_1761739668703.jpg", "ref_1761739668935.jpg", "ref_1761740201268.jpg", "ref_1761740317312.png", "ref_1761740752041.jpg", "ref_1761740752052.jpg", "ref_1761740756449.jpg", "ref_1761740759168.jpg", "ref_1761741246808.jpg", "ref_1761749379704.png", "ref_1761749379733.png", "ref_1761749909801.png", "ref_1761749909872.png", "ref_1762251976835.jpg", "ref_1762252055113.jpg", "ref_1762252063182.jpg", "ref_1762252073174.jpg", "ref_1762252083194.jpg", "ref_1762252091744.jpg", "ref_1762252100833.jpg", "ref_1762252109842.jpg", "ref_1762252116753.jpg", "ref_1762252135786.jpg", "ref_1762252146332.jpg", "ref_1762252164415.jpg", "ref_1762252175342.jpg", "ref_1762252182439.jpg", "ref_1762252192358.jpg", "ref_1762252200930.jpg", "ref_1762252209843.jpg", "ref_1762252219004.jpg", "ref_1762252227936.jpg", "ref_1762252237029.jpg", "ref_1762252246930.jpg", "ref_1762252255478.jpg", "ref_1762252266518.jpg", "ref_1762252275625.jpg", "ref_1762252284576.jpg", "ref_1762252303518.jpg", "ref_1762252312112.jpg", "ref_1762252321102.jpg", "ref_1762252330199.jpg", "ref_1762252341192.jpg", "ref_1762252358099.jpg", "ref_1762252366671.jpg", "ref_1762252377728.jpg", "ref_1762252386762.jpg", "ref_1762252395809.jpg", "ref_1762252404666.jpg", "ref_1762252414728.jpg", "ref_1762252423315.jpg", "ref_1762252432430.jpg", "ref_1762252441388.jpg", "ref_1762252452436.jpg", "ref_1762252461228.jpg", "ref_1762252471267.jpg", "ref_1762252480152.jpg", "ref_1762252488980.jpg", "ref_1762252499990.jpg", "ref_1762252509016.jpg", "ref_1762252518017.jpg", "ref_1762252527889.jpg", "ref_1762252536791.jpg", "ref_1762252545644.jpg", "ref_1762252556672.jpg", "ref_1762252565629.jpg", "ref_1762252574770.jpg", "ref_1762252584638.jpg", "ref_1762252593435.jpg", "ref_1762252604298.jpg", "ref_1762252613315.jpg", "ref_1762252622309.jpg", "ref_1762252641257.jpg", "ref_1762252652101.jpg", "ref_1762252660913.jpg", "ref_1762252669960.jpg", "ref_1762252680949.jpg", "ref_1762252687922.jpg", "ref_1762252697968.jpg", "ref_1762252708770.jpg", "ref_1762252717692.jpg", "ref_1762252726629.jpg", "ref_1762252737817.jpg", "ref_1762252756773.jpg", "ref_1762252765488.jpg", "ref_1762252776392.jpg", "ref_1762252785415.jpg", "ref_1762252794513.jpg", "ref_1762252802975.jpg", "ref_1762252813468.jpg", "ref_1762252822142.jpg", "ref_1762252833119.jpg", "ref_1762252842079.jpg", "ref_1762438257242.png", "ref_1762438266971.png", "ref_1762438267002.png", "ref_1762439055270.png", "ref_1762443459707.jpg", "ref_1762443459710.jpg", "ref_1762443631443.jpg", "ref_1762443633308.jpg", "ref_1762443703494.jpg", "ref_1762443707834.jpg", "ref_1762443707835.jpg", "ref_1762443707837.jpg", "ref_1762443875578.jpg", "ref_1762443945645.jpg", "ref_1762443951632.jpg", "ref_1762443952508.jpg", "ref_1762443991490.jpg", "ref_1762444001533.jpg", "ref_1762444012781.jpg", "ref_1762444022323.jpg", "ref_1762444033366.jpg", "ref_1762444044259.jpg", "ref_1762444055078.jpg", "ref_1762444067161.jpg", "ref_1762444078409.jpg", "ref_1762444090312.jpg", "ref_1762444101238.jpg", "ref_1762444111996.jpg", "ref_1762444134807.jpg", "ref_1762444146164.jpg", "ref_1762444157629.jpg", "ref_1762444179469.jpg", "ref_1762444190518.jpg", "ref_1762444200244.jpg", "ref_1762444211592.jpg", "ref_1762444223480.jpg", "ref_1762444231512.jpg", "ref_1762444242481.jpg", "ref_1762444253708.jpg", "ref_1762444265776.jpg", "ref_1762444277244.jpg", "ref_1762444289276.jpg", "ref_1762444301324.jpg", "ref_1762444312572.jpg", "ref_1762444323579.jpg", "ref_1762444335608.jpg", "ref_1762444346904.jpg", "ref_1762444358958.jpg", "ref_1762444371008.jpg", "ref_1762444382018.jpg", "ref_1762444393103.jpg", "ref_1762444405012.jpg", "ref_1762444416476.jpg", "ref_1762444428512.jpg", "ref_1762444440585.jpg", "ref_1762444451962.jpg", "ref_1762444462984.jpg", "ref_1762444475003.jpg", "ref_1762444486435.jpg", "ref_1762444498527.jpg", "ref_1762444522237.jpg", "ref_1762444533309.jpg", "ref_1762444544425.jpg", "ref_1762444556485.jpg", "ref_1762444568545.jpg", "ref_1762444577723.jpg", "ref_1762444589797.jpg", "ref_1762444611845.jpg", "ref_1762444623912.jpg", "ref_1762444635673.jpg", "ref_1762444647056.jpg", "ref_1762444659101.jpg", "ref_1762444667129.jpg", "ref_1762444679200.jpg", "ref_1762444691232.jpg", "ref_1762444703059.jpg", "ref_1762444712573.jpg", "ref_1762444726725.jpg", "ref_1762444738745.jpg", "ref_1762444750822.jpg", "ref_1762444762858.jpg", "ref_1762444772903.jpg", "ref_1762444784965.jpg", "ref_1762444796425.jpg", "ref_1762444808474.jpg", "ref_1762444820531.jpg", "ref_1762444832572.jpg", "ref_1762444844604.jpg", "ref_1762444856077.jpg", "ref_1762444867750.jpg", "ref_1762444879796.jpg", "ref_1762444891823.jpg", "ref_1762444903889.jpg", "ref_1762444915814.jpg", "ref_1762444927602.jpg", "ref_1762444939152.jpg", "ref_1762444951236.jpg", "ref_1762444961273.jpg", "ref_1762444973339.jpg", "ref_1762444985177.jpg", "ref_1762444996801.jpg", "ref_1762445008492.jpg", "ref_1762445020498.jpg", "ref_1762445032523.jpg", "ref_1762445042609.jpg", "ref_1762445054691.jpg", "ref_1762445066232.jpg", "ref_1762445078246.jpg", "ref_1762445090278.jpg", "ref_1762445102310.jpg", "ref_1762445114349.jpg", "ref_1762445126404.jpg", "ref_1762445138040.jpg", "ref_1762445149647.jpg", "ref_1762445161916.jpg", "ref_1762445173731.jpg", "ref_1762445185778.jpg", "ref_1762445195942.jpg", "ref_1762445207432.jpg", "ref_1762445219354.jpg", "ref_1762445231405.jpg", "ref_1762445243457.jpg", "ref_1762445255482.jpg", "ref_1762445267533.jpg", "ref_1762445279323.jpg", "ref_1762445290958.jpg", "ref_1762445303021.jpg", "ref_1762445315045.jpg", "ref_1762445327026.jpg", "ref_1762445339100.jpg", "ref_1762445350873.jpg", "ref_1762445362843.jpg", "ref_1762445374897.jpg", "ref_1762445398630.jpg", "ref_1762445410345.jpg", "ref_1762445422380.jpg", "ref_1762445434448.jpg", "ref_1762445446489.jpg", "ref_1762445456463.jpg", "ref_1762445468522.jpg", "ref_1762445480252.jpg", "ref_1762445492292.jpg", "ref_1762445504376.jpg", "ref_1762445516098.jpg", "ref_1762445528151.jpg", "ref_1762445540009.jpg", "ref_1762445551897.jpg", "ref_1762445563939.jpg", "ref_1762445575990.jpg", "ref_1762445587717.jpg", "ref_1762445599778.jpg", "ref_1762445611549.jpg", "ref_1762445623284.jpg", "ref_1762445635360.jpg", "ref_1762445646572.jpg", "ref_1762445658097.jpg", "ref_1762445670141.jpg", "ref_1762445682203.jpg", "ref_1762445693803.jpg", "ref_1762445705858.jpg", "ref_1762445729985.jpg", "ref_1762445741738.jpg", "ref_1762445753631.jpg", "ref_1762445765462.jpg", "ref_1762445777540.jpg", "ref_1762445787570.jpg", "ref_1762445799561.jpg", "ref_1762445811621.jpg", "ref_1762445823663.jpg", "ref_1762445835103.jpg", "ref_1762445845048.jpg", "ref_1762445857003.jpg", "ref_1762445869069.jpg", "ref_1762445881125.jpg", "ref_1762445893179.jpg", "ref_1762445904715.jpg", "ref_1762445916759.jpg", "ref_1762445927253.jpg", "ref_1762445939295.jpg", "ref_1762445951361.jpg", "ref_1762445963398.jpg", "ref_1762445974550.jpg", "ref_1762445986614.jpg", "ref_1762445998653.jpg", "ref_1762446010886.jpg", "ref_1762446022728.jpg", "ref_1762446034762.jpg", "ref_1762446046509.jpg", "ref_1762446056538.jpg", "ref_1762446068693.jpg", "ref_1762446082438.jpg", "ref_1762446094496.jpg", "ref_1762446106550.jpg", "ref_1762446118609.jpg", "ref_1762446130648.jpg", "ref_1762446142717.jpg", "ref_1762446154447.jpg", "ref_1762446166498.jpg", "ref_1762446180660.jpg", "ref_1762446192750.jpg", "ref_1762446204807.jpg", "ref_1762446216831.jpg", "ref_1762446228871.jpg", "ref_1762446240893.jpg", "ref_1762446252507.jpg", "ref_1762446264572.jpg", "ref_1762446276607.jpg", "ref_1762446288514.jpg", "ref_1762446300488.jpg", "ref_1762446312422.jpg", "ref_1762446324019.jpg", "ref_1762446336032.jpg", "ref_1762446348066.jpg", "ref_1762446360082.jpg", "ref_1762446372144.jpg", "ref_1762446384202.jpg", "ref_1762446396077.jpg", "ref_1762446408127.jpg", "ref_1762446420167.jpg", "ref_1762446432087.jpg", "ref_1762446444161.jpg", "ref_1762446456210.jpg", "ref_1762446468923.jpg", "ref_1762446480309.jpg", "ref_1762446492192.jpg", "ref_1762446504256.jpg", "ref_1762446516291.jpg", "ref_1762446528436.jpg", "ref_1762446540494.jpg", "ref_1762446552427.jpg", "ref_1762446564492.jpg", "ref_1762446576529.jpg", "ref_1762446588659.jpg", "ref_1762446602828.jpg", "ref_1762446614862.jpg", "ref_1762446626946.jpg", "ref_1762446638998.jpg", "ref_1762446651024.jpg", "ref_1762446663089.jpg", "ref_1762446677153.jpg", "ref_1762446689232.jpg", "ref_1762446701267.jpg", "ref_1762446713331.jpg", "ref_1762446725376.jpg", "ref_1762446737444.jpg", "ref_1762446749696.jpg", "ref_1762446761747.jpg", "ref_1762446773814.jpg", "ref_1762446785861.jpg", "ref_1762446797909.jpg", "ref_1762446811991.jpg", "ref_1762446824032.jpg", "ref_1762446836106.jpg", "ref_1762446850117.jpg", "ref_1762446862155.jpg", "ref_1762446874231.jpg", "ref_1762446886263.jpg", "ref_1762446898322.jpg", "ref_1762446912362.jpg", "ref_1762446924301.jpg", "ref_1762446934442.jpg", "ref_1762446946577.jpg", "ref_1762446960909.jpg", "ref_1762446972958.jpg", "ref_1762446985029.jpg", "ref_1762446997100.jpg", "ref_1762447009172.jpg", "ref_1762447021244.jpg", "ref_1762447033298.jpg", "ref_1762447045366.jpg", "ref_1762447057390.jpg", "ref_1762447069446.jpg", "ref_1762447081323.jpg", "ref_1762447093377.jpg", "ref_1762447105452.jpg", "ref_1762447117506.jpg", "ref_1762447129545.jpg", "ref_1762447141585.jpg", "ref_1762447165673.jpg", "ref_1762447177736.jpg", "ref_1762447190196.jpg", "ref_1762447202243.jpg", "ref_1762447214302.jpg", "ref_1762447224347.jpg", "ref_1762447234395.jpg", "ref_1762447246443.jpg", "ref_1762447260775.jpg", "ref_1762447272826.jpg", "ref_1762447284879.jpg", "ref_1762447296926.jpg", "ref_1762447310990.jpg", "ref_1762447323058.jpg", "ref_1762447335010.jpg", "ref_1762447347141.jpg", "ref_1762447359265.jpg", "ref_1762447373687.jpg", "ref_1762447385746.jpg", "ref_1762447397802.jpg", "ref_1762447410029.jpg", "ref_1762447422099.jpg", "ref_1762447436132.jpg", "ref_1762447448170.jpg", "ref_1762447460493.jpg", "ref_1762447474566.jpg", "ref_1762447486606.jpg", "ref_1762447498680.jpg", "ref_1762447510736.jpg", "ref_1762447522850.jpg", "ref_1762447536728.jpg", "ref_1762447548711.jpg", "ref_1762447560749.jpg", "ref_1762447572766.jpg", "ref_1762447584846.jpg", "ref_1762447599428.jpg", "ref_1762447611506.jpg", "ref_1762447623554.jpg", "ref_1762447635591.jpg", "ref_1762447647705.jpg", "ref_1762447662180.jpg", "ref_1762447674224.jpg", "ref_1762447686272.jpg", "ref_1762447698335.jpg", "ref_1762447712775.jpg", "ref_1762447724837.jpg", "ref_1762447736877.jpg", "ref_1762447748947.jpg", "ref_1762447761259.jpg", "ref_1762447775306.jpg", "ref_1762447787359.jpg", "ref_1762447799419.jpg", "ref_1762447811469.jpg", "ref_1762447825588.jpg", "ref_1762447837608.jpg", "ref_1762447863776.jpg", "ref_1762447875814.jpg", "ref_1762447887857.jpg", "ref_1762447902551.jpg", "ref_1762447914594.jpg", "ref_1762447922632.jpg", "ref_1762447934699.jpg", "ref_1762447946746.jpg", "ref_1762447958832.jpg", "ref_1762447970734.jpg", "ref_1762447985097.jpg", "ref_1762447997153.jpg", "ref_1762448007203.jpg", "ref_1762448019260.jpg", "ref_1762448031322.jpg", "ref_1762448043373.jpg", "ref_1762448054803.jpg", "ref_1762448066863.jpg", "ref_1762448079539.jpg", "ref_1762448094111.jpg", "ref_1762448106191.jpg", "ref_1762448118780.jpg", "ref_1762448132975.jpg", "ref_1762448145019.jpg", "ref_1762448157107.jpg", "ref_1762448171564.jpg", "ref_1762448181585.jpg", "ref_1762448193642.jpg", "ref_1762448207959.jpg", "ref_1762448220283.jpg", "ref_1762448232365.jpg", "ref_1762448246538.jpg", "ref_1762448258822.jpg", "ref_1762448271334.jpg", "ref_1762448285406.jpg", "ref_1762448297458.jpg", "ref_1762448309512.jpg", "ref_1762448323681.jpg", "ref_1762448335727.jpg", "ref_1762448348344.jpg", "ref_1762448362967.jpg", "ref_1762448375026.jpg", "ref_1762448387087.jpg", "ref_1762448399134.jpg", "ref_1762448411161.jpg", "ref_1762448423259.jpg", "ref_1762448435304.jpg", "ref_1762448449833.jpg", "ref_1762448461893.jpg", "ref_1762448476154.jpg", "ref_1762448488448.jpg", "ref_1762448501086.jpg", "ref_1762448515570.jpg", "ref_1762448527640.jpg", "ref_1762448542454.jpg", "ref_1762448554526.jpg", "ref_1762448566632.jpg", "ref_1762448579260.jpg", "ref_1762448593712.jpg", "ref_1762448605733.jpg", "ref_1762448617790.jpg", "ref_1762448629824.jpg", "ref_1762448644087.jpg", "ref_1762448654372.jpg", "ref_1762448666447.jpg", "ref_1762448680882.jpg", "ref_1762448692910.jpg", "ref_1762448704944.jpg", "ref_1762448717348.jpg", "ref_1762448731401.jpg", "ref_1762448743616.jpg", "ref_1762448755791.jpg", "ref_1762448768441.jpg", "ref_1762448780476.jpg", "ref_1762448794712.jpg", "ref_1762448806727.jpg", "ref_1762448819276.jpg", "ref_1762448833551.jpg", "ref_1762448845610.jpg", "ref_1762448858138.jpg", "ref_1762448870267.jpg", "ref_1762448884517.jpg", "ref_1762448896591.jpg", "ref_1762448908620.jpg", "ref_1762448920687.jpg", "ref_1762448935034.jpg", "ref_1762448947107.jpg", "ref_1762448959456.jpg", "ref_1762448971523.jpg", "ref_1762448983601.jpg", "ref_1762448995757.jpg", "ref_1762449010391.jpg", "ref_1762449022454.jpg", "ref_1762449034497.jpg", "ref_1762449046548.jpg", "ref_1762449061276.jpg", "ref_1762449073322.jpg", "ref_1762449085377.jpg", "ref_1762449097671.jpg", "ref_1762449110097.jpg", "ref_1762449124414.jpg", "ref_1762449136460.jpg", "ref_1762449148485.jpg", "ref_1762449160556.jpg", "ref_1762449172729.jpg", "ref_1762449184785.jpg", "ref_1762449199260.jpg", "ref_1762449211912.jpg", "ref_1762449226075.jpg", "ref_1762449239039.jpg", "ref_1762449251027.jpg", "ref_1762449263167.jpg", "ref_1762449275508.jpg", "ref_1762449289829.jpg", "ref_1762449302028.jpg", "ref_1762449316212.jpg", "ref_1762449326261.jpg", "ref_1762449340929.jpg", "ref_1762449352972.jpg", "ref_1762449365035.jpg", "ref_1762449377064.jpg", "ref_1762449391456.jpg", "ref_1762449403764.jpg", "ref_1762449417850.jpg", "ref_1762449429904.jpg", "ref_1762449441971.jpg", "ref_1762449456019.jpg", "ref_1762449466058.jpg", "ref_1762449478126.jpg", "ref_1762449493213.jpg", "ref_1762449505257.jpg", "ref_1762449517319.jpg", "ref_1762449530337.jpg", "ref_1762449542622.jpg", "ref_1762449556858.jpg", "ref_1762449568916.jpg", "ref_1762449580967.jpg", "ref_1762449593028.jpg", "ref_1762449605111.jpg", "ref_1762449617289.jpg", "ref_1762449629364.jpg", "ref_1762449644207.jpg", "ref_1762449654351.jpg", "ref_1762449669047.jpg", "ref_1762449681706.jpg", "ref_1762449694111.jpg", "ref_1762449708303.jpg", "ref_1762449720342.jpg", "ref_1762449732456.jpg", "ref_1762449746560.jpg", "ref_1762449758571.jpg", "ref_1762449770629.jpg", "ref_1762449784710.jpg", "ref_1762449796747.jpg", "ref_1762449808995.jpg", "ref_1762449823901.jpg", "ref_1762449835918.jpg", "ref_1762449848003.jpg", "ref_1762449860064.jpg", "ref_1762449874712.jpg", "ref_1762449886744.jpg", "ref_1762449898827.jpg", "ref_1762449911411.jpg", "ref_1762449923461.jpg", "ref_1762449935520.jpg", "ref_1762449949566.jpg", "ref_1762449962251.jpg", "ref_1762449976884.jpg", "ref_1762449989160.jpg", "ref_1762450001207.jpg", "ref_1762450013265.jpg", "ref_1762450025306.jpg", "ref_1762450037498.jpg", "ref_1762450051590.jpg", "ref_1762450063929.jpg", "ref_1762450078019.jpg", "ref_1762450090905.jpg", "ref_1762450105357.jpg", "ref_1762450117423.jpg", "ref_1762450127525.jpg", "ref_1762450139573.jpg", "ref_1762450151646.jpg", "ref_1762450163693.jpg", "ref_1762450175733.jpg", "ref_1762450190186.jpg", "ref_1762450202382.jpg", "ref_1762450214529.jpg", "ref_1762450228870.jpg", "ref_1762450241672.jpg", "ref_1762450255973.jpg", "ref_1762450268426.jpg", "ref_1762450281395.jpg", "ref_1762450295930.jpg", "ref_1762450308128.jpg", "ref_1762450321161.jpg", "ref_1762450335893.jpg", "ref_1762450348330.jpg", "ref_1762450363562.jpg", "ref_1762450375712.jpg", "ref_1762450388428.jpg", "ref_1762450403229.jpg", "ref_1762450415597.jpg", "ref_1762450427955.jpg", "ref_1762450443689.jpg", "ref_1762450456197.jpg", "ref_1762450468813.jpg", "ref_1762450483593.jpg", "ref_1762450495785.jpg", "ref_1762450509078.jpg", "ref_1762450521138.jpg", "ref_1762450535544.jpg", "ref_1762450547812.jpg", "ref_1762450560448.jpg", "ref_1762450575588.jpg", "ref_1762450587892.jpg", "ref_1762450602755.jpg", "ref_1762450615126.jpg", "ref_1762450627541.jpg", "ref_1762450642668.jpg", "ref_1762450654880.jpg", "ref_1762450669243.jpg", "ref_1762450681752.jpg", "ref_1762450696253.jpg", "ref_1762450709034.jpg", "ref_1762450724239.jpg", "ref_1762450736555.jpg", "ref_1762450749622.jpg", "ref_1762450762308.jpg", "ref_1762450776712.jpg", "ref_1762450789246.jpg", "ref_1762450802100.jpg", "ref_1762450814542.jpg", "ref_1762450829252.jpg", "ref_1762450842329.jpg", "ref_1762450857043.jpg", "ref_1762450869664.jpg", "ref_1762450882406.jpg", "ref_1762450896808.jpg", "ref_1762450908882.jpg", "ref_1762450922106.jpg", "ref_1762450949142.jpg", "ref_1762450964304.jpg", "ref_1762450976510.jpg", "ref_1762450989273.jpg", "ref_1762451003967.jpg", "ref_1762451011990.jpg", "ref_1762451024520.jpg", "ref_1762451038868.jpg", "ref_1762451051502.jpg", "ref_1762451066460.jpg", "ref_1762451079625.jpg", "ref_1762451094605.jpg", "ref_1762451106768.jpg", "ref_1762451119570.jpg", "ref_1762451134396.jpg", "ref_1762451146919.jpg", "ref_1762451159759.jpg", "ref_1762451174740.jpg", "ref_1762451187066.jpg", "ref_1762451200142.jpg", "ref_1762451215325.jpg", "ref_1762451227957.jpg", "ref_1762451243178.jpg", "ref_1762451255503.jpg", "ref_1762451269690.jpg", "ref_1762451281997.jpg", "ref_1762451294488.jpg", "ref_1762451307197.jpg", "ref_1762451322618.jpg", "ref_1762451334914.jpg", "ref_1762451347123.jpg", "ref_1762451360253.jpg", "ref_1762451375381.jpg", "ref_1762451387541.jpg", "ref_1762451401313.jpg", "ref_1762451415940.jpg", "ref_1762451428392.jpg", "ref_1762451441593.jpg", "ref_1762451456415.jpg", "ref_1762451468712.jpg", "ref_1762451484008.jpg", "ref_1762451496531.jpg", "ref_1762451509219.jpg", "ref_1762451524628.jpg", "ref_1762451537023.jpg", "ref_1762451549936.jpg", "ref_1762451564759.jpg", "ref_1762451577454.jpg", "ref_1762451590427.jpg", "ref_1762451603592.jpg", "ref_1762451618065.jpg", "ref_1762451631062.jpg", "ref_1762451644027.jpg", "ref_1762451658926.jpg", "ref_1762451671909.jpg", "ref_1762451685995.jpg", "ref_1762451700810.jpg", "ref_1762451714005.jpg", "ref_1762451726340.jpg", "ref_1762451738699.jpg", "ref_1762451754504.jpg", "ref_1762451766932.jpg", "ref_1762451779918.jpg", "ref_1762451792985.jpg", "ref_1762451807801.jpg", "ref_1762451820750.jpg", "ref_1762451833555.jpg", "ref_1762451846425.jpg", "ref_1762451861485.jpg", "ref_1762451874447.jpg", "ref_1762451887216.jpg", "ref_1762451902530.jpg", "ref_1762451915295.jpg", "ref_1762451928060.jpg", "ref_1762451943771.jpg", "ref_1762451956204.jpg", "ref_1762451969346.jpg", "ref_1762451985154.jpg", "ref_1762451997717.jpg", "ref_1762452012070.jpg", "ref_1762452025374.jpg", "ref_1762452039642.jpg", "ref_1762452052321.jpg", "ref_1762452065069.jpg", "ref_1762452079322.jpg", "ref_1762452092490.jpg", "ref_1762452105651.jpg", "ref_1762452120518.jpg", "ref_1762452133693.jpg", "ref_1762452146183.jpg", "ref_1762452160871.jpg", "ref_1762452173127.jpg", "ref_1762452185547.jpg", "ref_1762452200524.jpg", "ref_1762452213935.jpg", "ref_1762452228696.jpg", "ref_1762452240758.jpg", "ref_1762452252911.jpg", "ref_1762452264970.jpg", "ref_1762452277056.jpg", "ref_1762452289392.jpg", "ref_1762452303765.jpg", "ref_1762452315878.jpg", "ref_1762452328040.jpg", "ref_1762452342804.jpg", "ref_1762452354859.jpg", "ref_1762452367158.jpg", "ref_1762452381594.jpg", "ref_1762452394229.jpg", "ref_1762452408506.jpg", "ref_1762452420866.jpg", "ref_1762452447311.jpg", "ref_1762452459614.jpg", "ref_1762452472036.jpg", "ref_1762452486241.jpg", "ref_1762452498297.jpg", "ref_1762452508355.jpg", "ref_1762452520567.jpg", "ref_1762452532601.jpg", "ref_1762452544926.jpg", "ref_1762452559658.jpg", "ref_1762452572148.jpg", "ref_1762452586421.jpg", "ref_1762452598485.jpg", "ref_1762452610565.jpg", "ref_1762452623286.jpg", "ref_1762452637761.jpg", "ref_1762452649945.jpg", "ref_1762452662002.jpg", "ref_1762452676089.jpg", "ref_1762452688542.jpg", "ref_1762452700978.jpg", "ref_1762452716234.jpg", "ref_1762452728404.jpg", "ref_1762452740900.jpg", "ref_1762452753691.jpg", "ref_1762452768492.jpg", "ref_1762452780931.jpg", "ref_1762452793894.jpg", "ref_1762452808237.jpg", "ref_1762452820850.jpg", "ref_1762452834029.jpg", "ref_1762452848295.jpg", "ref_1762452860843.jpg", "ref_1762452873706.jpg", "ref_1762453036570.jpg", "ref_1762453036571.jpg", "ref_1762453036572.jpg", "ref_1762453036573.jpg", "ref_1762453036574.jpg", "ref_1762453036575.jpg", "ref_1762454953198.jpg", "ref_1762455024253.jpg", "ref_1762455831475.jpg", "ref_1762456165537.jpg", "ref_1762456573729.jpg", "ref_1762456576673.jpg", "ref_1762456592425.jpg", "ref_1762458765274.png", "ref_1762458780333.png", "ref_1762464249852.jpg", "ref_1762464434323.jpg", "ref_1762464627359.jpg", "ref_1762464647010.jpg", "ref_1762465007312.jpg", "ref_1762465081879.jpg", "ref_1762465088858.jpg", "ref_1762465766186.jpg", "ref_1762466033944.jpg", "ref_1762466043071.jpg", "ref_1762473375285.jpg", "ref_1762473378810.jpg", "ref_1762507814234.jpg", "ref_1762507942484.jpg", "ref_1762507989054.jpg", "ref_1762507990800.jpg", "ref_1762507992606.jpg", "ref_1762507994526.jpg", "ref_1762508084658.jpg", "ref_1762508129831.jpg", "ref_1762508270339.jpg", "ref_1762508270344.jpg", "ref_1762508270355.jpg", "ref_1762508270356.jpg", "ref_1762508270357.jpg", "ref_1762508270359.jpg", "ref_1762508472509.jpg", "ref_1762508472510.jpg", "ref_1762508472513.jpg", "ref_1762508472537.png", "ref_1762508472543.jpg", "ref_1762508472614.jpg", "ref_1762508715452.jpg", "ref_1762508715453.jpg", "ref_1762508715456.jpg", "ref_1762508715457.jpg", "ref_1762508715488.jpg", "ref_1762508918266.jpg", "ref_1762508918267.jpg", "ref_1762508918271.png", "ref_1762508918396.png", "ref_1762610690186.jpg", "ref_1762610703432.jpg", "ref_1762610869026.jpg", "ref_1762610905799.jpg", "ref_1762611796957.jpg", "ref_1762611840088.jpg", "ref_1762611847572.jpg", "ref_1762613110379.jpg", "ref_1762623498508.jpg", "ref_1762623534202.jpg", "ref_1762624829793.jpg", "ref_1762712436781.jpg", "ref_1762712537658.jpg", "ref_1762712636344.jpg", "ref_1762712640022.jpg", "ref_1762712680434.jpg", "ref_1762713120552.jpg", "ref_1762713661762.jpg", "ref_1762717812308.jpg", "ref_1762720601884.jpg", "ref_1762721161257.jpg"], {"image_upload": true}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImage", "display_name": "Load Image", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "LoadImageMask": {"input": {"required": {"image": [["1761597930315.jpg", "1761597930346.jpg", "1761597930367.jpg", "1761597930396.jpg", "1761597930425.jpg", "1761597930453.jpg", "1761597930480.jpg", "1761597930508.jpg", "1761597930536.jpg", "1761597930561.jpg", "1761597930675.png", "1761597930784.png", "1761597930893.png", "1761597931005.png", "1761597931165.png", "1761597931254.png", "1761597931291.jpg", "1761597931314.jpg", "1761597931353.jpg", "1761597931384.jpg", "1761597931486.png", "1761597931583.png", "1761597931678.png", "1761597931766.png", "1761597931903.png", "1761597932001.png", "1761597952317.jpg", "1761597952336.jpg", "1761597952353.jpg", "1761597952370.jpg", "1761597952387.jpg", "1761597952405.jpg", "1761597952422.jpg", "1761597952441.jpg", "1761597952457.jpg", "1761597952474.jpg", "1761597952611.png", "1761597952709.png", "1761597952805.png", "1761597952905.png", "1761597953027.png", "1761597953119.png", "1761597953153.jpg", "1761597953170.jpg", "1761597953193.jpg", "1761597953220.jpg", "1761597953316.png", "1761597953410.png", "1761597953505.png", "1761597953578.png", "1761597953674.png", "1761597953772.png", "1761598611514.jpg", "1761598611634.jpg", "1761598611658.jpg", "1761598611766.jpg", "1761598611853.jpg", "1761598611881.jpg", "1761598611901.jpg", "1761598611929.jpg", "1761598611949.jpg", "1761598611979.jpg", "1761598612099.png", "1761598612214.png", "1761598612317.png", "1761598612425.png", "1761598612555.png", "1761598612656.png", "1761598612706.jpg", "1761598612731.jpg", "1761598612760.jpg", "1761598612867.jpg", "1761598612966.png", "1761598613063.png", "1761598613160.png", "1761598613237.png", "1761598613354.png", "1761598613473.png", "1761676691867.png", "1761676935253.png", "1761676949497.png", "1761677110108.png", "1761677126210.png", "1761677171515.png", "1761677185583.png", "1761677396874.png", "1761677410966.png", "1761677452180.png", "1761677466228.png", "1761677482001.png", "1761677496095.png", "1761677510725.png", "1761677526772.png", "1761677540848.png", "1761677555235.png", "1761677569789.png", "1761677585850.png", "1761677599221.png", "1761677615293.png", "1761677628675.png", "1761677644440.png", "1761677659116.png", "1761677675185.png", "1761677690204.png", "1761677705324.png", "1761677719127.png", "1761677735167.png", "1761677749222.png", "1761677763904.png", "1761677779059.png", "1761677794026.png", "1761677809813.png", "1761677824261.png", "1761677839945.png", "1761677854640.png", "1761677867936.png", "1761677882801.png", "1761677898717.png", "1761677912999.png", "1761677928514.png", "1761677943317.png", "1761677958573.png", "1761677974048.png", "1761677988119.png", "1761678004194.png", "1761678019147.png", "1761678032330.png", "1761678047269.png", "1761678062739.png", "1761678078809.png", "1761681696042.png", "1761681714148.png", "1761681730192.png", "1761681746312.png", "1761681762855.png", "1761681780944.png", "1761681798349.png", "1761681814220.png", "1761681832262.png", "1761681847865.png", "1761681865288.png", "1761682297504.png", "1761682315554.png", "1761683677514.png", "1761683695605.png", "1761684439441.png", "1761684457513.png", "1761684472593.png", "1761684489675.png", "1762252054938.png", "1762252062974.png", "1762252073014.png", "1762252083057.png", "1762252091739.png", "1762252100680.png", "1762252109837.png", "1762252116750.png", "1762252127759.png", "1762252135781.png", "1762252146328.png", "1762252155360.png", "1762252164410.png", "1762252175335.png", "1762252182313.png", "1762252192352.png", "1762252200925.png", "1762252209838.png", "1762252219000.png", "1762252227932.png", "1762252237026.png", "1762252246926.png", "1762252255475.png", "1762252266512.png", "1762252275620.png", "1762252284571.png", "1762252293678.png", "1762252303514.png", "1762252312108.png", "1762252321098.png", "1762252330196.png", "1762252341185.png", "1762252348095.png", "1762252358094.png", "1762252366668.png", "1762252377723.png", "1762252386756.png", "1762252395805.png", "1762252404662.png", "1762252414723.png", "1762252423310.png", "1762252432425.png", "1762252441384.png", "1762252452432.png", "1762252461224.png", "1762252471262.png", "1762252480147.png", "1762252488973.png", "1762252499987.png", "1762252509010.png", "1762252517832.png", "1762252527886.png", "1762252536787.png", "1762252545639.png", "1762252556666.png", "1762252565622.png", "1762252574764.png", "1762252584632.png", "1762252593431.png", "1762252604294.png", "1762252613310.png", "1762252622305.png", "1762252633347.png", "1762252641250.png", "1762252652096.png", "1762252660906.png", "1762252669956.png", "1762252680945.png", "1762252687918.png", "1762252697961.png", "1762252708764.png", "1762252717686.png", "1762252726623.png", "1762252737811.png", "1762252746711.png", "1762252756767.png", "1762252765483.png", "1762252776386.png", "1762252785409.png", "1762252794509.png", "1762252802970.png", "1762252813462.png", "1762252822136.png", "1762252833115.png", "1762252842076.png", "1762292337386.png", "1762292351653.png", "1762293739548.png", "1762293753617.png", "1762293852196.png", "1762293860316.png", "1762293870354.png", "1762293878376.png", "1762293887081.png", "1762293896008.png", "1762293904456.png", "1762293912552.png", "1762293922586.png", "1762293930615.png", "1762293939536.png", "1762293948313.png", "1762293956698.png", "1762293964789.png", "1762293974836.png", "1762293982849.png", "1762293991799.png", "1762294000563.png", "1762294009079.png", "1762294019765.png", "1762294027791.png", "1762294037192.png", "1762294046054.png", "1762294054883.png", "1762294063320.png", "1762294071975.png", "1762294080028.png", "1762294089432.png", "1762294098355.png", "1762294107109.png", "1762294115550.png", "1762294124193.png", "1762294132251.png", "1762294141673.png", "1762294162652.png", "1762294177430.png", "1762294189923.png", "1762294200576.png", "1762294210586.png", "1762294218059.png", "1762294226935.png", "1762294235703.png", "1762294244164.png", "1762294252975.png", "1762294262840.png", "1762294270413.png", "1762294281208.png", "1762294289940.png", "1762294298564.png", "1762294307257.png", "1762294317129.png", "1762294324712.png", "1762294333504.png", "1762294342185.png", "1762294350856.png", "1762294359529.png", "1762294369519.png", "1762294378994.png", "1762294387747.png", "1762294396431.png", "1762294405122.png", "1762294413763.png", "1762294422102.png", "1762294431224.png", "1762294439952.png", "1762294448644.png", "1762294457366.png", "1762294466071.png", "1762294476501.png", "1762294483473.png", "1762294494187.png", "1762294502923.png", "1762294511629.png", "1762294520323.png", "1762294528798.png", "1762294537724.png", "1762294546445.png", "1762294555184.png", "1762294565891.png", "1762294574585.png", "1762294583070.png", "1762294592000.png", "1762294600729.png", "1762294609433.png", "1762294618146.png", "1762294626854.png", "1762294635303.png", "1762294644258.png", "1762294653196.png", "1762294661675.png", "1762294670387.png", "1762294679125.png", "1762294689607.png", "1762294698501.png", "1762294707448.png", "1762294715906.png", "1762294724625.png", "1762294733369.png", "1762294741849.png", "1762294750766.png", "1762294759716.png", "1762294768179.png", "1762294776846.png", "1762294785648.png", "1762294794094.png", "1762294802978.png", "1762294811936.png", "1762294822426.png", "1762294831105.png", "1762294839955.png", "1762294848358.png", "1762294857215.png", "1762294866282.png", "1762294874652.png", "1762294883337.png", "1762294892311.png", "1762294902613.png", "1762294911428.png", "1762294920518.png", "1762294928901.png", "1762294937546.png", "1762294946533.png", "1762294954840.png", "1762294963668.png", "1762294972736.png", "1762294981193.png", "1762294991810.png", "1762295000752.png", "1762295009247.png", "1762295017930.png", "1762295027001.png", "1762295035442.png", "1762295044072.png", "1762295053057.png", "1762295061548.png", "1762295070243.png", "1762295079237.png", "1762295087702.png", "1762295098348.png", "1762295105374.png", "1762295115841.png", "1762295124543.png", "1762295133520.png", "1762295141962.png", "1762295150639.png", "1762295159664.png", "1762295168115.png", "1762295176761.png", "1762295185818.png", "1762295194494.png", "1762295204882.png", "1762295213940.png", "1762295222667.png", "1762295231001.png", "1762295240088.png", "1762295248833.png", "1762295257142.png", "1762295266230.png", "1762295274911.png", "1762295283380.png", "1762436455476.png", "1762436464899.png", "1762436483643.png", "1762436491053.png", "1762436500112.png", "1762436509151.png", "1762436519294.png", "1762436527140.png", "1762436536019.png", "1762436545301.png", "1762436554310.png", "1762436563381.png", "1762436573554.png", "1762436581377.png", "1762436590384.png", "1762436599517.png", "1762436608695.png", "1762436617588.png", "1762436627811.png", "1762436635625.png", "1762436644741.png", "1762436654529.png", "1762436663278.png", "1762436671887.png", "1762436680129.png", "1762436690024.png", "1762436698979.png", "1762436708742.png", "1762436717580.png", "1762436726202.png", "1762436734441.png", "1762436744342.png", "1762436753236.png", "1762436762979.png", "1762436771833.png", "1762436780515.png", "1762436788687.png", "1762436798590.png", "1762436807474.png", "1762436815237.png", "1762436824078.png", "1762436832740.png", "1762436843054.png", "1762436850832.png", "1762436860038.png", "1762436869519.png", "1762436878359.png", "1762436886983.png", "1762436897308.png", "1762436905082.png", "1762436914300.png", "1762436923768.png", "1762436932676.png", "1762436941271.png", "1762436949582.png", "1762436959305.png", "1762436968538.png", "1762436976009.png", "1762436986920.png", "1762436995508.png", "1762437058091.png", "1762437068131.png", "1762437076184.png", "1762437084282.png", "1762437094343.png", "1762437102396.png", "1762437244770.png", "1762437258354.png", "1762437267092.png", "1762437275115.png", "1762437284559.png", "1762437293289.png", "1762437302843.png", "1762437311379.png", "1762437320864.png", "1762437328863.png", "1762437338364.png", "1762443945640.png", "1762443991484.png", "1762444001527.png", "1762444012775.png", "1762444022318.png", "1762444033230.png", "1762444044255.png", "1762444055074.png", "1762444067156.png", "1762444078404.png", "1762444090301.png", "1762444101232.png", "1762444111991.png", "1762444122777.png", "1762444134802.png", "1762444146160.png", "1762444157626.png", "1762444168336.png", "1762444179462.png", "1762444190237.png", "1762444200240.png", "1762444211588.png", "1762444223473.png", "1762444231506.png", "1762444242477.png", "1762444253704.png", "1762444265772.png", "1762444277238.png", "1762444289270.png", "1762444301320.png", "1762444312568.png", "1762444323575.png", "1762444335603.png", "1762444346900.png", "1762444358954.png", "1762444371003.png", "1762444382012.png", "1762444393098.png", "1762444405007.png", "1762444416472.png", "1762444428507.png", "1762444440579.png", "1762444451955.png", "1762444462980.png", "1762444474999.png", "1762444486430.png", "1762444498522.png", "1762444510569.png", "1762444522231.png", "1762444533303.png", "1762444544421.png", "1762444556481.png", "1762444568538.png", "1762444577719.png", "1762444589792.png", "1762444600723.png", "1762444611840.png", "1762444623907.png", "1762444635668.png", "1762444647052.png", "1762444659094.png", "1762444667124.png", "1762444679193.png", "1762444691224.png", "1762444703051.png", "1762444712568.png", "1762444726720.png", "1762444738739.png", "1762444750817.png", "1762444762851.png", "1762444772899.png", "1762444784960.png", "1762444796420.png", "1762444808468.png", "1762444820524.png", "1762444832567.png", "1762444844598.png", "1762444856072.png", "1762444867745.png", "1762444879789.png", "1762444891818.png", "1762444903884.png", "1762444915809.png", "1762444927597.png", "1762444939147.png", "1762444951230.png", "1762444961268.png", "1762444973333.png", "1762444985172.png", "1762444996796.png", "1762445008487.png", "1762445020494.png", "1762445032514.png", "1762445042605.png", "1762445054685.png", "1762445066228.png", "1762445078242.png", "1762445090273.png", "1762445102305.png", "1762445114344.png", "1762445126398.png", "1762445138036.png", "1762445149643.png", "1762445161687.png", "1762445173727.png", "1762445185772.png", "1762445195937.png", "1762445207427.png", "1762445219349.png", "1762445231400.png", "1762445243451.png", "1762445255477.png", "1762445267528.png", "1762445279319.png", "1762445290953.png", "1762445303016.png", "1762445315040.png", "1762445327022.png", "1762445339095.png", "1762445350868.png", "1762445362838.png", "1762445374892.png", "1762445386910.png", "1762445398625.png", "1762445410341.png", "1762445422375.png", "1762445434443.png", "1762445446483.png", "1762445456457.png", "1762445468516.png", "1762445480246.png", "1762445492286.png", "1762445504369.png", "1762445516093.png", "1762445528145.png", "1762445540003.png", "1762445551892.png", "1762445563934.png", "1762445575985.png", "1762445587712.png", "1762445599773.png", "1762445611544.png", "1762445623279.png", "1762445635353.png", "1762445646567.png", "1762445658092.png", "1762445670136.png", "1762445682196.png", "1762445693797.png", "1762445705851.png", "1762445717234.png", "1762445729979.png", "1762445741732.png", "1762445753626.png", "1762445765458.png", "1762445777532.png", "1762445787565.png", "1762445799555.png", "1762445811616.png", "1762445823657.png", "1762445835095.png", "1762445845044.png", "1762445856997.png", "1762445869064.png", "1762445881120.png", "1762445893174.png", "1762445904710.png", "1762445916752.png", "1762445927248.png", "1762445939288.png", "1762445951353.png", "1762445963390.png", "1762445974545.png", "1762445986609.png", "1762445998648.png", "1762446010676.png", "1762446022723.png", "1762446034756.png", "1762446046500.png", "1762446056533.png", "1762446068688.png", "1762446082432.png", "1762446094489.png", "1762446106544.png", "1762446118605.png", "1762446130641.png", "1762446142711.png", "1762446154441.png", "1762446166493.png", "1762446180653.png", "1762446192744.png", "1762446204801.png", "1762446216827.png", "1762446228865.png", "1762446240887.png", "1762446252501.png", "1762446264566.png", "1762446276601.png", "1762446288509.png", "1762446300481.png", "1762446312417.png", "1762446324014.png", "1762446336027.png", "1762446348060.png", "1762446360077.png", "1762446372139.png", "1762446384196.png", "1762446396072.png", "1762446408122.png", "1762446420161.png", "1762446432083.png", "1762446444154.png", "1762446456203.png", "1762446468247.png", "1762446480303.png", "1762446492185.png", "1762446504251.png", "1762446516285.png", "1762446528430.png", "1762446540490.png", "1762446552421.png", "1762446564485.png", "1762446576524.png", "1762446588654.png", "1762446602822.png", "1762446614856.png", "1762446626939.png", "1762446638992.png", "1762446651018.png", "1762446663084.png", "1762446677146.png", "1762446689226.png", "1762446701260.png", "1762446713325.png", "1762446725371.png", "1762446737439.png", "1762446749691.png", "1762446761742.png", "1762446773806.png", "1762446785856.png", "1762446797905.png", "1762446811984.png", "1762446824027.png", "1762446836100.png", "1762446850111.png", "1762446862148.png", "1762446874224.png", "1762446886257.png", "1762446898316.png", "1762446912352.png", "1762446924293.png", "1762446934437.png", "1762446946573.png", "1762446960903.png", "1762446972953.png", "1762446985023.png", "1762446997094.png", "1762447009167.png", "1762447021237.png", "1762447033293.png", "1762447045358.png", "1762447057385.png", "1762447069441.png", "1762447081318.png", "1762447093372.png", "1762447105447.png", "1762447117501.png", "1762447129539.png", "1762447141579.png", "1762447153625.png", "1762447165668.png", "1762447177730.png", "1762447190190.png", "1762447202238.png", "1762447214296.png", "1762447224338.png", "1762447234390.png", "1762447246438.png", "1762447260768.png", "1762447272819.png", "1762447284873.png", "1762447296921.png", "1762447310984.png", "1762447323052.png", "1762447335004.png", "1762447347135.png", "1762447359259.png", "1762447373681.png", "1762447385739.png", "1762447397795.png", "1762447410023.png", "1762447422092.png", "1762447436126.png", "1762447448164.png", "1762447460488.png", "1762447474560.png", "1762447486600.png", "1762447498674.png", "1762447510730.png", "1762447522845.png", "1762447536721.png", "1762447548704.png", "1762447560743.png", "1762447572759.png", "1762447584840.png", "1762447599421.png", "1762447611500.png", "1762447623548.png", "1762447635585.png", "1762447647700.png", "1762447662174.png", "1762447674218.png", "1762447686266.png", "1762447698329.png", "1762447712769.png", "1762447724830.png", "1762447736870.png", "1762447748939.png", "1762447761254.png", "1762447775299.png", "1762447787353.png", "1762447799414.png", "1762447811463.png", "1762447825582.png", "1762447837602.png", "1762447849680.png", "1762447863769.png", "1762447875808.png", "1762447887849.png", "1762447902544.png", "1762447914587.png", "1762447922625.png", "1762447934693.png", "1762447946740.png", "1762447958827.png", "1762447970728.png", "1762447985086.png", "1762447997145.png", "1762448007197.png", "1762448019252.png", "1762448031312.png", "1762448043361.png", "1762448054794.png", "1762448066857.png", "1762448079534.png", "1762448094104.png", "1762448106184.png", "1762448118775.png", "1762448132968.png", "1762448145013.png", "1762448157101.png", "1762448171557.png", "1762448181578.png", "1762448193637.png", "1762448207953.png", "1762448220277.png", "1762448232358.png", "1762448246532.png", "1762448258815.png", "1762448271328.png", "1762448285399.png", "1762448297452.png", "1762448309507.png", "1762448323674.png", "1762448335719.png", "1762448348337.png", "1762448362960.png", "1762448375020.png", "1762448387080.png", "1762448399127.png", "1762448411149.png", "1762448423253.png", "1762448435298.png", "1762448449826.png", "1762448461888.png", "1762448476147.png", "1762448488443.png", "1762448501080.png", "1762448515563.png", "1762448527635.png", "1762448542448.png", "1762448554519.png", "1762448566626.png", "1762448579254.png", "1762448593704.png", "1762448605726.png", "1762448617783.png", "1762448629817.png", "1762448644080.png", "1762448654365.png", "1762448666442.png", "1762448680874.png", "1762448692903.png", "1762448704939.png", "1762448717342.png", "1762448731394.png", "1762448743609.png", "1762448755784.png", "1762448768434.png", "1762448780470.png", "1762448794706.png", "1762448806721.png", "1762448819268.png", "1762448833544.png", "1762448845604.png", "1762448858132.png", "1762448870261.png", "1762448884511.png", "1762448896585.png", "1762448908615.png", "1762448920681.png", "1762448935027.png", "1762448947100.png", "1762448959450.png", "1762448971516.png", "1762448983595.png", "1762448995752.png", "1762449010384.png", "1762449022447.png", "1762449034488.png", "1762449046542.png", "1762449061270.png", "1762449073313.png", "1762449085371.png", "1762449097661.png", "1762449110090.png", "1762449124407.png", "1762449136453.png", "1762449148479.png", "1762449160548.png", "1762449172723.png", "1762449184780.png", "1762449199252.png", "1762449211903.png", "1762449226066.png", "1762449238106.png", "1762449251020.png", "1762449263162.png", "1762449275501.png", "1762449289822.png", "1762449302022.png", "1762449316205.png", "1762449326253.png", "1762449340921.png", "1762449352966.png", "1762449365029.png", "1762449377058.png", "1762449391449.png", "1762449403759.png", "1762449417844.png", "1762449429897.png", "1762449441963.png", "1762449456012.png", "1762449466052.png", "1762449478118.png", "1762449493203.png", "1762449505249.png", "1762449517313.png", "1762449530331.png", "1762449542616.png", "1762449556846.png", "1762449568908.png", "1762449580960.png", "1762449593022.png", "1762449605105.png", "1762449617279.png", "1762449629356.png", "1762449644197.png", "1762449654345.png", "1762449669040.png", "1762449681700.png", "1762449694103.png", "1762449708293.png", "1762449720334.png", "1762449732450.png", "1762449746552.png", "1762449758564.png", "1762449770623.png", "1762449784702.png", "1762449796740.png", "1762449808989.png", "1762449823893.png", "1762449835911.png", "1762449847996.png", "1762449860056.png", "1762449874705.png", "1762449886738.png", "1762449898819.png", "1762449911404.png", "1762449923453.png", "1762449935514.png", "1762449949559.png", "1762449962245.png", "1762449976876.png", "1762449989147.png", "1762450001198.png", "1762450013258.png", "1762450025297.png", "1762450037492.png", "1762450051583.png", "1762450063921.png", "1762450078012.png", "1762450090896.png", "1762450105350.png", "1762450117415.png", "1762450127518.png", "1762450139566.png", "1762450151640.png", "1762450163685.png", "1762450175727.png", "1762450190180.png", "1762450202375.png", "1762450214523.png", "1762450228862.png", "1762450241665.png", "1762450255965.png", "1762450268420.png", "1762450281387.png", "1762450295922.png", "1762450308119.png", "1762450321155.png", "1762450335885.png", "1762450348323.png", "1762450363555.png", "1762450375705.png", "1762450388422.png", "1762450403222.png", "1762450415590.png", "1762450427949.png", "1762450443680.png", "1762450456188.png", "1762450468807.png", "1762450483585.png", "1762450495778.png", "1762450509070.png", "1762450521131.png", "1762450535537.png", "1762450547804.png", "1762450560442.png", "1762450575581.png", "1762450587884.png", "1762450602747.png", "1762450615117.png", "1762450627533.png", "1762450642660.png", "1762450654874.png", "1762450669235.png", "1762450681744.png", "1762450696245.png", "1762450709028.png", "1762450724232.png", "1762450736547.png", "1762450749613.png", "1762450762302.png", "1762450776705.png", "1762450789239.png", "1762450802092.png", "1762450814534.png", "1762450829244.png", "1762450842322.png", "1762450857036.png", "1762450869657.png", "1762450882400.png", "1762450896801.png", "1762450908874.png", "1762450922100.png", "1762450937018.png", "1762450949135.png", "1762450964295.png", "1762450976503.png", "1762450989266.png", "1762451003956.png", "1762451011982.png", "1762451024513.png", "1762451038861.png", "1762451051495.png", "1762451066452.png", "1762451079618.png", "1762451094596.png", "1762451106761.png", "1762451119563.png", "1762451134387.png", "1762451146913.png", "1762451159752.png", "1762451174731.png", "1762451187057.png", "1762451200134.png", "1762451215315.png", "1762451227950.png", "1762451243171.png", "1762451255495.png", "1762451269682.png", "1762451281989.png", "1762451294479.png", "1762451307191.png", "1762451322609.png", "1762451334907.png", "1762451347116.png", "1762451360247.png", "1762451375372.png", "1762451387535.png", "1762451401306.png", "1762451415933.png", "1762451428384.png", "1762451441586.png", "1762451456406.png", "1762451468705.png", "1762451484000.png", "1762451496523.png", "1762451509213.png", "1762451524619.png", "1762451537016.png", "1762451549927.png", "1762451564750.png", "1762451577448.png", "1762451590418.png", "1762451603584.png", "1762451618058.png", "1762451631054.png", "1762451644021.png", "1762451658917.png", "1762451671901.png", "1762451685988.png", "1762451700802.png", "1762451713996.png", "1762451726331.png", "1762451738692.png", "1762451754495.png", "1762451766924.png", "1762451779911.png", "1762451792978.png", "1762451807794.png", "1762451820742.png", "1762451833548.png", "1762451846418.png", "1762451861477.png", "1762451874441.png", "1762451887208.png", "1762451902521.png", "1762451915288.png", "1762451928054.png", "1762451943762.png", "1762451956197.png", "1762451969338.png", "1762451985146.png", "1762451997708.png", "1762452012063.png", "1762452025367.png", "1762452039633.png", "1762452052314.png", "1762452065062.png", "1762452079313.png", "1762452092481.png", "1762452105643.png", "1762452120510.png", "1762452133685.png", "1762452146174.png", "1762452160863.png", "1762452173119.png", "1762452185538.png", "1762452200515.png", "1762452213926.png", "1762452228688.png", "1762452240748.png", "1762452252902.png", "1762452264962.png", "1762452277046.png", "1762452289383.png", "1762452303756.png", "1762452315872.png", "1762452328032.png", "1762452342796.png", "1762452354853.png", "1762452367152.png", "1762452381585.png", "1762452394222.png", "1762452408497.png", "1762452420860.png", "1762452433235.png", "1762452447303.png", "1762452459607.png", "1762452472029.png", "1762452486232.png", "1762452498289.png", "1762452508347.png", "1762452520558.png", "1762452532591.png", "1762452544920.png", "1762452559649.png", "1762452572141.png", "1762452586411.png", "1762452598473.png", "1762452610556.png", "1762452623280.png", "1762452637753.png", "1762452649936.png", "1762452661994.png", "1762452676081.png", "1762452688534.png", "1762452700972.png", "1762452716226.png", "1762452728393.png", "1762452740891.png", "1762452753685.png", "1762452768484.png", "1762452780922.png", "1762452793887.png", "1762452808228.png", "1762452820843.png", "1762452834018.png", "1762452848287.png", "1762452860834.png", "1762452873698.png", "ref_1761675962550.png", "ref_1761675962556.png", "ref_1761676578515.jpg", "ref_1761676578522.jpg", "ref_1761676918964.jpg", "ref_1761676918971.jpg", "ref_1761677093765.jpg", "ref_1761677093772.jpg", "ref_1761677155187.jpg", "ref_1761677155194.jpg", "ref_1761677380523.jpg", "ref_1761677380531.jpg", "ref_1761677435842.jpg", "ref_1761677435848.jpg", "ref_1761677457580.jpg", "ref_1761677457587.jpg", "ref_1761677466424.jpg", "ref_1761677506365.jpg", "ref_1761677506371.jpg", "ref_1761677510905.jpg", "ref_1761677549374.jpg", "ref_1761677549380.jpg", "ref_1761677560609.jpg", "ref_1761677560616.jpg", "ref_1761677569970.jpg", "ref_1761677586033.jpg", "ref_1761677608576.jpg", "ref_1761677608583.jpg", "ref_1761677615479.jpg", "ref_1761677628861.jpg", "ref_1761677644719.jpg", "ref_1761677674547.jpg", "ref_1761677674552.jpg", "ref_1761677675279.jpg", "ref_1761677690504.jpg", "ref_1761677705333.jpg", "ref_1761677719136.jpg", "ref_1761677735428.jpg", "ref_1761677749234.jpg", "ref_1761677763914.jpg", "ref_1761677779267.jpg", "ref_1761677794037.jpg", "ref_1761677810025.jpg", "ref_1761677824273.jpg", "ref_1761677839952.jpg", "ref_1761677854648.jpg", "ref_1761677867943.jpg", "ref_1761677883017.jpg", "ref_1761677898725.jpg", "ref_1761677913016.jpg", "ref_1761677928541.jpg", "ref_1761677943349.jpg", "ref_1761677958604.jpg", "ref_1761677974061.jpg", "ref_1761677988125.jpg", "ref_1761679807688.jpg", "ref_1761679807694.jpg", "ref_1761679839752.jpg", "ref_1761679839759.jpg", "ref_1761679850806.jpg", "ref_1761679850813.jpg", "ref_1761680549411.jpg", "ref_1761680549418.jpg", "ref_1761680828065.jpg", "ref_1761680828072.jpg", "ref_1761681062317.jpg", "ref_1761681062325.jpg", "ref_1761681506836.jpg", "ref_1761681506842.jpg", "ref_1761681514818.jpg", "ref_1761681534712.jpg", "ref_1761681534718.jpg", "ref_1761681593543.jpg", "ref_1761681679110.jpg", "ref_1761681679116.jpg", "ref_1761681693307.jpg", "ref_1761681693314.jpg", "ref_1761681696262.jpg", "ref_1761681714373.jpg", "ref_1761681747833.jpg", "ref_1761681767320.jpg", "ref_1761681767328.jpg", "ref_1761681781136.jpg", "ref_1761681798562.jpg", "ref_1761682276723.jpg", "ref_1761682276730.jpg", "ref_1761683611429.jpg", "ref_1761683656877.jpg", "ref_1761683656884.jpg", "ref_1761684422074.jpg", "ref_1761684422080.jpg", "ref_1761684425773.jpg", "ref_1761684425967.jpg", "ref_1761684426390.jpg", "ref_1761686305604.png", "ref_1761686845955.png", "ref_1761687073556.png", "ref_1761687106319.png", "ref_1761687650660.png", "ref_1761687775951.png", "ref_1761687877915.png", "ref_1761688081767.jpg", "ref_1761688081774.jpg", "ref_1761688086824.jpg", "ref_1761688087108.jpg", "ref_1761688361982.jpg", "ref_1761739664856.jpg", "ref_1761739664863.jpg", "ref_1761739668703.jpg", "ref_1761739668935.jpg", "ref_1761740201268.jpg", "ref_1761740317312.png", "ref_1761740752041.jpg", "ref_1761740752052.jpg", "ref_1761740756449.jpg", "ref_1761740759168.jpg", "ref_1761741246808.jpg", "ref_1761749379704.png", "ref_1761749379733.png", "ref_1761749909801.png", "ref_1761749909872.png", "ref_1762251976835.jpg", "ref_1762252055113.jpg", "ref_1762252063182.jpg", "ref_1762252073174.jpg", "ref_1762252083194.jpg", "ref_1762252091744.jpg", "ref_1762252100833.jpg", "ref_1762252109842.jpg", "ref_1762252116753.jpg", "ref_1762252135786.jpg", "ref_1762252146332.jpg", "ref_1762252164415.jpg", "ref_1762252175342.jpg", "ref_1762252182439.jpg", "ref_1762252192358.jpg", "ref_1762252200930.jpg", "ref_1762252209843.jpg", "ref_1762252219004.jpg", "ref_1762252227936.jpg", "ref_1762252237029.jpg", "ref_1762252246930.jpg", "ref_1762252255478.jpg", "ref_1762252266518.jpg", "ref_1762252275625.jpg", "ref_1762252284576.jpg", "ref_1762252303518.jpg", "ref_1762252312112.jpg", "ref_1762252321102.jpg", "ref_1762252330199.jpg", "ref_1762252341192.jpg", "ref_1762252358099.jpg", "ref_1762252366671.jpg", "ref_1762252377728.jpg", "ref_1762252386762.jpg", "ref_1762252395809.jpg", "ref_1762252404666.jpg", "ref_1762252414728.jpg", "ref_1762252423315.jpg", "ref_1762252432430.jpg", "ref_1762252441388.jpg", "ref_1762252452436.jpg", "ref_1762252461228.jpg", "ref_1762252471267.jpg", "ref_1762252480152.jpg", "ref_1762252488980.jpg", "ref_1762252499990.jpg", "ref_1762252509016.jpg", "ref_1762252518017.jpg", "ref_1762252527889.jpg", "ref_1762252536791.jpg", "ref_1762252545644.jpg", "ref_1762252556672.jpg", "ref_1762252565629.jpg", "ref_1762252574770.jpg", "ref_1762252584638.jpg", "ref_1762252593435.jpg", "ref_1762252604298.jpg", "ref_1762252613315.jpg", "ref_1762252622309.jpg", "ref_1762252641257.jpg", "ref_1762252652101.jpg", "ref_1762252660913.jpg", "ref_1762252669960.jpg", "ref_1762252680949.jpg", "ref_1762252687922.jpg", "ref_1762252697968.jpg", "ref_1762252708770.jpg", "ref_1762252717692.jpg", "ref_1762252726629.jpg", "ref_1762252737817.jpg", "ref_1762252756773.jpg", "ref_1762252765488.jpg", "ref_1762252776392.jpg", "ref_1762252785415.jpg", "ref_1762252794513.jpg", "ref_1762252802975.jpg", "ref_1762252813468.jpg", "ref_1762252822142.jpg", "ref_1762252833119.jpg", "ref_1762252842079.jpg", "ref_1762438257242.png", "ref_1762438266971.png", "ref_1762438267002.png", "ref_1762439055270.png", "ref_1762443459707.jpg", "ref_1762443459710.jpg", "ref_1762443631443.jpg", "ref_1762443633308.jpg", "ref_1762443703494.jpg", "ref_1762443707834.jpg", "ref_1762443707835.jpg", "ref_1762443707837.jpg", "ref_1762443875578.jpg", "ref_1762443945645.jpg", "ref_1762443951632.jpg", "ref_1762443952508.jpg", "ref_1762443991490.jpg", "ref_1762444001533.jpg", "ref_1762444012781.jpg", "ref_1762444022323.jpg", "ref_1762444033366.jpg", "ref_1762444044259.jpg", "ref_1762444055078.jpg", "ref_1762444067161.jpg", "ref_1762444078409.jpg", "ref_1762444090312.jpg", "ref_1762444101238.jpg", "ref_1762444111996.jpg", "ref_1762444134807.jpg", "ref_1762444146164.jpg", "ref_1762444157629.jpg", "ref_1762444179469.jpg", "ref_1762444190518.jpg", "ref_1762444200244.jpg", "ref_1762444211592.jpg", "ref_1762444223480.jpg", "ref_1762444231512.jpg", "ref_1762444242481.jpg", "ref_1762444253708.jpg", "ref_1762444265776.jpg", "ref_1762444277244.jpg", "ref_1762444289276.jpg", "ref_1762444301324.jpg", "ref_1762444312572.jpg", "ref_1762444323579.jpg", "ref_1762444335608.jpg", "ref_1762444346904.jpg", "ref_1762444358958.jpg", "ref_1762444371008.jpg", "ref_1762444382018.jpg", "ref_1762444393103.jpg", "ref_1762444405012.jpg", "ref_1762444416476.jpg", "ref_1762444428512.jpg", "ref_1762444440585.jpg", "ref_1762444451962.jpg", "ref_1762444462984.jpg", "ref_1762444475003.jpg", "ref_1762444486435.jpg", "ref_1762444498527.jpg", "ref_1762444522237.jpg", "ref_1762444533309.jpg", "ref_1762444544425.jpg", "ref_1762444556485.jpg", "ref_1762444568545.jpg", "ref_1762444577723.jpg", "ref_1762444589797.jpg", "ref_1762444611845.jpg", "ref_1762444623912.jpg", "ref_1762444635673.jpg", "ref_1762444647056.jpg", "ref_1762444659101.jpg", "ref_1762444667129.jpg", "ref_1762444679200.jpg", "ref_1762444691232.jpg", "ref_1762444703059.jpg", "ref_1762444712573.jpg", "ref_1762444726725.jpg", "ref_1762444738745.jpg", "ref_1762444750822.jpg", "ref_1762444762858.jpg", "ref_1762444772903.jpg", "ref_1762444784965.jpg", "ref_1762444796425.jpg", "ref_1762444808474.jpg", "ref_1762444820531.jpg", "ref_1762444832572.jpg", "ref_1762444844604.jpg", "ref_1762444856077.jpg", "ref_1762444867750.jpg", "ref_1762444879796.jpg", "ref_1762444891823.jpg", "ref_1762444903889.jpg", "ref_1762444915814.jpg", "ref_1762444927602.jpg", "ref_1762444939152.jpg", "ref_1762444951236.jpg", "ref_1762444961273.jpg", "ref_1762444973339.jpg", "ref_1762444985177.jpg", "ref_1762444996801.jpg", "ref_1762445008492.jpg", "ref_1762445020498.jpg", "ref_1762445032523.jpg", "ref_1762445042609.jpg", "ref_1762445054691.jpg", "ref_1762445066232.jpg", "ref_1762445078246.jpg", "ref_1762445090278.jpg", "ref_1762445102310.jpg", "ref_1762445114349.jpg", "ref_1762445126404.jpg", "ref_1762445138040.jpg", "ref_1762445149647.jpg", "ref_1762445161916.jpg", "ref_1762445173731.jpg", "ref_1762445185778.jpg", "ref_1762445195942.jpg", "ref_1762445207432.jpg", "ref_1762445219354.jpg", "ref_1762445231405.jpg", "ref_1762445243457.jpg", "ref_1762445255482.jpg", "ref_1762445267533.jpg", "ref_1762445279323.jpg", "ref_1762445290958.jpg", "ref_1762445303021.jpg", "ref_1762445315045.jpg", "ref_1762445327026.jpg", "ref_1762445339100.jpg", "ref_1762445350873.jpg", "ref_1762445362843.jpg", "ref_1762445374897.jpg", "ref_1762445398630.jpg", "ref_1762445410345.jpg", "ref_1762445422380.jpg", "ref_1762445434448.jpg", "ref_1762445446489.jpg", "ref_1762445456463.jpg", "ref_1762445468522.jpg", "ref_1762445480252.jpg", "ref_1762445492292.jpg", "ref_1762445504376.jpg", "ref_1762445516098.jpg", "ref_1762445528151.jpg", "ref_1762445540009.jpg", "ref_1762445551897.jpg", "ref_1762445563939.jpg", "ref_1762445575990.jpg", "ref_1762445587717.jpg", "ref_1762445599778.jpg", "ref_1762445611549.jpg", "ref_1762445623284.jpg", "ref_1762445635360.jpg", "ref_1762445646572.jpg", "ref_1762445658097.jpg", "ref_1762445670141.jpg", "ref_1762445682203.jpg", "ref_1762445693803.jpg", "ref_1762445705858.jpg", "ref_1762445729985.jpg", "ref_1762445741738.jpg", "ref_1762445753631.jpg", "ref_1762445765462.jpg", "ref_1762445777540.jpg", "ref_1762445787570.jpg", "ref_1762445799561.jpg", "ref_1762445811621.jpg", "ref_1762445823663.jpg", "ref_1762445835103.jpg", "ref_1762445845048.jpg", "ref_1762445857003.jpg", "ref_1762445869069.jpg", "ref_1762445881125.jpg", "ref_1762445893179.jpg", "ref_1762445904715.jpg", "ref_1762445916759.jpg", "ref_1762445927253.jpg", "ref_1762445939295.jpg", "ref_1762445951361.jpg", "ref_1762445963398.jpg", "ref_1762445974550.jpg", "ref_1762445986614.jpg", "ref_1762445998653.jpg", "ref_1762446010886.jpg", "ref_1762446022728.jpg", "ref_1762446034762.jpg", "ref_1762446046509.jpg", "ref_1762446056538.jpg", "ref_1762446068693.jpg", "ref_1762446082438.jpg", "ref_1762446094496.jpg", "ref_1762446106550.jpg", "ref_1762446118609.jpg", "ref_1762446130648.jpg", "ref_1762446142717.jpg", "ref_1762446154447.jpg", "ref_1762446166498.jpg", "ref_1762446180660.jpg", "ref_1762446192750.jpg", "ref_1762446204807.jpg", "ref_1762446216831.jpg", "ref_1762446228871.jpg", "ref_1762446240893.jpg", "ref_1762446252507.jpg", "ref_1762446264572.jpg", "ref_1762446276607.jpg", "ref_1762446288514.jpg", "ref_1762446300488.jpg", "ref_1762446312422.jpg", "ref_1762446324019.jpg", "ref_1762446336032.jpg", "ref_1762446348066.jpg", "ref_1762446360082.jpg", "ref_1762446372144.jpg", "ref_1762446384202.jpg", "ref_1762446396077.jpg", "ref_1762446408127.jpg", "ref_1762446420167.jpg", "ref_1762446432087.jpg", "ref_1762446444161.jpg", "ref_1762446456210.jpg", "ref_1762446468923.jpg", "ref_1762446480309.jpg", "ref_1762446492192.jpg", "ref_1762446504256.jpg", "ref_1762446516291.jpg", "ref_1762446528436.jpg", "ref_1762446540494.jpg", "ref_1762446552427.jpg", "ref_1762446564492.jpg", "ref_1762446576529.jpg", "ref_1762446588659.jpg", "ref_1762446602828.jpg", "ref_1762446614862.jpg", "ref_1762446626946.jpg", "ref_1762446638998.jpg", "ref_1762446651024.jpg", "ref_1762446663089.jpg", "ref_1762446677153.jpg", "ref_1762446689232.jpg", "ref_1762446701267.jpg", "ref_1762446713331.jpg", "ref_1762446725376.jpg", "ref_1762446737444.jpg", "ref_1762446749696.jpg", "ref_1762446761747.jpg", "ref_1762446773814.jpg", "ref_1762446785861.jpg", "ref_1762446797909.jpg", "ref_1762446811991.jpg", "ref_1762446824032.jpg", "ref_1762446836106.jpg", "ref_1762446850117.jpg", "ref_1762446862155.jpg", "ref_1762446874231.jpg", "ref_1762446886263.jpg", "ref_1762446898322.jpg", "ref_1762446912362.jpg", "ref_1762446924301.jpg", "ref_1762446934442.jpg", "ref_1762446946577.jpg", "ref_1762446960909.jpg", "ref_1762446972958.jpg", "ref_1762446985029.jpg", "ref_1762446997100.jpg", "ref_1762447009172.jpg", "ref_1762447021244.jpg", "ref_1762447033298.jpg", "ref_1762447045366.jpg", "ref_1762447057390.jpg", "ref_1762447069446.jpg", "ref_1762447081323.jpg", "ref_1762447093377.jpg", "ref_1762447105452.jpg", "ref_1762447117506.jpg", "ref_1762447129545.jpg", "ref_1762447141585.jpg", "ref_1762447165673.jpg", "ref_1762447177736.jpg", "ref_1762447190196.jpg", "ref_1762447202243.jpg", "ref_1762447214302.jpg", "ref_1762447224347.jpg", "ref_1762447234395.jpg", "ref_1762447246443.jpg", "ref_1762447260775.jpg", "ref_1762447272826.jpg", "ref_1762447284879.jpg", "ref_1762447296926.jpg", "ref_1762447310990.jpg", "ref_1762447323058.jpg", "ref_1762447335010.jpg", "ref_1762447347141.jpg", "ref_1762447359265.jpg", "ref_1762447373687.jpg", "ref_1762447385746.jpg", "ref_1762447397802.jpg", "ref_1762447410029.jpg", "ref_1762447422099.jpg", "ref_1762447436132.jpg", "ref_1762447448170.jpg", "ref_1762447460493.jpg", "ref_1762447474566.jpg", "ref_1762447486606.jpg", "ref_1762447498680.jpg", "ref_1762447510736.jpg", "ref_1762447522850.jpg", "ref_1762447536728.jpg", "ref_1762447548711.jpg", "ref_1762447560749.jpg", "ref_1762447572766.jpg", "ref_1762447584846.jpg", "ref_1762447599428.jpg", "ref_1762447611506.jpg", "ref_1762447623554.jpg", "ref_1762447635591.jpg", "ref_1762447647705.jpg", "ref_1762447662180.jpg", "ref_1762447674224.jpg", "ref_1762447686272.jpg", "ref_1762447698335.jpg", "ref_1762447712775.jpg", "ref_1762447724837.jpg", "ref_1762447736877.jpg", "ref_1762447748947.jpg", "ref_1762447761259.jpg", "ref_1762447775306.jpg", "ref_1762447787359.jpg", "ref_1762447799419.jpg", "ref_1762447811469.jpg", "ref_1762447825588.jpg", "ref_1762447837608.jpg", "ref_1762447863776.jpg", "ref_1762447875814.jpg", "ref_1762447887857.jpg", "ref_1762447902551.jpg", "ref_1762447914594.jpg", "ref_1762447922632.jpg", "ref_1762447934699.jpg", "ref_1762447946746.jpg", "ref_1762447958832.jpg", "ref_1762447970734.jpg", "ref_1762447985097.jpg", "ref_1762447997153.jpg", "ref_1762448007203.jpg", "ref_1762448019260.jpg", "ref_1762448031322.jpg", "ref_1762448043373.jpg", "ref_1762448054803.jpg", "ref_1762448066863.jpg", "ref_1762448079539.jpg", "ref_1762448094111.jpg", "ref_1762448106191.jpg", "ref_1762448118780.jpg", "ref_1762448132975.jpg", "ref_1762448145019.jpg", "ref_1762448157107.jpg", "ref_1762448171564.jpg", "ref_1762448181585.jpg", "ref_1762448193642.jpg", "ref_1762448207959.jpg", "ref_1762448220283.jpg", "ref_1762448232365.jpg", "ref_1762448246538.jpg", "ref_1762448258822.jpg", "ref_1762448271334.jpg", "ref_1762448285406.jpg", "ref_1762448297458.jpg", "ref_1762448309512.jpg", "ref_1762448323681.jpg", "ref_1762448335727.jpg", "ref_1762448348344.jpg", "ref_1762448362967.jpg", "ref_1762448375026.jpg", "ref_1762448387087.jpg", "ref_1762448399134.jpg", "ref_1762448411161.jpg", "ref_1762448423259.jpg", "ref_1762448435304.jpg", "ref_1762448449833.jpg", "ref_1762448461893.jpg", "ref_1762448476154.jpg", "ref_1762448488448.jpg", "ref_1762448501086.jpg", "ref_1762448515570.jpg", "ref_1762448527640.jpg", "ref_1762448542454.jpg", "ref_1762448554526.jpg", "ref_1762448566632.jpg", "ref_1762448579260.jpg", "ref_1762448593712.jpg", "ref_1762448605733.jpg", "ref_1762448617790.jpg", "ref_1762448629824.jpg", "ref_1762448644087.jpg", "ref_1762448654372.jpg", "ref_1762448666447.jpg", "ref_1762448680882.jpg", "ref_1762448692910.jpg", "ref_1762448704944.jpg", "ref_1762448717348.jpg", "ref_1762448731401.jpg", "ref_1762448743616.jpg", "ref_1762448755791.jpg", "ref_1762448768441.jpg", "ref_1762448780476.jpg", "ref_1762448794712.jpg", "ref_1762448806727.jpg", "ref_1762448819276.jpg", "ref_1762448833551.jpg", "ref_1762448845610.jpg", "ref_1762448858138.jpg", "ref_1762448870267.jpg", "ref_1762448884517.jpg", "ref_1762448896591.jpg", "ref_1762448908620.jpg", "ref_1762448920687.jpg", "ref_1762448935034.jpg", "ref_1762448947107.jpg", "ref_1762448959456.jpg", "ref_1762448971523.jpg", "ref_1762448983601.jpg", "ref_1762448995757.jpg", "ref_1762449010391.jpg", "ref_1762449022454.jpg", "ref_1762449034497.jpg", "ref_1762449046548.jpg", "ref_1762449061276.jpg", "ref_1762449073322.jpg", "ref_1762449085377.jpg", "ref_1762449097671.jpg", "ref_1762449110097.jpg", "ref_1762449124414.jpg", "ref_1762449136460.jpg", "ref_1762449148485.jpg", "ref_1762449160556.jpg", "ref_1762449172729.jpg", "ref_1762449184785.jpg", "ref_1762449199260.jpg", "ref_1762449211912.jpg", "ref_1762449226075.jpg", "ref_1762449239039.jpg", "ref_1762449251027.jpg", "ref_1762449263167.jpg", "ref_1762449275508.jpg", "ref_1762449289829.jpg", "ref_1762449302028.jpg", "ref_1762449316212.jpg", "ref_1762449326261.jpg", "ref_1762449340929.jpg", "ref_1762449352972.jpg", "ref_1762449365035.jpg", "ref_1762449377064.jpg", "ref_1762449391456.jpg", "ref_1762449403764.jpg", "ref_1762449417850.jpg", "ref_1762449429904.jpg", "ref_1762449441971.jpg", "ref_1762449456019.jpg", "ref_1762449466058.jpg", "ref_1762449478126.jpg", "ref_1762449493213.jpg", "ref_1762449505257.jpg", "ref_1762449517319.jpg", "ref_1762449530337.jpg", "ref_1762449542622.jpg", "ref_1762449556858.jpg", "ref_1762449568916.jpg", "ref_1762449580967.jpg", "ref_1762449593028.jpg", "ref_1762449605111.jpg", "ref_1762449617289.jpg", "ref_1762449629364.jpg", "ref_1762449644207.jpg", "ref_1762449654351.jpg", "ref_1762449669047.jpg", "ref_1762449681706.jpg", "ref_1762449694111.jpg", "ref_1762449708303.jpg", "ref_1762449720342.jpg", "ref_1762449732456.jpg", "ref_1762449746560.jpg", "ref_1762449758571.jpg", "ref_1762449770629.jpg", "ref_1762449784710.jpg", "ref_1762449796747.jpg", "ref_1762449808995.jpg", "ref_1762449823901.jpg", "ref_1762449835918.jpg", "ref_1762449848003.jpg", "ref_1762449860064.jpg", "ref_1762449874712.jpg", "ref_1762449886744.jpg", "ref_1762449898827.jpg", "ref_1762449911411.jpg", "ref_1762449923461.jpg", "ref_1762449935520.jpg", "ref_1762449949566.jpg", "ref_1762449962251.jpg", "ref_1762449976884.jpg", "ref_1762449989160.jpg", "ref_1762450001207.jpg", "ref_1762450013265.jpg", "ref_1762450025306.jpg", "ref_1762450037498.jpg", "ref_1762450051590.jpg", "ref_1762450063929.jpg", "ref_1762450078019.jpg", "ref_1762450090905.jpg", "ref_1762450105357.jpg", "ref_1762450117423.jpg", "ref_1762450127525.jpg", "ref_1762450139573.jpg", "ref_1762450151646.jpg", "ref_1762450163693.jpg", "ref_1762450175733.jpg", "ref_1762450190186.jpg", "ref_1762450202382.jpg", "ref_1762450214529.jpg", "ref_1762450228870.jpg", "ref_1762450241672.jpg", "ref_1762450255973.jpg", "ref_1762450268426.jpg", "ref_1762450281395.jpg", "ref_1762450295930.jpg", "ref_1762450308128.jpg", "ref_1762450321161.jpg", "ref_1762450335893.jpg", "ref_1762450348330.jpg", "ref_1762450363562.jpg", "ref_1762450375712.jpg", "ref_1762450388428.jpg", "ref_1762450403229.jpg", "ref_1762450415597.jpg", "ref_1762450427955.jpg", "ref_1762450443689.jpg", "ref_1762450456197.jpg", "ref_1762450468813.jpg", "ref_1762450483593.jpg", "ref_1762450495785.jpg", "ref_1762450509078.jpg", "ref_1762450521138.jpg", "ref_1762450535544.jpg", "ref_1762450547812.jpg", "ref_1762450560448.jpg", "ref_1762450575588.jpg", "ref_1762450587892.jpg", "ref_1762450602755.jpg", "ref_1762450615126.jpg", "ref_1762450627541.jpg", "ref_1762450642668.jpg", "ref_1762450654880.jpg", "ref_1762450669243.jpg", "ref_1762450681752.jpg", "ref_1762450696253.jpg", "ref_1762450709034.jpg", "ref_1762450724239.jpg", "ref_1762450736555.jpg", "ref_1762450749622.jpg", "ref_1762450762308.jpg", "ref_1762450776712.jpg", "ref_1762450789246.jpg", "ref_1762450802100.jpg", "ref_1762450814542.jpg", "ref_1762450829252.jpg", "ref_1762450842329.jpg", "ref_1762450857043.jpg", "ref_1762450869664.jpg", "ref_1762450882406.jpg", "ref_1762450896808.jpg", "ref_1762450908882.jpg", "ref_1762450922106.jpg", "ref_1762450949142.jpg", "ref_1762450964304.jpg", "ref_1762450976510.jpg", "ref_1762450989273.jpg", "ref_1762451003967.jpg", "ref_1762451011990.jpg", "ref_1762451024520.jpg", "ref_1762451038868.jpg", "ref_1762451051502.jpg", "ref_1762451066460.jpg", "ref_1762451079625.jpg", "ref_1762451094605.jpg", "ref_1762451106768.jpg", "ref_1762451119570.jpg", "ref_1762451134396.jpg", "ref_1762451146919.jpg", "ref_1762451159759.jpg", "ref_1762451174740.jpg", "ref_1762451187066.jpg", "ref_1762451200142.jpg", "ref_1762451215325.jpg", "ref_1762451227957.jpg", "ref_1762451243178.jpg", "ref_1762451255503.jpg", "ref_1762451269690.jpg", "ref_1762451281997.jpg", "ref_1762451294488.jpg", "ref_1762451307197.jpg", "ref_1762451322618.jpg", "ref_1762451334914.jpg", "ref_1762451347123.jpg", "ref_1762451360253.jpg", "ref_1762451375381.jpg", "ref_1762451387541.jpg", "ref_1762451401313.jpg", "ref_1762451415940.jpg", "ref_1762451428392.jpg", "ref_1762451441593.jpg", "ref_1762451456415.jpg", "ref_1762451468712.jpg", "ref_1762451484008.jpg", "ref_1762451496531.jpg", "ref_1762451509219.jpg", "ref_1762451524628.jpg", "ref_1762451537023.jpg", "ref_1762451549936.jpg", "ref_1762451564759.jpg", "ref_1762451577454.jpg", "ref_1762451590427.jpg", "ref_1762451603592.jpg", "ref_1762451618065.jpg", "ref_1762451631062.jpg", "ref_1762451644027.jpg", "ref_1762451658926.jpg", "ref_1762451671909.jpg", "ref_1762451685995.jpg", "ref_1762451700810.jpg", "ref_1762451714005.jpg", "ref_1762451726340.jpg", "ref_1762451738699.jpg", "ref_1762451754504.jpg", "ref_1762451766932.jpg", "ref_1762451779918.jpg", "ref_1762451792985.jpg", "ref_1762451807801.jpg", "ref_1762451820750.jpg", "ref_1762451833555.jpg", "ref_1762451846425.jpg", "ref_1762451861485.jpg", "ref_1762451874447.jpg", "ref_1762451887216.jpg", "ref_1762451902530.jpg", "ref_1762451915295.jpg", "ref_1762451928060.jpg", "ref_1762451943771.jpg", "ref_1762451956204.jpg", "ref_1762451969346.jpg", "ref_1762451985154.jpg", "ref_1762451997717.jpg", "ref_1762452012070.jpg", "ref_1762452025374.jpg", "ref_1762452039642.jpg", "ref_1762452052321.jpg", "ref_1762452065069.jpg", "ref_1762452079322.jpg", "ref_1762452092490.jpg", "ref_1762452105651.jpg", "ref_1762452120518.jpg", "ref_1762452133693.jpg", "ref_1762452146183.jpg", "ref_1762452160871.jpg", "ref_1762452173127.jpg", "ref_1762452185547.jpg", "ref_1762452200524.jpg", "ref_1762452213935.jpg", "ref_1762452228696.jpg", "ref_1762452240758.jpg", "ref_1762452252911.jpg", "ref_1762452264970.jpg", "ref_1762452277056.jpg", "ref_1762452289392.jpg", "ref_1762452303765.jpg", "ref_1762452315878.jpg", "ref_1762452328040.jpg", "ref_1762452342804.jpg", "ref_1762452354859.jpg", "ref_1762452367158.jpg", "ref_1762452381594.jpg", "ref_1762452394229.jpg", "ref_1762452408506.jpg", "ref_1762452420866.jpg", "ref_1762452447311.jpg", "ref_1762452459614.jpg", "ref_1762452472036.jpg", "ref_1762452486241.jpg", "ref_1762452498297.jpg", "ref_1762452508355.jpg", "ref_1762452520567.jpg", "ref_1762452532601.jpg", "ref_1762452544926.jpg", "ref_1762452559658.jpg", "ref_1762452572148.jpg", "ref_1762452586421.jpg", "ref_1762452598485.jpg", "ref_1762452610565.jpg", "ref_1762452623286.jpg", "ref_1762452637761.jpg", "ref_1762452649945.jpg", "ref_1762452662002.jpg", "ref_1762452676089.jpg", "ref_1762452688542.jpg", "ref_1762452700978.jpg", "ref_1762452716234.jpg", "ref_1762452728404.jpg", "ref_1762452740900.jpg", "ref_1762452753691.jpg", "ref_1762452768492.jpg", "ref_1762452780931.jpg", "ref_1762452793894.jpg", "ref_1762452808237.jpg", "ref_1762452820850.jpg", "ref_1762452834029.jpg", "ref_1762452848295.jpg", "ref_1762452860843.jpg", "ref_1762452873706.jpg", "ref_1762453036570.jpg", "ref_1762453036571.jpg", "ref_1762453036572.jpg", "ref_1762453036573.jpg", "ref_1762453036574.jpg", "ref_1762453036575.jpg", "ref_1762454953198.jpg", "ref_1762455024253.jpg", "ref_1762455831475.jpg", "ref_1762456165537.jpg", "ref_1762456573729.jpg", "ref_1762456576673.jpg", "ref_1762456592425.jpg", "ref_1762458765274.png", "ref_1762458780333.png", "ref_1762464249852.jpg", "ref_1762464434323.jpg", "ref_1762464627359.jpg", "ref_1762464647010.jpg", "ref_1762465007312.jpg", "ref_1762465081879.jpg", "ref_1762465088858.jpg", "ref_1762465766186.jpg", "ref_1762466033944.jpg", "ref_1762466043071.jpg", "ref_1762473375285.jpg", "ref_1762473378810.jpg", "ref_1762507814234.jpg", "ref_1762507942484.jpg", "ref_1762507989054.jpg", "ref_1762507990800.jpg", "ref_1762507992606.jpg", "ref_1762507994526.jpg", "ref_1762508084658.jpg", "ref_1762508129831.jpg", "ref_1762508270339.jpg", "ref_1762508270344.jpg", "ref_1762508270355.jpg", "ref_1762508270356.jpg", "ref_1762508270357.jpg", "ref_1762508270359.jpg", "ref_1762508472509.jpg", "ref_1762508472510.jpg", "ref_1762508472513.jpg", "ref_1762508472537.png", "ref_1762508472543.jpg", "ref_1762508472614.jpg", "ref_1762508715452.jpg", "ref_1762508715453.jpg", "ref_1762508715456.jpg", "ref_1762508715457.jpg", "ref_1762508715488.jpg", "ref_1762508918266.jpg", "ref_1762508918267.jpg", "ref_1762508918271.png", "ref_1762508918396.png", "ref_1762610690186.jpg", "ref_1762610703432.jpg", "ref_1762610869026.jpg", "ref_1762610905799.jpg", "ref_1762611796957.jpg", "ref_1762611840088.jpg", "ref_1762611847572.jpg", "ref_1762613110379.jpg", "ref_1762623498508.jpg", "ref_1762623534202.jpg", "ref_1762624829793.jpg", "ref_1762712436781.jpg", "ref_1762712537658.jpg", "ref_1762712636344.jpg", "ref_1762712640022.jpg", "ref_1762712680434.jpg", "ref_1762713120552.jpg", "ref_1762713661762.jpg", "ref_1762717812308.jpg", "ref_1762720601884.jpg", "ref_1762721161257.jpg"], {"image_upload": true}], "channel": [["alpha", "red", "green", "blue"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "LoadImageMask", "display_name": "Load Image (as Mask)", "description": "", "python_module": "nodes", "category": "mask", "output_node": false}, "LoadImageOutput": {"input": {"required": {"image": ["COMBO", {"image_upload": true, "image_folder": "output", "remote": {"route": "/internal/files/output", "refresh_button": true, "control_after_refresh": "first"}}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "LoadImageOutput", "display_name": "Load Image (from Outputs)", "description": "Load an image from the output folder. When the refresh button is clicked, the node will update the image list and automatically select the first image, allowing for easy iteration.", "python_module": "nodes", "category": "image", "output_node": false, "experimental": true}, "ImageScale": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "width": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["image", "upscale_method", "width", "height", "crop"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScale", "display_name": "Upscale Image", "description": "", "python_module": "nodes", "category": "image/upscaling", "output_node": false}, "ImageScaleBy": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "scale_by": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 8.0, "step": 0.01}]}}, "input_order": {"required": ["image", "upscale_method", "scale_by"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScaleBy", "display_name": "Upscale Image By", "description": "", "python_module": "nodes", "category": "image/upscaling", "output_node": false}, "ImageInvert": {"input": {"required": {"image": ["IMAGE"]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageInvert", "display_name": "Invert Image", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ImageBatch": {"input": {"required": {"image1": ["IMAGE"], "image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageBatch", "display_name": "Batch Images", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ImagePadForOutpaint": {"input": {"required": {"image": ["IMAGE"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feathering": ["INT", {"default": 40, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "left", "top", "right", "bottom", "feathering"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "name": "ImagePadForOutpaint", "display_name": "Pad Image for Outpainting", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "EmptyImage": {"input": {"required": {"width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "color": ["INT", {"default": 0, "min": 0, "max": 16777215, "step": 1, "display": "color"}]}}, "input_order": {"required": ["width", "height", "batch_size", "color"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "EmptyImage", "display_name": "EmptyImage", "description": "", "python_module": "nodes", "category": "image", "output_node": false}, "ConditioningAverage": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "conditioning_from": ["CONDITIONING"], "conditioning_to_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning_to", "conditioning_from", "conditioning_to_strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningAverage", "display_name": "ConditioningAverage", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningCombine": {"input": {"required": {"conditioning_1": ["CONDITIONING"], "conditioning_2": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_1", "conditioning_2"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningCombine", "display_name": "Conditioning (Combine)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningConcat": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "conditioning_from": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning_to", "conditioning_from"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningConcat", "display_name": "Conditioning (Concat)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetArea": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["INT", {"default": 64, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 64, "min": 64, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "x", "y", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetArea", "display_name": "Conditioning (Set Area)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetAreaPercentage": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "height": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "x", "y", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaPercentage", "display_name": "Conditioning (Set Area with Percentage)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetAreaStrength": {"input": {"required": {"conditioning": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaStrength", "display_name": "ConditioningSetAreaStrength", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ConditioningSetMask": {"input": {"required": {"conditioning": ["CONDITIONING"], "mask": ["MASK"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}}, "input_order": {"required": ["conditioning", "mask", "strength", "set_cond_area"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetMask", "display_name": "Conditioning (Set Mask)", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "KSamplerAdvanced": {"input": {"required": {"model": ["MODEL"], "add_noise": [["enable", "disable"]], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "latent_image": ["LATENT"], "start_at_step": ["INT", {"default": 0, "min": 0, "max": 10000}], "end_at_step": ["INT", {"default": 10000, "min": 0, "max": 10000}], "return_with_leftover_noise": [["disable", "enable"]]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "steps", "cfg", "sampler_name", "scheduler", "positive", "negative", "latent_image", "start_at_step", "end_at_step", "return_with_leftover_noise"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "KSamplerAdvanced", "display_name": "KSampler (Advanced)", "description": "", "python_module": "nodes", "category": "sampling", "output_node": false}, "SetLatentNoiseMask": {"input": {"required": {"samples": ["LATENT"], "mask": ["MASK"]}}, "input_order": {"required": ["samples", "mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "SetLatentNoiseMask", "display_name": "Set Latent Noise Mask", "description": "", "python_module": "nodes", "category": "latent/inpaint", "output_node": false}, "LatentComposite": {"input": {"required": {"samples_to": ["LATENT"], "samples_from": ["LATENT"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "feather": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["samples_to", "samples_from", "x", "y", "feather"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentComposite", "display_name": "Latent Composite", "description": "", "python_module": "nodes", "category": "latent", "output_node": false}, "LatentBlend": {"input": {"required": {"samples1": ["LATENT"], "samples2": ["LATENT"], "blend_factor": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["samples1", "samples2", "blend_factor"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentBlend", "display_name": "Latent Blend", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "LatentRotate": {"input": {"required": {"samples": ["LATENT"], "rotation": [["none", "90 degrees", "180 degrees", "270 degrees"]]}}, "input_order": {"required": ["samples", "rotation"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentRotate", "display_name": "Rotate Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LatentFlip": {"input": {"required": {"samples": ["LATENT"], "flip_method": [["x-axis: vertically", "y-axis: horizontally"]]}}, "input_order": {"required": ["samples", "flip_method"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentFlip", "display_name": "Flip Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LatentCrop": {"input": {"required": {"samples": ["LATENT"], "width": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["samples", "width", "height", "x", "y"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentCrop", "display_name": "Crop Latent", "description": "", "python_module": "nodes", "category": "latent/transform", "output_node": false}, "LoraLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "clip": ["CLIP", {"tooltip": "The CLIP model the LoRA will be applied to."}], "lora_name": [[], {"tooltip": "The name of the LoRA."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the CLIP model. This value can be negative."}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"]}, "output": ["MODEL", "CLIP"], "output_is_list": [false, false], "output_name": ["MODEL", "CLIP"], "name": "LoraLoader", "display_name": "Load LoRA", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "CLIPLoader": {"input": {"required": {"clip_name": [[]], "type": [["stable_diffusion", "stable_cascade", "sd3", "stable_audio", "mochi", "ltxv", "pixart", "cosmos", "lumina2", "wan", "hidream", "chroma", "ace", "omnigen2", "qwen_image", "hunyuan_image"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["clip_name", "type"], "optional": ["device"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPLoader", "display_name": "Load CLIP", "description": "[Recipes]\n\nstable_diffusion: clip-l\nstable_cascade: clip-g\nsd3: t5 xxl/ clip-g / clip-l\nstable_audio: t5 base\nmochi: t5 xxl\ncosmos: old t5 xxl\nlumina2: gemma 2 2B\nwan: umt5 xxl\n hidream: llama-3.1 (Recommend) or t5\nomnigen2: qwen vl 2.5 3B", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "UNETLoader": {"input": {"required": {"unet_name": [[]], "weight_dtype": [["default", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2"]]}}, "input_order": {"required": ["unet_name", "weight_dtype"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "UNETLoader", "display_name": "Load Diffusion Model", "description": "", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "DualCLIPLoader": {"input": {"required": {"clip_name1": [[]], "clip_name2": [[]], "type": [["sdxl", "sd3", "flux", "hunyuan_video", "hidream", "hunyuan_image"]]}, "optional": {"device": [["default", "cpu"], {"advanced": true}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "type"], "optional": ["device"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "DualCLIPLoader", "display_name": "DualCLIPLoader", "description": "[Recipes]\n\nsdxl: clip-l, clip-g\nsd3: clip-l, clip-g / clip-l, t5 / clip-g, t5\nflux: clip-l, t5\nhidream: at least one of t5 or llama, recommended t5 and llama\nhunyuan_image: qwen2.5vl 7b and byt5 small", "python_module": "nodes", "category": "advanced/loaders", "output_node": false}, "CLIPVisionEncode": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "image": ["IMAGE"], "crop": [["center", "none"]]}}, "input_order": {"required": ["clip_vision", "image", "crop"]}, "output": ["CLIP_VISION_OUTPUT"], "output_is_list": [false], "output_name": ["CLIP_VISION_OUTPUT"], "name": "CLIPVisionEncode", "display_name": "CLIP Vision Encode", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "StyleModelApply": {"input": {"required": {"conditioning": ["CONDITIONING"], "style_model": ["STYLE_MODEL"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_type": [["multiply", "attn_bias"]]}}, "input_order": {"required": ["conditioning", "style_model", "clip_vision_output", "strength", "strength_type"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "StyleModelApply", "display_name": "Apply Style Model", "description": "", "python_module": "nodes", "category": "conditioning/style_model", "output_node": false}, "unCLIPConditioning": {"input": {"required": {"conditioning": ["CONDITIONING"], "clip_vision_output": ["CLIP_VISION_OUTPUT"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "noise_augmentation": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "clip_vision_output", "strength", "noise_augmentation"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "unCLIPConditioning", "display_name": "unCLIPConditioning", "description": "", "python_module": "nodes", "category": "conditioning", "output_node": false}, "ControlNetApply": {"input": {"required": {"conditioning": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "control_net", "image", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ControlNetApply", "display_name": "Apply ControlNet (OLD)", "description": "", "python_module": "nodes", "category": "conditioning/controlnet", "output_node": false, "deprecated": true}, "ControlNetApplyAdvanced": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "control_net": ["CONTROL_NET"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"vae": ["VAE"]}}, "input_order": {"required": ["positive", "negative", "control_net", "image", "strength", "start_percent", "end_percent"], "optional": ["vae"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ControlNetApplyAdvanced", "display_name": "Apply ControlNet", "description": "", "python_module": "nodes", "category": "conditioning/controlnet", "output_node": false}, "ControlNetLoader": {"input": {"required": {"control_net_name": [[]]}}, "input_order": {"required": ["control_net_name"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "ControlNetLoader", "display_name": "Load ControlNet Model", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "DiffControlNetLoader": {"input": {"required": {"model": ["MODEL"], "control_net_name": [[]]}}, "input_order": {"required": ["model", "control_net_name"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "name": "DiffControlNetLoader", "display_name": "Load ControlNet Model (diff)", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "StyleModelLoader": {"input": {"required": {"style_model_name": [[]]}}, "input_order": {"required": ["style_model_name"]}, "output": ["STYLE_MODEL"], "output_is_list": [false], "output_name": ["STYLE_MODEL"], "name": "StyleModelLoader", "display_name": "Load Style Model", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "CLIPVisionLoader": {"input": {"required": {"clip_name": [[]]}}, "input_order": {"required": ["clip_name"]}, "output": ["CLIP_VISION"], "output_is_list": [false], "output_name": ["CLIP_VISION"], "name": "CLIPVisionLoader", "display_name": "Load CLIP Vision", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "VAEDecodeTiled": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 32}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to decode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}}, "input_order": {"required": ["samples", "vae", "tile_size", "overlap", "temporal_size", "temporal_overlap"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VAEDecodeTiled", "display_name": "VAE Decode (Tiled)", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "VAEEncodeTiled": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "tile_size": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 64}], "overlap": ["INT", {"default": 64, "min": 0, "max": 4096, "step": 32}], "temporal_size": ["INT", {"default": 64, "min": 8, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to encode at a time."}], "temporal_overlap": ["INT", {"default": 8, "min": 4, "max": 4096, "step": 4, "tooltip": "Only used for video VAEs: Amount of frames to overlap."}]}}, "input_order": {"required": ["pixels", "vae", "tile_size", "overlap", "temporal_size", "temporal_overlap"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeTiled", "display_name": "VAE Encode (Tiled)", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "unCLIPCheckpointLoader": {"input": {"required": {"ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE", "CLIP_VISION"], "output_is_list": [false, false, false, false], "output_name": ["MODEL", "CLIP", "VAE", "CLIP_VISION"], "name": "unCLIPCheckpointLoader", "display_name": "unCLIPCheckpointLoader", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "GLIGENLoader": {"input": {"required": {"gligen_name": [[]]}}, "input_order": {"required": ["gligen_name"]}, "output": ["GLIGEN"], "output_is_list": [false], "output_name": ["GLIGEN"], "name": "GLIGENLoader", "display_name": "GLIGENLoader", "description": "", "python_module": "nodes", "category": "loaders", "output_node": false}, "GLIGENTextBoxApply": {"input": {"required": {"conditioning_to": ["CONDITIONING"], "clip": ["CLIP"], "gligen_textbox_model": ["GLIGEN"], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "width": ["INT", {"default": 64, "min": 8, "max": 16384, "step": 8}], "height": ["INT", {"default": 64, "min": 8, "max": 16384, "step": 8}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}]}}, "input_order": {"required": ["conditioning_to", "clip", "gligen_textbox_model", "text", "width", "height", "x", "y"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "GLIGENTextBoxApply", "display_name": "GLIGENTextBoxApply", "description": "", "python_module": "nodes", "category": "conditioning/gligen", "output_node": false}, "InpaintModelConditioning": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "vae": ["VAE"], "pixels": ["IMAGE"], "mask": ["MASK"], "noise_mask": ["BOOLEAN", {"default": true, "tooltip": "Add a noise mask to the latent so sampling will only happen within the mask. Might improve results or completely break things depending on the model."}]}}, "input_order": {"required": ["positive", "negative", "vae", "pixels", "mask", "noise_mask"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "InpaintModelConditioning", "display_name": "InpaintModelConditioning", "description": "", "python_module": "nodes", "category": "conditioning/inpaint", "output_node": false}, "CheckpointLoader": {"input": {"required": {"config_name": [[]], "ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]]}}, "input_order": {"required": ["config_name", "ckpt_name"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoader", "display_name": "Load Checkpoint With Config (DEPRECATED)", "description": "", "python_module": "nodes", "category": "advanced/loaders", "output_node": false, "deprecated": true}, "DiffusersLoader": {"input": {"required": {"model_path": [[]]}}, "input_order": {"required": ["model_path"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "DiffusersLoader", "display_name": "DiffusersLoader", "description": "", "python_module": "nodes", "category": "advanced/loaders/deprecated", "output_node": false}, "LoadLatent": {"input": {"required": {"latent": [[]]}}, "input_order": {"required": ["latent"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LoadLatent", "display_name": "LoadLatent", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": false}, "SaveLatent": {"input": {"required": {"samples": ["LATENT"], "filename_prefix": ["STRING", {"default": "latents/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["samples", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveLatent", "display_name": "SaveLatent", "description": "", "python_module": "nodes", "category": "_for_testing", "output_node": true}, "ConditioningZeroOut": {"input": {"required": {"conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningZeroOut", "display_name": "ConditioningZeroOut", "description": "", "python_module": "nodes", "category": "advanced/conditioning", "output_node": false}, "ConditioningSetTimestepRange": {"input": {"required": {"conditioning": ["CONDITIONING"], "start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["conditioning", "start", "end"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetTimestepRange", "display_name": "ConditioningSetTimestepRange", "description": "", "python_module": "nodes", "category": "advanced/conditioning", "output_node": false}, "LoraLoaderModelOnly": {"input": {"required": {"model": ["MODEL"], "lora_name": [[]], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "lora_name", "strength_model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoraLoaderModelOnly", "display_name": "LoraLoaderModelOnly", "description": "LoRAs are used to modify diffusion and CLIP models, altering the way in which latents are denoised such as applying styles. Multiple LoRA nodes can be linked together.", "python_module": "nodes", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model.", "The modified CLIP model."]}, "LatentAdd": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentAdd", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentSubtract": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentSubtract", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentMultiply": {"input": {"required": {"samples": ["LATENT", {}], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["samples", "multiplier"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentInterpolate": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["samples1", "samples2", "ratio"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentInterpolate", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentConcat": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}], "dim": ["COMBO", {"multiselect": false, "options": ["x", "-x", "y", "-y", "t", "-t"]}]}}, "input_order": {"required": ["samples1", "samples2", "dim"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentConcat", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentCut": {"input": {"required": {"samples": ["LATENT", {}], "dim": ["COMBO", {"multiselect": false, "options": ["x", "y", "t"]}], "index": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "amount": ["INT", {"default": 1, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["samples", "dim", "index", "amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentCut", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentBatch": {"input": {"required": {"samples1": ["LATENT", {}], "samples2": ["LATENT", {}]}}, "input_order": {"required": ["samples1", "samples2"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentBatch", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentBatchSeedBehavior": {"input": {"required": {"samples": ["LATENT", {}], "seed_behavior": ["COMBO", {"default": "fixed", "multiselect": false, "options": ["random", "fixed"]}]}}, "input_order": {"required": ["samples", "seed_behavior"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentBatchSeedBehavior", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentApplyOperation": {"input": {"required": {"samples": ["LATENT", {}], "operation": ["LATENT_OPERATION", {}]}}, "input_order": {"required": ["samples", "operation"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "LatentApplyOperation", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LatentApplyOperationCFG": {"input": {"required": {"model": ["MODEL", {}], "operation": ["LATENT_OPERATION", {}]}}, "input_order": {"required": ["model", "operation"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "LatentApplyOperationCFG", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LatentOperationTonemapReinhard": {"input": {"required": {"multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["multiplier"]}, "output": ["LATENT_OPERATION"], "output_is_list": [false], "output_name": ["LATENT_OPERATION"], "output_tooltips": [null], "name": "LatentOperationTonemapReinhard", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LatentOperationSharpen": {"input": {"required": {"sharpen_radius": ["INT", {"default": 9, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}], "alpha": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 5.0, "step": 0.01}]}}, "input_order": {"required": ["sharpen_radius", "sigma", "alpha"]}, "output": ["LATENT_OPERATION"], "output_is_list": [false], "output_name": ["LATENT_OPERATION"], "output_tooltips": [null], "name": "LatentOperationSharpen", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_latent", "category": "latent/advanced/operations", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "HypernetworkLoader": {"input": {"required": {"model": ["MODEL", {}], "hypernetwork_name": ["COMBO", {"multiselect": false, "options": []}], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "hypernetwork_name", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "HypernetworkLoader", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hypernetwork", "category": "loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "UpscaleModelLoader": {"input": {"required": {"model_name": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["model_name"]}, "output": ["UPSCALE_MODEL"], "output_is_list": [false], "output_name": ["UPSCALE_MODEL"], "output_tooltips": [null], "name": "UpscaleModelLoader", "display_name": "Load Upscale Model", "description": "", "python_module": "comfy_extras.nodes_upscale_model", "category": "loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageUpscaleWithModel": {"input": {"required": {"upscale_model": ["UPSCALE_MODEL", {}], "image": ["IMAGE", {}]}}, "input_order": {"required": ["upscale_model", "image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageUpscaleWithModel", "display_name": "Upscale Image (using Model)", "description": "", "python_module": "comfy_extras.nodes_upscale_model", "category": "image/upscaling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageBlend": {"input": {"required": {"image1": ["IMAGE", {}], "image2": ["IMAGE", {}], "blend_factor": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "blend_mode": ["COMBO", {"multiselect": false, "options": ["normal", "multiply", "screen", "overlay", "soft_light", "difference"]}]}}, "input_order": {"required": ["image1", "image2", "blend_factor", "blend_mode"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageBlend", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageBlur": {"input": {"required": {"image": ["IMAGE", {}], "blur_radius": ["INT", {"default": 1, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.1}]}}, "input_order": {"required": ["image", "blur_radius", "sigma"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageBlur", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageQuantize": {"input": {"required": {"image": ["IMAGE", {}], "colors": ["INT", {"default": 256, "min": 1, "max": 256, "step": 1}], "dither": ["COMBO", {"multiselect": false, "options": ["none", "floyd-steinberg", "bayer-2", "bayer-4", "bayer-8", "bayer-16"]}]}}, "input_order": {"required": ["image", "colors", "dither"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageQuantize", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageSharpen": {"input": {"required": {"image": ["IMAGE", {}], "sharpen_radius": ["INT", {"default": 1, "min": 1, "max": 31, "step": 1}], "sigma": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 10.0, "step": 0.01}], "alpha": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 5.0, "step": 0.01}]}}, "input_order": {"required": ["image", "sharpen_radius", "sigma", "alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageSharpen", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageScaleToTotalPixels": {"input": {"required": {"image": ["IMAGE", {}], "upscale_method": ["COMBO", {"multiselect": false, "options": ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]}], "megapixels": ["FLOAT", {"default": 1.0, "min": 0.01, "max": 16.0, "step": 0.01}]}}, "input_order": {"required": ["image", "upscale_method", "megapixels"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageScaleToTotalPixels", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_post_processing", "category": "image/upscaling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LatentCompositeMasked": {"input": {"required": {"destination": ["LATENT"], "source": ["LATENT"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 8}], "resize_source": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "resize_source"], "optional": ["mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "LatentCompositeMasked", "display_name": "LatentCompositeMasked", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "latent", "output_node": false}, "ImageCompositeMasked": {"input": {"required": {"destination": ["IMAGE"], "source": ["IMAGE"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "resize_source": ["BOOLEAN", {"default": false}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["destination", "source", "x", "y", "resize_source"], "optional": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCompositeMasked", "display_name": "ImageCompositeMasked", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "image", "output_node": false}, "MaskToImage": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "MaskToImage", "display_name": "Convert Mask to Image", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ImageToMask": {"input": {"required": {"image": ["IMAGE"], "channel": [["red", "green", "blue", "alpha"]]}}, "input_order": {"required": ["image", "channel"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImageToMask", "display_name": "Convert Image to Mask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ImageColorToMask": {"input": {"required": {"image": ["IMAGE"], "color": ["INT", {"default": 0, "min": 0, "max": 16777215, "step": 1, "display": "color"}]}}, "input_order": {"required": ["image", "color"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ImageColorToMask", "display_name": "ImageColorToMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "SolidMask": {"input": {"required": {"value": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["value", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "SolidMask", "display_name": "SolidMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "InvertMask": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "InvertMask", "display_name": "InvertMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "CropMask": {"input": {"required": {"mask": ["MASK"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}]}}, "input_order": {"required": ["mask", "x", "y", "width", "height"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "CropMask", "display_name": "CropMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "MaskComposite": {"input": {"required": {"destination": ["MASK"], "source": ["MASK"], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "operation": [["multiply", "add", "subtract", "and", "or", "xor"]]}}, "input_order": {"required": ["destination", "source", "x", "y", "operation"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "MaskComposite", "display_name": "MaskComposite", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "FeatherMask": {"input": {"required": {"mask": ["MASK"], "left": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "top": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "right": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "bottom": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["mask", "left", "top", "right", "bottom"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "FeatherMask", "display_name": "FeatherMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "GrowMask": {"input": {"required": {"mask": ["MASK"], "expand": ["INT", {"default": 0, "min": -16384, "max": 16384, "step": 1}], "tapered_corners": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mask", "expand", "tapered_corners"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "GrowMask", "display_name": "GrowMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "ThresholdMask": {"input": {"required": {"mask": ["MASK"], "value": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["mask", "value"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ThresholdMask", "display_name": "ThresholdMask", "description": "", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": false}, "MaskPreview": {"input": {"required": {"mask": ["MASK"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mask"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "MaskPreview", "display_name": "MaskPreview", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "comfy_extras.nodes_mask", "category": "mask", "output_node": true}, "PorterDuffImageComposite": {"input": {"required": {"source": ["IMAGE", {}], "source_alpha": ["MASK", {}], "destination": ["IMAGE", {}], "destination_alpha": ["MASK", {}], "mode": ["COMBO", {"default": "DST", "multiselect": false, "options": ["ADD", "CLEAR", "DARKEN", "DST", "DST_ATOP", "DST_IN", "DST_OUT", "DST_OVER", "LIGHTEN", "MULTIPLY", "OVERLAY", "SCREEN", "SRC", "SRC_ATOP", "SRC_IN", "SRC_OUT", "SRC_OVER", "XOR"]}]}}, "input_order": {"required": ["source", "source_alpha", "destination", "destination_alpha", "mode"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "output_tooltips": [null, null], "name": "PorterDuffImageComposite", "display_name": "Porter-Duff Image Composite", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SplitImageWithAlpha": {"input": {"required": {"image": ["IMAGE", {}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "output_tooltips": [null, null], "name": "SplitImageWithAlpha", "display_name": "Split Image with Alpha", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "JoinImageWithAlpha": {"input": {"required": {"image": ["IMAGE", {}], "alpha": ["MASK", {}]}}, "input_order": {"required": ["image", "alpha"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "JoinImageWithAlpha", "display_name": "Join Image with Alpha", "description": "", "python_module": "comfy_extras.nodes_compositing", "category": "mask/compositing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RebatchLatents": {"input": {"required": {"latents": ["LATENT", {}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["latents", "batch_size"]}, "output": ["LATENT"], "output_is_list": [true], "output_name": ["LATENT"], "output_tooltips": [null], "name": "RebatchLatents", "display_name": "Rebatch Latents", "description": "", "python_module": "comfy_extras.nodes_rebatch", "category": "latent/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RebatchImages": {"input": {"required": {"images": ["IMAGE", {}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["images", "batch_size"]}, "output": ["IMAGE"], "output_is_list": [true], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RebatchImages", "display_name": "Rebatch Images", "description": "", "python_module": "comfy_extras.nodes_rebatch", "category": "image/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelMergeSimple": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "ratio"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSimple", "display_name": "ModelMergeSimple", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeBlocks": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "input": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "input", "middle", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeBlocks", "display_name": "ModelMergeBlocks", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeSubtract": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSubtract", "display_name": "ModelMergeSubtract", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "ModelMergeAdd": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"]}}, "input_order": {"required": ["model1", "model2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeAdd", "display_name": "ModelMergeAdd", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CheckpointSave": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "vae": ["VAE"], "filename_prefix": ["STRING", {"default": "checkpoints/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "clip", "vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "CheckpointSave", "display_name": "Save Checkpoint", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "CLIPMergeSimple": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"], "ratio": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["clip1", "clip2", "ratio"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeSimple", "display_name": "CLIPMergeSimple", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPMergeSubtract": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"], "multiplier": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip1", "clip2", "multiplier"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeSubtract", "display_name": "CLIPMergeSubtract", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPMergeAdd": {"input": {"required": {"clip1": ["CLIP"], "clip2": ["CLIP"]}}, "input_order": {"required": ["clip1", "clip2"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "CLIPMergeAdd", "display_name": "CLIPMergeAdd", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": false}, "CLIPSave": {"input": {"required": {"clip": ["CLIP"], "filename_prefix": ["STRING", {"default": "clip/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["clip", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "CLIPSave", "display_name": "CLIPSave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "VAESave": {"input": {"required": {"vae": ["VAE"], "filename_prefix": ["STRING", {"default": "vae/ComfyUI_vae"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "VAESave", "display_name": "VAESave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "ModelSave": {"input": {"required": {"model": ["MODEL"], "filename_prefix": ["STRING", {"default": "diffusion_models/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ModelSave", "display_name": "ModelSave", "description": "", "python_module": "comfy_extras.nodes_model_merging", "category": "advanced/model_merging", "output_node": true}, "TomePatchModel": {"input": {"required": {"model": ["MODEL", {}], "ratio": ["FLOAT", {"default": 0.3, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "ratio"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "TomePatchModel", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_tomesd", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeSDXLRefiner": {"input": {"required": {"ascore": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip": ["CLIP", {}]}}, "input_order": {"required": ["ascore", "width", "height", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeSDXLRefiner", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_clip_sdxl", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeSDXL": {"input": {"required": {"clip": ["CLIP", {}], "width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "crop_w": ["INT", {"default": 0, "min": 0, "max": 16384}], "crop_h": ["INT", {"default": 0, "min": 0, "max": 16384}], "target_width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "target_height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "text_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "text_l": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "width", "height", "crop_w", "crop_h", "target_width", "target_height", "text_g", "text_l"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeSDXL", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_clip_sdxl", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "Canny": {"input": {"required": {"image": ["IMAGE", {}], "low_threshold": ["FLOAT", {"default": 0.4, "min": 0.01, "max": 0.99, "step": 0.01}], "high_threshold": ["FLOAT", {"default": 0.8, "min": 0.01, "max": 0.99, "step": 0.01}]}}, "input_order": {"required": ["image", "low_threshold", "high_threshold"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "Canny", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_canny", "category": "image/preprocessors", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FreeU": {"input": {"required": {"model": ["MODEL"], "b1": ["FLOAT", {"default": 1.1, "min": 0.0, "max": 10.0, "step": 0.01}], "b2": ["FLOAT", {"default": 1.2, "min": 0.0, "max": 10.0, "step": 0.01}], "s1": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 10.0, "step": 0.01}], "s2": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "b1", "b2", "s1", "s2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreeU", "display_name": "FreeU", "description": "", "python_module": "comfy_extras.nodes_freelunch", "category": "model_patches/unet", "output_node": false}, "FreeU_V2": {"input": {"required": {"model": ["MODEL"], "b1": ["FLOAT", {"default": 1.3, "min": 0.0, "max": 10.0, "step": 0.01}], "b2": ["FLOAT", {"default": 1.4, "min": 0.0, "max": 10.0, "step": 0.01}], "s1": ["FLOAT", {"default": 0.9, "min": 0.0, "max": 10.0, "step": 0.01}], "s2": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "b1", "b2", "s1", "s2"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "FreeU_V2", "display_name": "FreeU_V2", "description": "", "python_module": "comfy_extras.nodes_freelunch", "category": "model_patches/unet", "output_node": false}, "SamplerCustom": {"input": {"required": {"model": ["MODEL"], "add_noise": ["BOOLEAN", {"default": true}], "noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "sampler": ["SAMPLER"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["model", "add_noise", "noise_seed", "cfg", "positive", "negative", "sampler", "sigmas", "latent_image"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["output", "denoised_output"], "name": "SamplerCustom", "display_name": "SamplerCustom", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling", "output_node": false}, "BasicScheduler": {"input": {"required": {"model": ["MODEL"], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "scheduler", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "BasicScheduler", "display_name": "BasicScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "KarrasScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "rho": ["FLOAT", {"default": 7.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "rho"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "KarrasScheduler", "display_name": "KarrasScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "ExponentialScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ExponentialScheduler", "display_name": "ExponentialScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "PolyexponentialScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "rho": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "rho"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "PolyexponentialScheduler", "display_name": "PolyexponentialScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "LaplaceScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "sigma_max": ["FLOAT", {"default": 14.614642, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "sigma_min": ["FLOAT", {"default": 0.0291675, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "mu": ["FLOAT", {"default": 0.0, "min": -10.0, "max": 10.0, "step": 0.1, "round": false}], "beta": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["steps", "sigma_max", "sigma_min", "mu", "beta"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "LaplaceScheduler", "display_name": "LaplaceScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "VPScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "beta_d": ["FLOAT", {"default": 19.9, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "beta_min": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 5000.0, "step": 0.01, "round": false}], "eps_s": ["FLOAT", {"default": 0.001, "min": 0.0, "max": 1.0, "step": 0.0001, "round": false}]}}, "input_order": {"required": ["steps", "beta_d", "beta_min", "eps_s"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "VPScheduler", "display_name": "VPScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "BetaSamplingScheduler": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "alpha": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 50.0, "step": 0.01, "round": false}], "beta": ["FLOAT", {"default": 0.6, "min": 0.0, "max": 50.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["model", "steps", "alpha", "beta"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "BetaSamplingScheduler", "display_name": "BetaSamplingScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "SDTurboScheduler": {"input": {"required": {"model": ["MODEL"], "steps": ["INT", {"default": 1, "min": 1, "max": 10}], "denoise": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "SDTurboScheduler", "display_name": "SDTurboScheduler", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/schedulers", "output_node": false}, "KSamplerSelect": {"input": {"required": {"sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]]}}, "input_order": {"required": ["sampler_name"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "KSamplerSelect", "display_name": "KSamplerSelect", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerAncestral": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerAncestral", "display_name": "SamplerEulerAncestral", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerEulerAncestralCFGPP": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerEulerAncestralCFGPP", "display_name": "SamplerEulerAncestralCFG++", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerLMS": {"input": {"required": {"order": ["INT", {"default": 4, "min": 1, "max": 100}]}}, "input_order": {"required": ["order"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerLMS", "display_name": "SamplerLMS", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_3M_SDE": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["eta", "s_noise", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_3M_SDE", "display_name": "SamplerDPMPP_3M_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_2M_SDE": {"input": {"required": {"solver_type": [["midpoint", "heun"]], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["solver_type", "eta", "s_noise", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_2M_SDE", "display_name": "SamplerDPMPP_2M_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_SDE": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "r": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "noise_device": [["gpu", "cpu"]]}}, "input_order": {"required": ["eta", "s_noise", "r", "noise_device"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_SDE", "display_name": "SamplerDPMPP_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMPP_2S_Ancestral": {"input": {"required": {"eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMPP_2S_Ancestral", "display_name": "SamplerDPMPP_2S_Ancestral", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerDPMAdaptative": {"input": {"required": {"order": ["INT", {"default": 3, "min": 2, "max": 3}], "rtol": ["FLOAT", {"default": 0.05, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "atol": ["FLOAT", {"default": 0.0078, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "h_init": ["FLOAT", {"default": 0.05, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "pcoeff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "icoeff": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "dcoeff": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "accept_safety": ["FLOAT", {"default": 0.81, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "eta": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["order", "rtol", "atol", "h_init", "pcoeff", "icoeff", "dcoeff", "accept_safety", "eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerDPMAdaptative", "display_name": "SamplerDPMAdaptative", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerER_SDE": {"input": {"required": {"solver_type": ["COMBO", {"options": ["ER-SDE", "Reverse-time SDE", "ODE"]}], "max_stage": ["INT", {"default": 3, "min": 1, "max": 3}], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false, "tooltip": "Stochastic strength of reverse-time SDE.\nWhen eta=0, it reduces to deterministic ODE. This setting doesn't apply to ER-SDE solver type."}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}]}}, "input_order": {"required": ["solver_type", "max_stage", "eta", "s_noise"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerER_SDE", "display_name": "SamplerER_SDE", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SamplerSASolver": {"input": {"required": {"model": ["MODEL", {}], "eta": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "round": false}], "sde_start_percent": ["FLOAT", {"default": 0.2, "min": 0.0, "max": 1.0, "step": 0.001}], "sde_end_percent": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.001}], "s_noise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": false}], "predictor_order": ["INT", {"default": 3, "min": 1, "max": 6}], "corrector_order": ["INT", {"default": 4, "min": 0, "max": 6}], "use_pece": ["BOOLEAN", {}], "simple_order_2": ["BOOLEAN", {}]}}, "input_order": {"required": ["model", "eta", "sde_start_percent", "sde_end_percent", "s_noise", "predictor_order", "corrector_order", "use_pece", "simple_order_2"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "name": "SamplerSASolver", "display_name": "SamplerSASolver", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/samplers", "output_node": false}, "SplitSigmas": {"input": {"required": {"sigmas": ["SIGMAS"], "step": ["INT", {"default": 0, "min": 0, "max": 10000}]}}, "input_order": {"required": ["sigmas", "step"]}, "output": ["SIGMAS", "SIGMAS"], "output_is_list": [false, false], "output_name": ["high_sigmas", "low_sigmas"], "name": "SplitSigmas", "display_name": "SplitSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SplitSigmasDenoise": {"input": {"required": {"sigmas": ["SIGMAS"], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["sigmas", "denoise"]}, "output": ["SIGMAS", "SIGMAS"], "output_is_list": [false, false], "output_name": ["high_sigmas", "low_sigmas"], "name": "SplitSigmasDenoise", "display_name": "SplitSigmasDenoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "FlipSigmas": {"input": {"required": {"sigmas": ["SIGMAS"]}}, "input_order": {"required": ["sigmas"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "FlipSigmas", "display_name": "FlipSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SetFirstSigma": {"input": {"required": {"sigmas": ["SIGMAS"], "sigma": ["FLOAT", {"default": 136.0, "min": 0.0, "max": 20000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["sigmas", "sigma"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "SetFirstSigma", "display_name": "SetFirstSigma", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "ExtendIntermediateSigmas": {"input": {"required": {"sigmas": ["SIGMAS"], "steps": ["INT", {"default": 2, "min": 1, "max": 100}], "start_at_sigma": ["FLOAT", {"default": -1.0, "min": -1.0, "max": 20000.0, "step": 0.01, "round": false}], "end_at_sigma": ["FLOAT", {"default": 12.0, "min": 0.0, "max": 20000.0, "step": 0.01, "round": false}], "spacing": [["linear", "cosine", "sine"]]}}, "input_order": {"required": ["sigmas", "steps", "start_at_sigma", "end_at_sigma", "spacing"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ExtendIntermediateSigmas", "display_name": "ExtendIntermediateSigmas", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "SamplingPercentToSigma": {"input": {"required": {"model": ["MODEL", {}], "sampling_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.0001}], "return_actual_sigma": ["BOOLEAN", {"default": false, "tooltip": "Return the actual sigma value instead of the value used for interval checks.\nThis only affects results at 0.0 and 1.0."}]}}, "input_order": {"required": ["model", "sampling_percent", "return_actual_sigma"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["sigma_value"], "name": "SamplingPercentToSigma", "display_name": "SamplingPercentToSigma", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/sigmas", "output_node": false}, "CFGGuider": {"input": {"required": {"model": ["MODEL"], "positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "cfg"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "CFGGuider", "display_name": "CFGGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "DualCFGGuider": {"input": {"required": {"model": ["MODEL"], "cond1": ["CONDITIONING"], "cond2": ["CONDITIONING"], "negative": ["CONDITIONING"], "cfg_conds": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "cfg_cond2_negative": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "style": [["regular", "nested"]]}}, "input_order": {"required": ["model", "cond1", "cond2", "negative", "cfg_conds", "cfg_cond2_negative", "style"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "DualCFGGuider", "display_name": "DualCFGGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "BasicGuider": {"input": {"required": {"model": ["MODEL"], "conditioning": ["CONDITIONING"]}}, "input_order": {"required": ["model", "conditioning"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "name": "BasicGuider", "display_name": "BasicGuider", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/guiders", "output_node": false}, "RandomNoise": {"input": {"required": {"noise_seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}}, "input_order": {"required": ["noise_seed"]}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "RandomNoise", "display_name": "RandomNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/noise", "output_node": false}, "DisableNoise": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["NOISE"], "output_is_list": [false], "output_name": ["NOISE"], "name": "DisableNoise", "display_name": "DisableNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling/noise", "output_node": false}, "AddNoise": {"input": {"required": {"model": ["MODEL"], "noise": ["NOISE"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["model", "noise", "sigmas", "latent_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "AddNoise", "display_name": "AddNoise", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "_for_testing/custom_sampling/noise", "output_node": false}, "SamplerCustomAdvanced": {"input": {"required": {"noise": ["NOISE"], "guider": ["GUIDER"], "sampler": ["SAMPLER"], "sigmas": ["SIGMAS"], "latent_image": ["LATENT"]}}, "input_order": {"required": ["noise", "guider", "sampler", "sigmas", "latent_image"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["output", "denoised_output"], "name": "SamplerCustomAdvanced", "display_name": "SamplerCustomAdvanced", "description": "", "python_module": "comfy_extras.nodes_custom_sampler", "category": "sampling/custom_sampling", "output_node": false}, "HyperTile": {"input": {"required": {"model": ["MODEL", {}], "tile_size": ["INT", {"default": 256, "min": 1, "max": 2048}], "swap_size": ["INT", {"default": 2, "min": 1, "max": 128}], "max_depth": ["INT", {"default": 0, "min": 0, "max": 10}], "scale_depth": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["model", "tile_size", "swap_size", "max_depth", "scale_depth"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "HyperTile", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hypertile", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelSamplingDiscrete": {"input": {"required": {"model": ["MODEL"], "sampling": [["eps", "v_prediction", "lcm", "x0", "img_to_img"]], "zsnr": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["model", "sampling", "zsnr"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingDiscrete", "display_name": "ModelSamplingDiscrete", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingContinuousEDM": {"input": {"required": {"model": ["MODEL"], "sampling": [["v_prediction", "edm", "edm_playground_v2.5", "eps", "cosmos_rflow"]], "sigma_max": ["FLOAT", {"default": 120.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}], "sigma_min": ["FLOAT", {"default": 0.002, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["model", "sampling", "sigma_max", "sigma_min"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingContinuousEDM", "display_name": "ModelSamplingContinuousEDM", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingContinuousV": {"input": {"required": {"model": ["MODEL"], "sampling": [["v_prediction"]], "sigma_max": ["FLOAT", {"default": 500.0, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}], "sigma_min": ["FLOAT", {"default": 0.03, "min": 0.0, "max": 1000.0, "step": 0.001, "round": false}]}}, "input_order": {"required": ["model", "sampling", "sigma_max", "sigma_min"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingContinuousV", "display_name": "ModelSamplingContinuousV", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingStableCascade": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingStableCascade", "display_name": "ModelSamplingStableCascade", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingSD3": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingSD3", "display_name": "ModelSamplingSD3", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingAuraFlow": {"input": {"required": {"model": ["MODEL"], "shift": ["FLOAT", {"default": 1.73, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "shift"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingAuraFlow", "display_name": "ModelSamplingAuraFlow", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelSamplingFlux": {"input": {"required": {"model": ["MODEL"], "max_shift": ["FLOAT", {"default": 1.15, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 100.0, "step": 0.01}], "width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}]}}, "input_order": {"required": ["model", "max_shift", "base_shift", "width", "height"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelSamplingFlux", "display_name": "ModelSamplingFlux", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "RescaleCFG": {"input": {"required": {"model": ["MODEL"], "multiplier": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "multiplier"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "RescaleCFG", "display_name": "RescaleCFG", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/model", "output_node": false}, "ModelComputeDtype": {"input": {"required": {"model": ["MODEL"], "dtype": [["default", "fp32", "fp16", "bf16"]]}}, "input_order": {"required": ["model", "dtype"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelComputeDtype", "display_name": "ModelComputeDtype", "description": "", "python_module": "comfy_extras.nodes_model_advanced", "category": "advanced/debug/model", "output_node": false}, "PatchModelAddDownscale": {"input": {"required": {"model": ["MODEL", {}], "block_number": ["INT", {"default": 3, "min": 1, "max": 32, "step": 1}], "downscale_factor": ["FLOAT", {"default": 2.0, "min": 0.1, "max": 9.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.35, "min": 0.0, "max": 1.0, "step": 0.001}], "downscale_after_skip": ["BOOLEAN", {"default": true}], "downscale_method": ["COMBO", {"multiselect": false, "options": ["bicubic", "nearest-exact", "bilinear", "area", "bislerp"]}], "upscale_method": ["COMBO", {"multiselect": false, "options": ["bicubic", "nearest-exact", "bilinear", "area", "bislerp"]}]}}, "input_order": {"required": ["model", "block_number", "downscale_factor", "start_percent", "end_percent", "downscale_after_skip", "downscale_method", "upscale_method"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "PatchModelAddDownscale", "display_name": "PatchModelAddDownscale (Kohya Deep Shrink)", "description": "", "python_module": "comfy_extras.nodes_model_downscale", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageCrop": {"input": {"required": {"image": ["IMAGE"], "width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "width", "height", "x", "y"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageCrop", "display_name": "Image Crop", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "RepeatImageBatch": {"input": {"required": {"image": ["IMAGE"], "amount": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["image", "amount"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "RepeatImageBatch", "display_name": "RepeatImageBatch", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/batch", "output_node": false}, "ImageFromBatch": {"input": {"required": {"image": ["IMAGE"], "batch_index": ["INT", {"default": 0, "min": 0, "max": 4095}], "length": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["image", "batch_index", "length"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFromBatch", "display_name": "ImageFromBatch", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/batch", "output_node": false}, "ImageAddNoise": {"input": {"required": {"image": ["IMAGE"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true, "tooltip": "The random seed used for creating the noise."}], "strength": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["image", "seed", "strength"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageAddNoise", "display_name": "ImageAddNoise", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image", "output_node": false}, "SaveAnimatedWEBP": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "fps": ["FLOAT", {"default": 6.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "lossless": ["BOOLEAN", {"default": true}], "quality": ["INT", {"default": 80, "min": 0, "max": 100}], "method": [["default", "fastest", "slowest"]]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "fps", "lossless", "quality", "method"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAnimatedWEBP", "display_name": "SaveAnimatedWEBP", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/animation", "output_node": true}, "SaveAnimatedPNG": {"input": {"required": {"images": ["IMAGE"], "filename_prefix": ["STRING", {"default": "ComfyUI"}], "fps": ["FLOAT", {"default": 6.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "compress_level": ["INT", {"default": 4, "min": 0, "max": 9}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "filename_prefix", "fps", "compress_level"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAnimatedPNG", "display_name": "SaveAnimatedPNG", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/animation", "output_node": true}, "SaveSVGNode": {"input": {"required": {"svg": ["SVG"], "filename_prefix": ["STRING", {"default": "svg/ComfyUI", "tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes."}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["svg", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveSVGNode", "display_name": "SaveSVGNode", "description": "Save SVG files on disk.", "python_module": "comfy_extras.nodes_images", "category": "image/save", "output_node": true}, "ImageStitch": {"input": {"required": {"image1": ["IMAGE"], "direction": [["right", "down", "left", "up"], {"default": "right"}], "match_image_size": ["BOOLEAN", {"default": true}], "spacing_width": ["INT", {"default": 0, "min": 0, "max": 1024, "step": 2}], "spacing_color": [["white", "black", "red", "green", "blue"], {"default": "white"}]}, "optional": {"image2": ["IMAGE"]}}, "input_order": {"required": ["image1", "direction", "match_image_size", "spacing_width", "spacing_color"], "optional": ["image2"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageStitch", "display_name": "Image Stitch", "description": "\nStitches image2 to image1 in the specified direction.\nIf image2 is not provided, returns image1 unchanged.\nOptional spacing can be added between images.\n", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "ResizeAndPadImage": {"input": {"required": {"image": ["IMAGE"], "target_width": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "target_height": ["INT", {"default": 512, "min": 1, "max": 16384, "step": 1}], "padding_color": [["white", "black"]], "interpolation": [["area", "bicubic", "nearest-exact", "bilinear", "lanczos"]]}}, "input_order": {"required": ["image", "target_width", "target_height", "padding_color", "interpolation"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ResizeAndPadImage", "display_name": "ResizeAndPadImage", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "GetImageSize": {"input": {"required": {"image": ["IMAGE"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["image"], "hidden": ["unique_id"]}, "output": ["INT", "INT", "INT"], "output_is_list": [false, false, false], "output_name": ["width", "height", "batch_size"], "name": "GetImageSize", "display_name": "Get Image Size", "description": "Returns width and height of the image, and passes it through unchanged.", "python_module": "comfy_extras.nodes_images", "category": "image", "output_node": false}, "ImageRotate": {"input": {"required": {"image": ["IMAGE"], "rotation": [["none", "90 degrees", "180 degrees", "270 degrees"]]}}, "input_order": {"required": ["image", "rotation"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageRotate", "display_name": "ImageRotate", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "ImageFlip": {"input": {"required": {"image": ["IMAGE"], "flip_method": [["x-axis: vertically", "y-axis: horizontally"]]}}, "input_order": {"required": ["image", "flip_method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageFlip", "display_name": "ImageFlip", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/transform", "output_node": false}, "ImageScaleToMaxDimension": {"input": {"required": {"image": ["IMAGE"], "upscale_method": [["area", "lanczos", "bilinear", "nearest-exact", "bilinear", "bicubic"]], "largest_size": ["INT", {"default": 512, "min": 0, "max": 16384, "step": 1}]}}, "input_order": {"required": ["image", "upscale_method", "largest_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ImageScaleToMaxDimension", "display_name": "ImageScaleToMaxDimension", "description": "", "python_module": "comfy_extras.nodes_images", "category": "image/upscaling", "output_node": false}, "ImageOnlyCheckpointLoader": {"input": {"required": {"ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]]}}, "input_order": {"required": ["ckpt_name"]}, "output": ["MODEL", "CLIP_VISION", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP_VISION", "VAE"], "name": "ImageOnlyCheckpointLoader", "display_name": "Image Only Checkpoint Loader (img2vid model)", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "loaders/video_models", "output_node": false}, "SVD_img2vid_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION"], "init_image": ["IMAGE"], "vae": ["VAE"], "width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "video_frames": ["INT", {"default": 14, "min": 1, "max": 4096}], "motion_bucket_id": ["INT", {"default": 127, "min": 1, "max": 1023}], "fps": ["INT", {"default": 6, "min": 1, "max": 1024}], "augmentation_level": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "video_frames", "motion_bucket_id", "fps", "augmentation_level"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "name": "SVD_img2vid_Conditioning", "display_name": "SVD_img2vid_Conditioning", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "conditioning/video_models", "output_node": false}, "VideoLinearCFGGuidance": {"input": {"required": {"model": ["MODEL"], "min_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}]}}, "input_order": {"required": ["model", "min_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "VideoLinearCFGGuidance", "display_name": "VideoLinearCFGGuidance", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "sampling/video_models", "output_node": false}, "VideoTriangleCFGGuidance": {"input": {"required": {"model": ["MODEL"], "min_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.5, "round": 0.01}]}}, "input_order": {"required": ["model", "min_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "VideoTriangleCFGGuidance", "display_name": "VideoTriangleCFGGuidance", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "sampling/video_models", "output_node": false}, "ImageOnlyCheckpointSave": {"input": {"required": {"model": ["MODEL"], "clip_vision": ["CLIP_VISION"], "vae": ["VAE"], "filename_prefix": ["STRING", {"default": "checkpoints/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["model", "clip_vision", "vae", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "ImageOnlyCheckpointSave", "display_name": "ImageOnlyCheckpointSave", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "advanced/model_merging", "output_node": true}, "ConditioningSetAreaPercentageVideo": {"input": {"required": {"conditioning": ["CONDITIONING"], "width": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "height": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "temporal": ["FLOAT", {"default": 1.0, "min": 0, "max": 1.0, "step": 0.01}], "x": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "y": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "z": ["FLOAT", {"default": 0, "min": 0, "max": 1.0, "step": 0.01}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["conditioning", "width", "height", "temporal", "x", "y", "z", "strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetAreaPercentageVideo", "display_name": "ConditioningSetAreaPercentageVideo", "description": "", "python_module": "comfy_extras.nodes_video_model", "category": "conditioning", "output_node": false}, "TrainLoraNode": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to train the LoRA on."}], "latents": ["LATENT", {"tooltip": "The Latents to use for training, serve as dataset/input of the model."}], "positive": ["CONDITIONING", {"tooltip": "The positive conditioning to use for training."}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 10000, "step": 1, "tooltip": "The batch size to use for training."}], "grad_accumulation_steps": ["INT", {"default": 1, "min": 1, "max": 1024, "step": 1, "tooltip": "The number of gradient accumulation steps to use for training."}], "steps": ["INT", {"default": 16, "min": 1, "max": 100000, "tooltip": "The number of steps to train the LoRA for."}], "learning_rate": ["FLOAT", {"default": 0.0005, "min": 1e-07, "max": 1.0, "step": 1e-06, "tooltip": "The learning rate to use for training."}], "rank": ["INT", {"default": 8, "min": 1, "max": 128, "tooltip": "The rank of the LoRA layers."}], "optimizer": [["AdamW", "Adam", "SGD", "RMSprop"], {"default": "AdamW", "tooltip": "The optimizer to use for training."}], "loss_function": [["MSE", "L1", "Huber", "SmoothL1"], {"default": "MSE", "tooltip": "The loss function to use for training."}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "tooltip": "The seed to use for training (used in generator for LoRA weight initialization and noise sampling)"}], "training_dtype": [["bf16", "fp32"], {"default": "bf16", "tooltip": "The dtype to use for training."}], "lora_dtype": [["bf16", "fp32"], {"default": "bf16", "tooltip": "The dtype to use for lora."}], "algorithm": [["LoRA", "LoHa", "LoKr", "OFT"], {"default": "LoRA", "tooltip": "The algorithm to use for training."}], "gradient_checkpointing": ["BOOLEAN", {"default": true, "tooltip": "Use gradient checkpointing for training."}], "existing_lora": [["[None]"], {"default": "[None]", "tooltip": "The existing LoRA to append to. Set to None for new LoRA."}]}}, "input_order": {"required": ["model", "latents", "positive", "batch_size", "grad_accumulation_steps", "steps", "learning_rate", "rank", "optimizer", "loss_function", "seed", "training_dtype", "lora_dtype", "algorithm", "gradient_checkpointing", "existing_lora"]}, "output": ["MODEL", "LORA_MODEL", "LOSS_MAP", "INT"], "output_is_list": [false, false, false, false], "output_name": ["model_with_lora", "lora", "loss", "steps"], "name": "TrainLoraNode", "display_name": "Train LoRA", "description": "", "python_module": "comfy_extras.nodes_train", "category": "training", "output_node": false, "experimental": true}, "SaveLoRANode": {"input": {"required": {"lora": ["LORA_MODEL", {"tooltip": "The LoRA model to save. Do not use the model with LoRA layers."}], "prefix": ["STRING", {"default": "loras/ComfyUI_trained_lora", "tooltip": "The prefix to use for the saved LoRA file."}]}, "optional": {"steps": ["INT", {"forceInput": true, "tooltip": "Optional: The number of steps to LoRA has been trained for, used to name the saved file."}]}}, "input_order": {"required": ["lora", "prefix"], "optional": ["steps"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveLoRANode", "display_name": "Save LoRA Weights", "description": "", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": true, "experimental": true}, "LoraModelLoader": {"input": {"required": {"model": ["MODEL", {"tooltip": "The diffusion model the LoRA will be applied to."}], "lora": ["LORA_MODEL", {"tooltip": "The LoRA model to apply to the diffusion model."}], "strength_model": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01, "tooltip": "How strongly to modify the diffusion model. This value can be negative."}]}}, "input_order": {"required": ["model", "lora", "strength_model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "LoraModelLoader", "display_name": "Load LoRA Model", "description": "Load Trained LoRA weights from Train LoRA node.", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": false, "output_tooltips": ["The modified diffusion model."], "experimental": true}, "LoadImageSetFromFolderNode": {"input": {"required": {"folder": [["3d"], {"tooltip": "The folder to load images from."}]}, "optional": {"resize_method": [["None", "Stretch", "Crop", "Pad"], {"default": "None"}]}}, "input_order": {"required": ["folder"], "optional": ["resize_method"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "LoadImageSetFromFolderNode", "display_name": "Load Image Dataset from Folder", "description": "Loads a batch of images from a directory for training.", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": false, "experimental": true}, "LoadImageTextSetFromFolderNode": {"input": {"required": {"folder": [["3d"], {"tooltip": "The folder to load images from."}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}, "optional": {"resize_method": [["None", "Stretch", "Crop", "Pad"], {"default": "None"}], "width": ["INT", {"default": -1, "min": -1, "max": 10000, "step": 1, "tooltip": "The width to resize the images to. -1 means use the original width."}], "height": ["INT", {"default": -1, "min": -1, "max": 10000, "step": 1, "tooltip": "The height to resize the images to. -1 means use the original height."}]}}, "input_order": {"required": ["folder", "clip"], "optional": ["resize_method", "width", "height"]}, "output": ["IMAGE", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["IMAGE", "CONDITIONING"], "name": "LoadImageTextSetFromFolderNode", "display_name": "Load Image and Text Dataset from Folder", "description": "Loads a batch of images and caption from a directory for training.", "python_module": "comfy_extras.nodes_train", "category": "loaders", "output_node": false, "experimental": true}, "LossGraphNode": {"input": {"required": {"loss": ["LOSS_MAP", {"default": {}}], "filename_prefix": ["STRING", {"default": "loss_graph"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["loss", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "LossGraphNode", "display_name": "Plot Loss Graph", "description": "Plots the loss graph and saves it to the output directory.", "python_module": "comfy_extras.nodes_train", "category": "training", "output_node": true, "experimental": true}, "SelfAttentionGuidance": {"input": {"required": {"model": ["MODEL", {}], "scale": ["FLOAT", {"default": 0.5, "min": -2.0, "max": 5.0, "step": 0.01}], "blur_sigma": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 10.0, "step": 0.1}]}}, "input_order": {"required": ["model", "scale", "blur_sigma"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SelfAttentionGuidance", "display_name": "Self-Attention Guidance", "description": "", "python_module": "comfy_extras.nodes_sag", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "PerpNeg": {"input": {"required": {"model": ["MODEL", {}], "empty_conditioning": ["CONDITIONING", {}], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "empty_conditioning", "neg_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "PerpNeg", "display_name": "Perp-Neg (DEPRECATED by PerpNegGuider)", "description": "", "python_module": "comfy_extras.nodes_perpneg", "category": "_for_testing", "output_node": false, "deprecated": true, "experimental": true, "api_node": false}, "PerpNegGuider": {"input": {"required": {"model": ["MODEL", {}], "positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "empty_conditioning": ["CONDITIONING", {}], "cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}], "neg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "positive", "negative", "empty_conditioning", "cfg", "neg_scale"]}, "output": ["GUIDER"], "output_is_list": [false], "output_name": ["GUIDER"], "output_tooltips": [null], "name": "PerpNegGuider", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_perpneg", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "StableZero123_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION", {}], "init_image": ["IMAGE", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "elevation", "azimuth"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "StableZero123_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableZero123_Conditioning_Batched": {"input": {"required": {"clip_vision": ["CLIP_VISION", {}], "init_image": ["IMAGE", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 256, "min": 16, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "elevation_batch_increment": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}], "azimuth_batch_increment": ["FLOAT", {"default": 0.0, "min": -180.0, "max": 180.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "batch_size", "elevation", "azimuth", "elevation_batch_increment", "azimuth_batch_increment"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "StableZero123_Conditioning_Batched", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SV3D_Conditioning": {"input": {"required": {"clip_vision": ["CLIP_VISION", {}], "init_image": ["IMAGE", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "height": ["INT", {"default": 576, "min": 16, "max": 16384, "step": 8}], "video_frames": ["INT", {"default": 21, "min": 1, "max": 4096}], "elevation": ["FLOAT", {"default": 0.0, "min": -90.0, "max": 90.0, "step": 0.1, "round": false}]}}, "input_order": {"required": ["clip_vision", "init_image", "vae", "width", "height", "video_frames", "elevation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "SV3D_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable3d", "category": "conditioning/3d_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SD_4XUpscale_Conditioning": {"input": {"required": {"images": ["IMAGE", {}], "positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "scale_ratio": ["FLOAT", {"default": 4.0, "min": 0.0, "max": 10.0, "step": 0.01}], "noise_augmentation": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["images", "positive", "negative", "scale_ratio", "noise_augmentation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "SD_4XUpscale_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_sdupscale", "category": "conditioning/upscale_diffusion", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PhotoMakerLoader": {"input": {"required": {"photomaker_model_name": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["photomaker_model_name"]}, "output": ["PHOTOMAKER"], "output_is_list": [false], "output_name": ["PHOTOMAKER"], "output_tooltips": [null], "name": "PhotoMakerLoader", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_photomaker", "category": "_for_testing/photomaker", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "PhotoMakerEncode": {"input": {"required": {"photomaker": ["PHOTOMAKER", {}], "image": ["IMAGE", {}], "clip": ["CLIP", {}], "text": ["STRING", {"default": "photograph of photomaker", "multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["photomaker", "image", "clip", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "PhotoMakerEncode", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_photomaker", "category": "_for_testing/photomaker", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "CLIPTextEncodePixArtAlpha": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 0, "max": 16384}], "height": ["INT", {"default": 1024, "min": 0, "max": 16384}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip": ["CLIP", {}]}}, "input_order": {"required": ["width", "height", "text", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodePixArtAlpha", "display_name": null, "description": "Encodes text and sets the resolution conditioning for PixArt Alpha. Does not apply to PixArt Sigma.", "python_module": "comfy_extras.nodes_pixart", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeControlnet": {"input": {"required": {"clip": ["CLIP", {}], "conditioning": ["CONDITIONING", {}], "text": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "conditioning", "text"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeControlnet", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cond", "category": "_for_testing/conditioning", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "T5TokenizerOptions": {"input": {"required": {"clip": ["CLIP", {}], "min_padding": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}], "min_length": ["INT", {"default": 0, "min": 0, "max": 10000, "step": 1}]}}, "input_order": {"required": ["clip", "min_padding", "min_length"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "T5TokenizerOptions", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cond", "category": "_for_testing/conditioning", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "Morphology": {"input": {"required": {"image": ["IMAGE", {}], "operation": ["COMBO", {"multiselect": false, "options": ["erode", "dilate", "open", "close", "gradient", "bottom_hat", "top_hat"]}], "kernel_size": ["INT", {"default": 3, "min": 3, "max": 999, "step": 1}]}}, "input_order": {"required": ["image", "operation", "kernel_size"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "Morphology", "display_name": "ImageMorphology", "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/postprocessing", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageRGBToYUV": {"input": {"required": {"image": ["IMAGE", {}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE", "IMAGE", "IMAGE"], "output_is_list": [false, false, false], "output_name": ["Y", "U", "V"], "output_tooltips": [null, null, null], "name": "ImageRGBToYUV", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ImageYUVToRGB": {"input": {"required": {"Y": ["IMAGE", {}], "U": ["IMAGE", {}], "V": ["IMAGE", {}]}}, "input_order": {"required": ["Y", "U", "V"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ImageYUVToRGB", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_morphology", "category": "image/batch", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_EmptyLatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 256, "max": 16384, "step": 8}], "height": ["INT", {"default": 1024, "min": 256, "max": 16384, "step": 8}], "compression": ["INT", {"default": 42, "min": 4, "max": 128, "step": 1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "compression", "batch_size"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["stage_c", "stage_b"], "output_tooltips": [null, null], "name": "StableCascade_EmptyLatentImage", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "latent/stable_cascade", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_StageB_Conditioning": {"input": {"required": {"conditioning": ["CONDITIONING", {}], "stage_c": ["LATENT", {}]}}, "input_order": {"required": ["conditioning", "stage_c"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "StableCascade_StageB_Conditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "conditioning/stable_cascade", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_StageC_VAEEncode": {"input": {"required": {"image": ["IMAGE", {}], "vae": ["VAE", {}], "compression": ["INT", {"default": 42, "min": 4, "max": 128, "step": 1}]}}, "input_order": {"required": ["image", "vae", "compression"]}, "output": ["LATENT", "LATENT"], "output_is_list": [false, false], "output_name": ["stage_c", "stage_b"], "output_tooltips": [null, null], "name": "StableCascade_StageC_VAEEncode", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "latent/stable_cascade", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StableCascade_SuperResolutionControlnet": {"input": {"required": {"image": ["IMAGE", {}], "vae": ["VAE", {}]}}, "input_order": {"required": ["image", "vae"]}, "output": ["IMAGE", "LATENT", "LATENT"], "output_is_list": [false, false, false], "output_name": ["controlnet_input", "stage_c", "stage_b"], "output_tooltips": [null, null, null], "name": "StableCascade_SuperResolutionControlnet", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_stable_cascade", "category": "_for_testing/stable_cascade", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "DifferentialDiffusion": {"input": {"required": {"model": ["MODEL", {}]}, "optional": {"strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model"], "optional": ["strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "DifferentialDiffusion", "display_name": "Differential Diffusion", "description": "", "python_module": "comfy_extras.nodes_differential_diffusion", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "InstructPixToPixConditioning": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "pixels": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "pixels"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "InstructPixToPixConditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_ip2p", "category": "conditioning/instructpix2pix", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelMergeSD1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0.", "input_blocks.1.", "input_blocks.2.", "input_blocks.3.", "input_blocks.4.", "input_blocks.5.", "input_blocks.6.", "input_blocks.7.", "input_blocks.8.", "input_blocks.9.", "input_blocks.10.", "input_blocks.11.", "middle_block.0.", "middle_block.1.", "middle_block.2.", "output_blocks.0.", "output_blocks.1.", "output_blocks.2.", "output_blocks.3.", "output_blocks.4.", "output_blocks.5.", "output_blocks.6.", "output_blocks.7.", "output_blocks.8.", "output_blocks.9.", "output_blocks.10.", "output_blocks.11.", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD1", "display_name": "ModelMergeSD1", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD2": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0.", "input_blocks.1.", "input_blocks.2.", "input_blocks.3.", "input_blocks.4.", "input_blocks.5.", "input_blocks.6.", "input_blocks.7.", "input_blocks.8.", "input_blocks.9.", "input_blocks.10.", "input_blocks.11.", "middle_block.0.", "middle_block.1.", "middle_block.2.", "output_blocks.0.", "output_blocks.1.", "output_blocks.2.", "output_blocks.3.", "output_blocks.4.", "output_blocks.5.", "output_blocks.6.", "output_blocks.7.", "output_blocks.8.", "output_blocks.9.", "output_blocks.10.", "output_blocks.11.", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD2", "display_name": "ModelMergeSD2", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSDXL": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "time_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "label_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "input_blocks.8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "middle_block.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.0": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.7": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "output_blocks.8": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "time_embed.", "label_emb.", "input_blocks.0", "input_blocks.1", "input_blocks.2", "input_blocks.3", "input_blocks.4", "input_blocks.5", "input_blocks.6", "input_blocks.7", "input_blocks.8", "middle_block.0", "middle_block.1", "middle_block.2", "output_blocks.0", "output_blocks.1", "output_blocks.2", "output_blocks.3", "output_blocks.4", "output_blocks.5", "output_blocks.6", "output_blocks.7", "output_blocks.8", "out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSDXL", "display_name": "ModelMergeSDXL", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD3_2B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "context_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embed.", "x_embedder.", "context_embedder.", "y_embedder.", "t_embedder.", "joint_blocks.0.", "joint_blocks.1.", "joint_blocks.2.", "joint_blocks.3.", "joint_blocks.4.", "joint_blocks.5.", "joint_blocks.6.", "joint_blocks.7.", "joint_blocks.8.", "joint_blocks.9.", "joint_blocks.10.", "joint_blocks.11.", "joint_blocks.12.", "joint_blocks.13.", "joint_blocks.14.", "joint_blocks.15.", "joint_blocks.16.", "joint_blocks.17.", "joint_blocks.18.", "joint_blocks.19.", "joint_blocks.20.", "joint_blocks.21.", "joint_blocks.22.", "joint_blocks.23.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD3_2B", "display_name": "ModelMergeSD3_2B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeAuraflow": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "init_x_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "positional_encoding": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "cond_seq_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "register_tokens": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_layers.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_layers.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "modF.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_linear.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "init_x_linear.", "positional_encoding", "cond_seq_linear.", "register_tokens", "t_embedder.", "double_layers.0.", "double_layers.1.", "double_layers.2.", "double_layers.3.", "single_layers.0.", "single_layers.1.", "single_layers.2.", "single_layers.3.", "single_layers.4.", "single_layers.5.", "single_layers.6.", "single_layers.7.", "single_layers.8.", "single_layers.9.", "single_layers.10.", "single_layers.11.", "single_layers.12.", "single_layers.13.", "single_layers.14.", "single_layers.15.", "single_layers.16.", "single_layers.17.", "single_layers.18.", "single_layers.19.", "single_layers.20.", "single_layers.21.", "single_layers.22.", "single_layers.23.", "single_layers.24.", "single_layers.25.", "single_layers.26.", "single_layers.27.", "single_layers.28.", "single_layers.29.", "single_layers.30.", "single_layers.31.", "modF.", "final_linear."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeAuraflow", "display_name": "ModelMergeAuraflow", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeFlux1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "img_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "guidance_in": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "vector_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "double_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "single_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "img_in.", "time_in.", "guidance_in", "vector_in.", "txt_in.", "double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeFlux1", "display_name": "ModelMergeFlux1", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeSD35_Large": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "context_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "joint_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embed.", "x_embedder.", "context_embedder.", "y_embedder.", "t_embedder.", "joint_blocks.0.", "joint_blocks.1.", "joint_blocks.2.", "joint_blocks.3.", "joint_blocks.4.", "joint_blocks.5.", "joint_blocks.6.", "joint_blocks.7.", "joint_blocks.8.", "joint_blocks.9.", "joint_blocks.10.", "joint_blocks.11.", "joint_blocks.12.", "joint_blocks.13.", "joint_blocks.14.", "joint_blocks.15.", "joint_blocks.16.", "joint_blocks.17.", "joint_blocks.18.", "joint_blocks.19.", "joint_blocks.20.", "joint_blocks.21.", "joint_blocks.22.", "joint_blocks.23.", "joint_blocks.24.", "joint_blocks.25.", "joint_blocks.26.", "joint_blocks.27.", "joint_blocks.28.", "joint_blocks.29.", "joint_blocks.30.", "joint_blocks.31.", "joint_blocks.32.", "joint_blocks.33.", "joint_blocks.34.", "joint_blocks.35.", "joint_blocks.36.", "joint_blocks.37.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeSD35_Large", "display_name": "ModelMergeSD35_Large", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeMochiPreview": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_frequencies.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t5_y_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t5_yproj.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.40.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.41.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.42.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.43.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.44.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.45.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.46.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.47.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_frequencies.", "t_embedder.", "t5_y_embedder.", "t5_yproj.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "blocks.36.", "blocks.37.", "blocks.38.", "blocks.39.", "blocks.40.", "blocks.41.", "blocks.42.", "blocks.43.", "blocks.44.", "blocks.45.", "blocks.46.", "blocks.47.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeMochiPreview", "display_name": "ModelMergeMochiPreview", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeLTXV": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "patchify_proj.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adaln_single.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "caption_projection.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "scale_shift_table": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "proj_out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "patchify_proj.", "adaln_single.", "caption_projection.", "transformer_blocks.0.", "transformer_blocks.1.", "transformer_blocks.2.", "transformer_blocks.3.", "transformer_blocks.4.", "transformer_blocks.5.", "transformer_blocks.6.", "transformer_blocks.7.", "transformer_blocks.8.", "transformer_blocks.9.", "transformer_blocks.10.", "transformer_blocks.11.", "transformer_blocks.12.", "transformer_blocks.13.", "transformer_blocks.14.", "transformer_blocks.15.", "transformer_blocks.16.", "transformer_blocks.17.", "transformer_blocks.18.", "transformer_blocks.19.", "transformer_blocks.20.", "transformer_blocks.21.", "transformer_blocks.22.", "transformer_blocks.23.", "transformer_blocks.24.", "transformer_blocks.25.", "transformer_blocks.26.", "transformer_blocks.27.", "scale_shift_table", "proj_out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeLTXV", "display_name": "ModelMergeLTXV", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmos7B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "extra_pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "affline_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "extra_pos_embedder.", "x_embedder.", "t_embedder.", "affline_norm.", "blocks.block0.", "blocks.block1.", "blocks.block2.", "blocks.block3.", "blocks.block4.", "blocks.block5.", "blocks.block6.", "blocks.block7.", "blocks.block8.", "blocks.block9.", "blocks.block10.", "blocks.block11.", "blocks.block12.", "blocks.block13.", "blocks.block14.", "blocks.block15.", "blocks.block16.", "blocks.block17.", "blocks.block18.", "blocks.block19.", "blocks.block20.", "blocks.block21.", "blocks.block22.", "blocks.block23.", "blocks.block24.", "blocks.block25.", "blocks.block26.", "blocks.block27.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmos7B", "display_name": "ModelMergeCosmos7B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmos14B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "extra_pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "affline_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.block35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "extra_pos_embedder.", "x_embedder.", "t_embedder.", "affline_norm.", "blocks.block0.", "blocks.block1.", "blocks.block2.", "blocks.block3.", "blocks.block4.", "blocks.block5.", "blocks.block6.", "blocks.block7.", "blocks.block8.", "blocks.block9.", "blocks.block10.", "blocks.block11.", "blocks.block12.", "blocks.block13.", "blocks.block14.", "blocks.block15.", "blocks.block16.", "blocks.block17.", "blocks.block18.", "blocks.block19.", "blocks.block20.", "blocks.block21.", "blocks.block22.", "blocks.block23.", "blocks.block24.", "blocks.block25.", "blocks.block26.", "blocks.block27.", "blocks.block28.", "blocks.block29.", "blocks.block30.", "blocks.block31.", "blocks.block32.", "blocks.block33.", "blocks.block34.", "blocks.block35.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmos14B", "display_name": "ModelMergeCosmos14B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeWAN2_1": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "patch_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_projection.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "text_embedding.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "img_emb.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "head.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "patch_embedding.", "time_embedding.", "time_projection.", "text_embedding.", "img_emb.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "blocks.36.", "blocks.37.", "blocks.38.", "blocks.39.", "head."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeWAN2_1", "display_name": "ModelMergeWAN2_1", "description": "1.3B model has 30 blocks, 14B model has 40 blocks. Image to video model has the extra img_emb.", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmosPredict2_2B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedding_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "x_embedder.", "t_embedder.", "t_embedding_norm.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmosPredict2_2B", "display_name": "ModelMergeCosmosPredict2_2B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeCosmosPredict2_14B": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "x_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedder.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "t_embedding_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "final_layer.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embedder.", "x_embedder.", "t_embedder.", "t_embedding_norm.", "blocks.0.", "blocks.1.", "blocks.2.", "blocks.3.", "blocks.4.", "blocks.5.", "blocks.6.", "blocks.7.", "blocks.8.", "blocks.9.", "blocks.10.", "blocks.11.", "blocks.12.", "blocks.13.", "blocks.14.", "blocks.15.", "blocks.16.", "blocks.17.", "blocks.18.", "blocks.19.", "blocks.20.", "blocks.21.", "blocks.22.", "blocks.23.", "blocks.24.", "blocks.25.", "blocks.26.", "blocks.27.", "blocks.28.", "blocks.29.", "blocks.30.", "blocks.31.", "blocks.32.", "blocks.33.", "blocks.34.", "blocks.35.", "final_layer."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeCosmosPredict2_14B", "display_name": "ModelMergeCosmosPredict2_14B", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "ModelMergeQwenImage": {"input": {"required": {"model1": ["MODEL"], "model2": ["MODEL"], "pos_embeds.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "img_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_norm.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "txt_in.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "time_text_embed.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.0.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.1.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.2.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.3.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.4.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.5.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.6.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.7.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.8.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.9.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.10.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.11.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.12.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.13.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.14.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.15.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.16.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.17.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.18.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.19.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.20.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.21.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.22.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.23.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.24.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.25.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.26.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.27.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.28.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.29.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.30.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.31.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.32.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.33.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.34.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.35.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.36.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.37.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.38.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.39.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.40.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.41.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.42.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.43.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.44.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.45.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.46.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.47.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.48.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.49.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.50.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.51.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.52.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.53.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.54.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.55.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.56.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.57.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.58.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "transformer_blocks.59.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "proj_out.": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model1", "model2", "pos_embeds.", "img_in.", "txt_norm.", "txt_in.", "time_text_embed.", "transformer_blocks.0.", "transformer_blocks.1.", "transformer_blocks.2.", "transformer_blocks.3.", "transformer_blocks.4.", "transformer_blocks.5.", "transformer_blocks.6.", "transformer_blocks.7.", "transformer_blocks.8.", "transformer_blocks.9.", "transformer_blocks.10.", "transformer_blocks.11.", "transformer_blocks.12.", "transformer_blocks.13.", "transformer_blocks.14.", "transformer_blocks.15.", "transformer_blocks.16.", "transformer_blocks.17.", "transformer_blocks.18.", "transformer_blocks.19.", "transformer_blocks.20.", "transformer_blocks.21.", "transformer_blocks.22.", "transformer_blocks.23.", "transformer_blocks.24.", "transformer_blocks.25.", "transformer_blocks.26.", "transformer_blocks.27.", "transformer_blocks.28.", "transformer_blocks.29.", "transformer_blocks.30.", "transformer_blocks.31.", "transformer_blocks.32.", "transformer_blocks.33.", "transformer_blocks.34.", "transformer_blocks.35.", "transformer_blocks.36.", "transformer_blocks.37.", "transformer_blocks.38.", "transformer_blocks.39.", "transformer_blocks.40.", "transformer_blocks.41.", "transformer_blocks.42.", "transformer_blocks.43.", "transformer_blocks.44.", "transformer_blocks.45.", "transformer_blocks.46.", "transformer_blocks.47.", "transformer_blocks.48.", "transformer_blocks.49.", "transformer_blocks.50.", "transformer_blocks.51.", "transformer_blocks.52.", "transformer_blocks.53.", "transformer_blocks.54.", "transformer_blocks.55.", "transformer_blocks.56.", "transformer_blocks.57.", "transformer_blocks.58.", "transformer_blocks.59.", "proj_out."]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ModelMergeQwenImage", "display_name": "ModelMergeQwenImage", "description": "", "python_module": "comfy_extras.nodes_model_merging_model_specific", "category": "advanced/model_merging/model_specific", "output_node": false}, "PerturbedAttentionGuidance": {"input": {"required": {"model": ["MODEL", {}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.01, "round": 0.01}]}}, "input_order": {"required": ["model", "scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "PerturbedAttentionGuidance", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_pag", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "AlignYourStepsScheduler": {"input": {"required": {"model_type": ["COMBO", {"multiselect": false, "options": ["SD1", "SDXL", "SVD"]}], "steps": ["INT", {"default": 10, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model_type", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "AlignYourStepsScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_align_your_steps", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "UNetSelfAttentionMultiply": {"input": {"required": {"model": ["MODEL", {}], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "q", "k", "v", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "UNetSelfAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "UNetCrossAttentionMultiply": {"input": {"required": {"model": ["MODEL", {}], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "q", "k", "v", "out"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "UNetCrossAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "CLIPAttentionMultiply": {"input": {"required": {"clip": ["CLIP", {}], "q": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "k": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "v": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "out": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip", "q", "k", "v", "out"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "CLIPAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "UNetTemporalAttentionMultiply": {"input": {"required": {"model": ["MODEL", {}], "self_structural": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "self_temporal": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "cross_structural": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "cross_temporal": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "self_structural", "self_temporal", "cross_structural", "cross_temporal"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "UNetTemporalAttentionMultiply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_attention_multiply", "category": "_for_testing/attention_experiments", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "SamplerLCMUpscale": {"input": {"required": {"scale_ratio": ["FLOAT", {"default": 1.0, "min": 0.1, "max": 20.0, "step": 0.01}], "scale_steps": ["INT", {"default": -1, "min": -1, "max": 1000, "step": 1}], "upscale_method": ["COMBO", {"multiselect": false, "options": ["bislerp", "nearest-exact", "bilinear", "area", "bicubic"]}]}}, "input_order": {"required": ["scale_ratio", "scale_steps", "upscale_method"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "output_tooltips": [null], "name": "SamplerLCMUpscale", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_advanced_samplers", "category": "sampling/custom_sampling/samplers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SamplerEulerCFGpp": {"input": {"required": {"version": ["COMBO", {"multiselect": false, "options": ["regular", "alternative"]}]}}, "input_order": {"required": ["version"]}, "output": ["SAMPLER"], "output_is_list": [false], "output_name": ["SAMPLER"], "output_tooltips": [null], "name": "SamplerEulerCFGpp", "display_name": "SamplerEulerCFG++", "description": "", "python_module": "comfy_extras.nodes_advanced_samplers", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "WebcamCapture": {"input": {"required": {"image": ["WEBCAM", {}], "width": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "height": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "capture_on_queue": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "width", "height", "capture_on_queue"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "WebcamCapture", "display_name": "Webcam Capture", "description": "", "python_module": "comfy_extras.nodes_webcam", "category": "image", "output_node": false}, "EmptyLatentAudio": {"input": {"required": {"seconds": ["FLOAT", {"default": 47.6, "min": 1.0, "max": 1000.0, "step": 0.1}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["seconds", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentAudio", "display_name": "Empty Latent Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "VAEEncodeAudio": {"input": {"required": {"audio": ["AUDIO"], "vae": ["VAE"]}}, "input_order": {"required": ["audio", "vae"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VAEEncodeAudio", "display_name": "VAE Encode Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "VAEDecodeAudio": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"]}}, "input_order": {"required": ["samples", "vae"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "VAEDecodeAudio", "display_name": "VAE Decode Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "latent/audio", "output_node": false}, "SaveAudio": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudio", "display_name": "Save Audio (FLAC)", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "SaveAudioMP3": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}], "quality": [["V0", "128k", "320k"], {"default": "V0"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix", "quality"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudioMP3", "display_name": "Save Audio (MP3)", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "SaveAudioOpus": {"input": {"required": {"audio": ["AUDIO"], "filename_prefix": ["STRING", {"default": "audio/ComfyUI"}], "quality": [["64k", "96k", "128k", "192k", "320k"], {"default": "128k"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio", "filename_prefix", "quality"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveAudioOpus", "display_name": "Save Audio (Opus)", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "LoadAudio": {"input": {"required": {"audio": [[], {"audio_upload": true}]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "LoadAudio", "display_name": "Load Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "PreviewAudio": {"input": {"required": {"audio": ["AUDIO"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["audio"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAudio", "display_name": "Preview Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": true}, "ConditioningStableAudio": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "seconds_start": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1000.0, "step": 0.1}], "seconds_total": ["FLOAT", {"default": 47.0, "min": 0.0, "max": 1000.0, "step": 0.1}]}}, "input_order": {"required": ["positive", "negative", "seconds_start", "seconds_total"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ConditioningStableAudio", "display_name": "ConditioningStableAudio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "conditioning", "output_node": false}, "RecordAudio": {"input": {"required": {"audio": ["AUDIO_RECORD", {}]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "RecordAudio", "display_name": "Record Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "TrimAudioDuration": {"input": {"required": {"audio": ["AUDIO"], "start_index": ["FLOAT", {"default": 0.0, "min": -18446744073709551615, "max": 18446744073709551615, "step": 0.01, "tooltip": "Start time in seconds, can be negative to count from the end (supports sub-seconds)."}], "duration": ["FLOAT", {"default": 60.0, "min": 0.0, "step": 0.01, "tooltip": "Duration in seconds"}]}}, "input_order": {"required": ["audio", "start_index", "duration"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "TrimAudioDuration", "display_name": "Trim Audio Duration", "description": "Trim audio tensor into chosen time range.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "SplitAudioChannels": {"input": {"required": {"audio": ["AUDIO"]}}, "input_order": {"required": ["audio"]}, "output": ["AUDIO", "AUDIO"], "output_is_list": [false, false], "output_name": ["left", "right"], "name": "SplitAudioChannels", "display_name": "Split Audio Channels", "description": "Separates the audio into left and right channels.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "AudioConcat": {"input": {"required": {"audio1": ["AUDIO"], "audio2": ["AUDIO"], "direction": [["after", "before"], {"default": "after", "tooltip": "Whether to append audio2 after or before audio1."}]}}, "input_order": {"required": ["audio1", "audio2", "direction"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioConcat", "display_name": "Audio Concat", "description": "Concatenates the audio1 to audio2 in the specified direction.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "AudioMerge": {"input": {"required": {"audio1": ["AUDIO"], "audio2": ["AUDIO"], "merge_method": [["add", "mean", "subtract", "multiply"], {"tooltip": "The method used to combine the audio waveforms."}]}}, "input_order": {"required": ["audio1", "audio2", "merge_method"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioMerge", "display_name": "Audio Merge", "description": "Combine two audio tracks by overlaying their waveforms.", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "AudioAdjustVolume": {"input": {"required": {"audio": ["AUDIO"], "volume": ["INT", {"default": 1.0, "min": -100, "max": 100, "tooltip": "Volume adjustment in decibels (dB). 0 = no change, +6 = double, -6 = half, etc"}]}}, "input_order": {"required": ["audio", "volume"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "AudioAdjustVolume", "display_name": "Audio Adjust Volume", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "EmptyAudio": {"input": {"required": {"duration": ["FLOAT", {"default": 60.0, "min": 0.0, "max": 18446744073709551615, "step": 0.01, "tooltip": "Duration of the empty audio clip in seconds"}], "sample_rate": ["INT", {"default": 44100, "tooltip": "Sample rate of the empty audio clip."}], "channels": ["INT", {"default": 2, "min": 1, "max": 2, "tooltip": "Number of audio channels (1 for mono, 2 for stereo)."}]}}, "input_order": {"required": ["duration", "sample_rate", "channels"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "name": "EmptyAudio", "display_name": "Empty Audio", "description": "", "python_module": "comfy_extras.nodes_audio", "category": "audio", "output_node": false}, "TripleCLIPLoader": {"input": {"required": {"clip_name1": ["COMBO", {"multiselect": false, "options": []}], "clip_name2": ["COMBO", {"multiselect": false, "options": []}], "clip_name3": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "TripleCLIPLoader", "display_name": null, "description": "[Recipes]\n\nsd3: clip-l, clip-g, t5", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptySD3LatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptySD3LatentImage", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "latent/sd3", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeSD3": {"input": {"required": {"clip": ["CLIP", {}], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "empty_padding": ["COMBO", {"multiselect": false, "options": ["none", "empty_prompt"]}]}}, "input_order": {"required": ["clip", "clip_l", "clip_g", "t5xxl", "empty_padding"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeSD3", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ControlNetApplySD3": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "control_net": ["CONTROL_NET", {}], "vae": ["VAE", {}], "image": ["IMAGE", {}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["positive", "negative", "control_net", "vae", "image", "strength", "start_percent", "end_percent"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "output_tooltips": [null, null], "name": "ControlNetApplySD3", "display_name": "Apply Controlnet with VAE", "description": "", "python_module": "comfy_extras.nodes_sd3", "category": "conditioning/controlnet", "output_node": false, "deprecated": true, "experimental": false, "api_node": false}, "SkipLayerGuidanceSD3": {"input": {"required": {"model": ["MODEL", {}], "layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "layers", "scale", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SkipLayerGuidanceSD3", "display_name": null, "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.", "python_module": "comfy_extras.nodes_sd3", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "GITSScheduler": {"input": {"required": {"coeff": ["FLOAT", {"default": 1.2, "min": 0.8, "max": 1.5, "step": 0.05}], "steps": ["INT", {"default": 10, "min": 2, "max": 1000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["coeff", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "GITSScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_gits", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SetUnionControlNetType": {"input": {"required": {"control_net": ["CONTROL_NET", {}], "type": ["COMBO", {"multiselect": false, "options": ["auto", "openpose", "depth", "hed/pidi/scribble/ted", "canny/lineart/anime_lineart/mlsd", "normal", "segment", "tile", "repaint"]}]}}, "input_order": {"required": ["control_net", "type"]}, "output": ["CONTROL_NET"], "output_is_list": [false], "output_name": ["CONTROL_NET"], "output_tooltips": [null], "name": "SetUnionControlNetType", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_controlnet", "category": "conditioning/controlnet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ControlNetInpaintingAliMamaApply": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "control_net": ["CONTROL_NET", {}], "vae": ["VAE", {}], "image": ["IMAGE", {}], "mask": ["MASK", {}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["positive", "negative", "control_net", "vae", "image", "mask", "strength", "start_percent", "end_percent"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "output_tooltips": [null, null], "name": "ControlNetInpaintingAliMamaApply", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_controlnet", "category": "conditioning/controlnet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeHunyuanDiT": {"input": {"required": {"clip": ["CLIP", {}], "bert": ["STRING", {"multiline": true, "dynamicPrompts": true}], "mt5xl": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "bert", "mt5xl"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeHunyuanDiT", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TextEncodeHunyuanVideo_ImageToVideo": {"input": {"required": {"clip": ["CLIP", {}], "clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}], "image_interleave": ["INT", {"tooltip": "How much the image influences things vs the text prompt. Higher number means more influence from the text prompt.", "default": 2, "min": 1, "max": 512}]}}, "input_order": {"required": ["clip", "clip_vision_output", "prompt", "image_interleave"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeHunyuanVideo_ImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyHunyuanLatentVideo": {"input": {"required": {"width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 25, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyHunyuanLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "HunyuanImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 53, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "guidance_type": ["COMBO", {"multiselect": false, "options": ["v1 (concat)", "v2 (replace)", "custom"]}]}, "optional": {"start_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "vae", "width", "height", "length", "batch_size", "guidance_type"], "optional": ["start_image"]}, "output": ["CONDITIONING", "LATENT"], "output_is_list": [false, false], "output_name": ["positive", "latent"], "output_tooltips": [null, null], "name": "HunyuanImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyHunyuanImageLatent": {"input": {"required": {"width": ["INT", {"default": 2048, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 2048, "min": 64, "max": 16384, "step": 32}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyHunyuanImageLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "latent", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "HunyuanRefinerLatent": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "latent": ["LATENT", {}], "noise_augmentation": ["FLOAT", {"default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "latent", "noise_augmentation"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "HunyuanRefinerLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hunyuan", "category": "sd", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "Epsilon Scaling": {"input": {"required": {"model": ["MODEL", {}], "scaling_factor": ["FLOAT", {"default": 1.005, "min": 0.5, "max": 1.5, "step": 0.001, "display": "number"}]}}, "input_order": {"required": ["model", "scaling_factor"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "Epsilon Scaling", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_eps", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TemporalScoreRescaling": {"input": {"required": {"model": ["MODEL", {}], "tsr_k": ["FLOAT", {"tooltip": "Controls the rescaling strength.\nLower k produces more detailed results; higher k produces smoother results in image generation. Setting k = 1 disables rescaling.", "default": 0.95, "min": 0.01, "max": 100.0, "step": 0.001, "display": "number"}], "tsr_sigma": ["FLOAT", {"tooltip": "Controls how early rescaling takes effect.\nLarger values take effect earlier.", "default": 1.0, "min": 0.01, "max": 100.0, "step": 0.001, "display": "number"}]}}, "input_order": {"required": ["model", "tsr_k", "tsr_sigma"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "TemporalScoreRescaling", "display_name": "TSR - Temporal Score Rescaling", "description": "[Post-CFG Function]\nTSR - Temporal Score Rescaling (2510.01184)\n\nRescaling the model's score or noise to steer the sampling diversity.\n", "python_module": "comfy_extras.nodes_eps", "category": "model_patches/unet", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeFlux": {"input": {"required": {"clip": ["CLIP", {}], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "guidance": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["clip", "clip_l", "t5xxl", "guidance"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeFlux", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxGuidance": {"input": {"required": {"conditioning": ["CONDITIONING", {}], "guidance": ["FLOAT", {"default": 3.5, "min": 0.0, "max": 100.0, "step": 0.1}]}}, "input_order": {"required": ["conditioning", "guidance"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "FluxGuidance", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxDisableGuidance": {"input": {"required": {"conditioning": ["CONDITIONING", {}]}}, "input_order": {"required": ["conditioning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "FluxDisableGuidance", "display_name": null, "description": "This node completely disables the guidance embed on Flux and Flux like models", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxKontextImageScale": {"input": {"required": {"image": ["IMAGE", {}]}}, "input_order": {"required": ["image"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxKontextImageScale", "display_name": null, "description": "This node resizes the image to one that is more optimal for flux kontext.", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FluxKontextMultiReferenceLatentMethod": {"input": {"required": {"conditioning": ["CONDITIONING", {}], "reference_latents_method": ["COMBO", {"multiselect": false, "options": ["offset", "index", "uxo/uno"]}]}}, "input_order": {"required": ["conditioning", "reference_latents_method"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "FluxKontextMultiReferenceLatentMethod", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_flux", "category": "advanced/conditioning/flux", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LoraSave": {"input": {"required": {"filename_prefix": ["STRING", {"default": "loras/ComfyUI_extracted_lora", "multiline": false}], "rank": ["INT", {"default": 8, "min": 1, "max": 4096, "step": 1}], "lora_type": ["COMBO", {"multiselect": false, "options": ["standard", "full_diff"]}], "bias_diff": ["BOOLEAN", {"default": true}]}, "optional": {"model_diff": ["MODEL", {"tooltip": "The ModelSubtract output to be converted to a lora."}], "text_encoder_diff": ["CLIP", {"tooltip": "The CLIPSubtract output to be converted to a lora."}]}, "hidden": {"prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["filename_prefix", "rank", "lora_type", "bias_diff"], "optional": ["model_diff", "text_encoder_diff"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "LoraSave", "display_name": "Extract and Save Lora", "description": "", "python_module": "comfy_extras.nodes_lora_extract", "category": "_for_testing", "output_node": true, "deprecated": false, "experimental": true, "api_node": false}, "TorchCompileModel": {"input": {"required": {"model": ["MODEL", {}], "backend": ["COMBO", {"multiselect": false, "options": ["inductor", "cudagraphs"]}]}}, "input_order": {"required": ["model", "backend"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "TorchCompileModel", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_torch_compile", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "EmptyMochiLatentVideo": {"input": {"required": {"width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 25, "min": 7, "max": 16384, "step": 6}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyMochiLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_mochi", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SkipLayerGuidanceDiT": {"input": {"required": {"model": ["MODEL", {}], "double_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "single_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 10.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.01, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}], "rescaling_scale": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["model", "double_layers", "single_layers", "scale", "start_percent", "end_percent", "rescaling_scale"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SkipLayerGuidanceDiT", "display_name": null, "description": "Generic version of SkipLayerGuidance node that can be used on every DiT model.", "python_module": "comfy_extras.nodes_slg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "SkipLayerGuidanceDiTSimple": {"input": {"required": {"model": ["MODEL", {}], "double_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "single_layers": ["STRING", {"default": "7, 8, 9", "multiline": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["model", "double_layers", "single_layers", "start_percent", "end_percent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "SkipLayerGuidanceDiTSimple", "display_name": null, "description": "Simple version of the SkipLayerGuidanceDiT node that only modifies the uncond pass.", "python_module": "comfy_extras.nodes_slg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "Mahiro": {"input": {"required": {"model": ["MODEL", {}]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "Mahiro", "display_name": "Mahiro is so cute that she deserves a better guidance function!! (\u3002\u30fb\u03c9\u30fb\u3002)", "description": "Modify the guidance to scale more on the 'direction' of the positive prompt rather than the difference between the negative prompt.", "python_module": "comfy_extras.nodes_mahiro", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "EmptyLTXVLatentVideo": {"input": {"required": {"width": ["INT", {"default": 768, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 32}], "length": ["INT", {"default": 97, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyLTXVLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "latent/video/ltxv", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVImgToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "image": ["IMAGE", {}], "width": ["INT", {"default": 768, "min": 64, "max": 16384, "step": 32}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 32}], "length": ["INT", {"default": 97, "min": 9, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}]}}, "input_order": {"required": ["positive", "negative", "vae", "image", "width", "height", "length", "batch_size", "strength"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "LTXVImgToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelSamplingLTXV": {"input": {"required": {"model": ["MODEL", {}], "max_shift": ["FLOAT", {"default": 2.05, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 100.0, "step": 0.01}]}, "optional": {"latent": ["LATENT", {}]}}, "input_order": {"required": ["model", "max_shift", "base_shift"], "optional": ["latent"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "ModelSamplingLTXV", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "advanced/model", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVConditioning": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "frame_rate": ["FLOAT", {"default": 25.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "frame_rate"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "output_tooltips": [null, null], "name": "LTXVConditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVScheduler": {"input": {"required": {"steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "max_shift": ["FLOAT", {"default": 2.05, "min": 0.0, "max": 100.0, "step": 0.01}], "base_shift": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 100.0, "step": 0.01}], "stretch": ["BOOLEAN", {"tooltip": "Stretch the sigmas to be in the range [terminal, 1].", "default": true}], "terminal": ["FLOAT", {"tooltip": "The terminal value of the sigmas after stretching.", "default": 0.1, "min": 0.0, "max": 0.99, "step": 0.01}]}, "optional": {"latent": ["LATENT", {}]}}, "input_order": {"required": ["steps", "max_shift", "base_shift", "stretch", "terminal"], "optional": ["latent"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "LTXVScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVAddGuide": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "latent": ["LATENT", {}], "image": ["IMAGE", {"tooltip": "Image or video to condition the latent video on. Must be 8*n + 1 frames. If the video is not 8*n + 1 frames, it will be cropped to the nearest 8*n + 1 frames."}], "frame_idx": ["INT", {"tooltip": "Frame index to start the conditioning at. For single-frame images or videos with 1-8 frames, any frame_idx value is acceptable. For videos with 9+ frames, frame_idx must be divisible by 8, otherwise it will be rounded down to the nearest multiple of 8. Negative values are counted from the end of the video.", "default": 0, "min": -9999, "max": 9999}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["positive", "negative", "vae", "latent", "image", "frame_idx", "strength"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "LTXVAddGuide", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVPreprocess": {"input": {"required": {"image": ["IMAGE", {}], "img_compression": ["INT", {"tooltip": "Amount of compression to apply on image.", "default": 35, "min": 0, "max": 100}]}}, "input_order": {"required": ["image", "img_compression"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["output_image"], "output_tooltips": [null], "name": "LTXVPreprocess", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "image", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LTXVCropGuides": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "latent": ["LATENT", {}]}}, "input_order": {"required": ["positive", "negative", "latent"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "LTXVCropGuides", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lt", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CreateHookLora": {"input": {"required": {"lora_name": [[]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["lora_name", "strength_model", "strength_clip"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookLora", "display_name": "Create Hook LoRA", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookLoraModelOnly": {"input": {"required": {"lora_name": [[]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["lora_name", "strength_model"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookLoraModelOnly", "display_name": "Create Hook LoRA (MO)", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookModelAsLora": {"input": {"required": {"ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["ckpt_name", "strength_model", "strength_clip"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookModelAsLora", "display_name": "Create Hook Model as LoRA", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "CreateHookModelAsLoraModelOnly": {"input": {"required": {"ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"prev_hooks": ["HOOKS"]}}, "input_order": {"required": ["ckpt_name", "strength_model"], "optional": ["prev_hooks"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CreateHookModelAsLoraModelOnly", "display_name": "Create Hook Model as LoRA (MO)", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/create", "output_node": false, "experimental": true}, "SetHookKeyframes": {"input": {"required": {"hooks": ["HOOKS"]}, "optional": {"hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["hooks"], "optional": ["hook_kf"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "SetHookKeyframes", "display_name": "Set Hook Keyframes", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframe": {"input": {"required": {"strength_mult": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["strength_mult", "start_percent"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframe", "display_name": "Create Hook Keyframe", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframesInterpolated": {"input": {"required": {"strength_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "keyframes_count": ["INT", {"default": 5, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["strength_start", "strength_end", "interpolation", "start_percent", "end_percent", "keyframes_count", "print_keyframes"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframesInterpolated", "display_name": "Create Hook Keyframes Interp.", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CreateHookKeyframesFromFloats": {"input": {"required": {"floats_strength": ["FLOATS", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"]}}, "input_order": {"required": ["floats_strength", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_hook_kf"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "CreateHookKeyframesFromFloats", "display_name": "Create Hook Keyframes From Floats", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/scheduling", "output_node": false, "experimental": true}, "CombineHooks2": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks2", "display_name": "Combine Hooks [2]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "CombineHooks4": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"], "hooks_C": ["HOOKS"], "hooks_D": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B", "hooks_C", "hooks_D"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks4", "display_name": "Combine Hooks [4]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "CombineHooks8": {"input": {"required": {}, "optional": {"hooks_A": ["HOOKS"], "hooks_B": ["HOOKS"], "hooks_C": ["HOOKS"], "hooks_D": ["HOOKS"], "hooks_E": ["HOOKS"], "hooks_F": ["HOOKS"], "hooks_G": ["HOOKS"], "hooks_H": ["HOOKS"]}}, "input_order": {"required": [], "optional": ["hooks_A", "hooks_B", "hooks_C", "hooks_D", "hooks_E", "hooks_F", "hooks_G", "hooks_H"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "CombineHooks8", "display_name": "Combine Hooks [8]", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/combine", "output_node": false, "experimental": true}, "ConditioningSetProperties": {"input": {"required": {"cond_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["cond_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetProperties", "display_name": "Cond Set Props", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "ConditioningSetPropertiesAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["cond", "cond_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetPropertiesAndCombine", "display_name": "Cond Set Props Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "PairConditioningSetProperties": {"input": {"required": {"positive_NEW": ["CONDITIONING"], "negative_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["positive_NEW", "negative_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetProperties", "display_name": "Cond Pair Set Props", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "PairConditioningSetPropertiesAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_NEW": ["CONDITIONING"], "negative_NEW": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"mask": ["MASK"], "hooks": ["HOOKS"], "timesteps": ["TIMESTEPS_RANGE"]}}, "input_order": {"required": ["positive", "negative", "positive_NEW", "negative_NEW", "strength", "set_cond_area"], "optional": ["mask", "hooks", "timesteps"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetPropertiesAndCombine", "display_name": "Cond Pair Set Props Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "ConditioningSetDefaultCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_DEFAULT": ["CONDITIONING"]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["cond", "cond_DEFAULT"], "optional": ["hooks"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ConditioningSetDefaultCombine", "display_name": "Cond Set Default Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond single", "output_node": false, "experimental": true}, "PairConditioningSetDefaultCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_DEFAULT": ["CONDITIONING"], "negative_DEFAULT": ["CONDITIONING"]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["positive", "negative", "positive_DEFAULT", "negative_DEFAULT"], "optional": ["hooks"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningSetDefaultCombine", "display_name": "Cond Pair Set Default Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "PairConditioningCombine": {"input": {"required": {"positive_A": ["CONDITIONING"], "negative_A": ["CONDITIONING"], "positive_B": ["CONDITIONING"], "negative_B": ["CONDITIONING"]}}, "input_order": {"required": ["positive_A", "negative_A", "positive_B", "negative_B"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "PairConditioningCombine", "display_name": "Cond Pair Combine", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/cond pair", "output_node": false, "experimental": true}, "SetClipHooks": {"input": {"required": {"clip": ["CLIP"], "apply_to_conds": ["BOOLEAN", {"default": true}], "schedule_clip": ["BOOLEAN", {"default": false}]}, "optional": {"hooks": ["HOOKS"]}}, "input_order": {"required": ["clip", "apply_to_conds", "schedule_clip"], "optional": ["hooks"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "name": "SetClipHooks", "display_name": "Set CLIP Hooks", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks/clip", "output_node": false, "experimental": true}, "ConditioningTimestepsRange": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["start_percent", "end_percent"]}, "output": ["TIMESTEPS_RANGE", "TIMESTEPS_RANGE", "TIMESTEPS_RANGE"], "output_is_list": [false, false, false], "output_name": ["TIMESTEPS_RANGE", "BEFORE_RANGE", "AFTER_RANGE"], "name": "ConditioningTimestepsRange", "display_name": "Timesteps Range", "description": "", "python_module": "comfy_extras.nodes_hooks", "category": "advanced/hooks", "output_node": false, "experimental": true}, "Load3D": {"input": {"required": {"model_file": [[], {"file_upload": true}], "image": ["LOAD_3D", {}], "width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["model_file", "image", "width", "height"]}, "output": ["IMAGE", "MASK", "STRING", "IMAGE", "IMAGE", "LOAD3D_CAMERA", "VIDEO"], "output_is_list": [false, false, false, false, false, false, false], "output_name": ["image", "mask", "mesh_path", "normal", "lineart", "camera_info", "recording_video"], "name": "Load3D", "display_name": "Load 3D", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": false, "experimental": true}, "Load3DAnimation": {"input": {"required": {"model_file": [[], {"file_upload": true}], "image": ["LOAD_3D_ANIMATION", {}], "width": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}], "height": ["INT", {"default": 1024, "min": 1, "max": 4096, "step": 1}]}}, "input_order": {"required": ["model_file", "image", "width", "height"]}, "output": ["IMAGE", "MASK", "STRING", "IMAGE", "LOAD3D_CAMERA", "VIDEO"], "output_is_list": [false, false, false, false, false, false], "output_name": ["image", "mask", "mesh_path", "normal", "camera_info", "recording_video"], "name": "Load3DAnimation", "display_name": "Load 3D - Animation", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": false, "experimental": true}, "Preview3D": {"input": {"required": {"model_file": ["STRING", {"default": "", "multiline": false}]}, "optional": {"camera_info": ["LOAD3D_CAMERA", {}]}}, "input_order": {"required": ["model_file"], "optional": ["camera_info"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Preview3D", "display_name": "Preview 3D", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": true, "experimental": true}, "Preview3DAnimation": {"input": {"required": {"model_file": ["STRING", {"default": "", "multiline": false}]}, "optional": {"camera_info": ["LOAD3D_CAMERA", {}]}}, "input_order": {"required": ["model_file"], "optional": ["camera_info"]}, "output": [], "output_is_list": [], "output_name": [], "name": "Preview3DAnimation", "display_name": "Preview 3D - Animation", "description": "", "python_module": "comfy_extras.nodes_load_3d", "category": "3d", "output_node": true, "experimental": true}, "EmptyCosmosLatentVideo": {"input": {"required": {"width": ["INT", {"default": 1280, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 704, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 121, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "length", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyCosmosLatentVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CosmosImageToVideoLatent": {"input": {"required": {"vae": ["VAE", {}], "width": ["INT", {"default": 1280, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 704, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 121, "min": 1, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image", "end_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "CosmosImageToVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "conditioning/inpaint", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CosmosPredict2ImageToVideoLatent": {"input": {"required": {"vae": ["VAE", {}], "width": ["INT", {"default": 848, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 93, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image", "end_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "CosmosPredict2ImageToVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cosmos", "category": "conditioning/inpaint", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "SaveWEBM": {"input": {"required": {"images": ["IMAGE", {}], "filename_prefix": ["STRING", {"default": "ComfyUI", "multiline": false}], "codec": ["COMBO", {"multiselect": false, "options": ["vp9", "av1"]}], "fps": ["FLOAT", {"default": 24.0, "min": 0.01, "max": 1000.0, "step": 0.01}], "crf": ["FLOAT", {"tooltip": "Higher crf means lower quality with a smaller file size, lower crf means higher quality higher filesize.", "default": 32.0, "min": 0, "max": 63.0, "step": 1}]}, "hidden": {"prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["images", "filename_prefix", "codec", "fps", "crf"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "SaveWEBM", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": true, "deprecated": false, "experimental": true, "api_node": false}, "SaveVideo": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to save."}], "filename_prefix": ["STRING", {"tooltip": "The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.", "default": "video/ComfyUI", "multiline": false}], "format": ["COMBO", {"tooltip": "The format to save the video as.", "default": "auto", "multiselect": false, "options": ["auto", "mp4"]}], "codec": ["COMBO", {"tooltip": "The codec to use for the video.", "default": "auto", "multiselect": false, "options": ["auto", "h264"]}]}, "hidden": {"prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["video", "filename_prefix", "format", "codec"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "SaveVideo", "display_name": "Save Video", "description": "Saves the input images to your ComfyUI output directory.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": true, "deprecated": false, "experimental": false, "api_node": false}, "CreateVideo": {"input": {"required": {"images": ["IMAGE", {"tooltip": "The images to create a video from."}], "fps": ["FLOAT", {"default": 30.0, "min": 1.0, "max": 120.0, "step": 1.0}]}, "optional": {"audio": ["AUDIO", {"tooltip": "The audio to add to the video."}]}}, "input_order": {"required": ["images", "fps"], "optional": ["audio"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "CreateVideo", "display_name": "Create Video", "description": "Create a video from images.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "GetVideoComponents": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to extract components from."}]}}, "input_order": {"required": ["video"]}, "output": ["IMAGE", "AUDIO", "FLOAT"], "output_is_list": [false, false, false], "output_name": ["images", "audio", "fps"], "output_tooltips": [null, null, null], "name": "GetVideoComponents", "display_name": "Get Video Components", "description": "Extracts all components from a video: frames, audio, and framerate.", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LoadVideo": {"input": {"required": {"file": ["COMBO", {"multiselect": false, "options": [], "video_upload": true}]}}, "input_order": {"required": ["file"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LoadVideo", "display_name": "Load Video", "description": "", "python_module": "comfy_extras.nodes_video", "category": "image/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeLumina2": {"input": {"required": {"system_prompt": ["COMBO", {"tooltip": "Lumina2 provide two types of system prompts:Superior: You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts. Alignment: You are an assistant designed to generate high-quality images with the highest degree of image-text alignment based on textual prompts.", "multiselect": false, "options": ["superior", "alignment"]}], "user_prompt": ["STRING", {"tooltip": "The text to be encoded.", "multiline": true, "dynamicPrompts": true}], "clip": ["CLIP", {"tooltip": "The CLIP model used for encoding the text."}]}}, "input_order": {"required": ["system_prompt", "user_prompt", "clip"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": ["A conditioning containing the embedded text used to guide the diffusion model."], "name": "CLIPTextEncodeLumina2", "display_name": "CLIP Text Encode for Lumina2", "description": "Encodes a system prompt and a user prompt using a CLIP model into an embedding that can be used to guide the diffusion model towards generating specific images.", "python_module": "comfy_extras.nodes_lumina2", "category": "conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RenormCFG": {"input": {"required": {"model": ["MODEL", {}], "cfg_trunc": ["FLOAT", {"default": 100, "min": 0.0, "max": 100.0, "step": 0.01}], "renorm_cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "cfg_trunc", "renorm_cfg"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "RenormCFG", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lumina2", "category": "advanced/model", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanTrackToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "tracks": ["STRING", {"default": "[]", "multiline": true}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "temperature": ["FLOAT", {"default": 220.0, "min": 1.0, "max": 1000.0, "step": 0.1}], "topk": ["INT", {"default": 2, "min": 1, "max": 10}], "start_image": ["IMAGE", {}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "tracks", "width", "height", "length", "batch_size", "temperature", "topk", "start_image"], "optional": ["clip_vision_output"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanTrackToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanFunControlToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "control_video": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanFunControlToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "Wan22FunControlToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"ref_image": ["IMAGE", {}], "control_video": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["ref_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "Wan22FunControlToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanFunInpaintToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "end_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanFunInpaintToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanFirstLastFrameToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_start_image": ["CLIP_VISION_OUTPUT", {}], "clip_vision_end_image": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "end_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_start_image", "clip_vision_end_image", "start_image", "end_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanFirstLastFrameToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanVaceToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1000.0, "step": 0.01}]}, "optional": {"control_video": ["IMAGE", {}], "control_masks": ["MASK", {}], "reference_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size", "strength"], "optional": ["control_video", "control_masks", "reference_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["positive", "negative", "latent", "trim_latent"], "output_tooltips": [null, null, null, null], "name": "WanVaceToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TrimVideoLatent": {"input": {"required": {"samples": ["LATENT", {}], "trim_amount": ["INT", {"default": 0, "min": 0, "max": 99999}]}}, "input_order": {"required": ["samples", "trim_amount"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "TrimVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "latent/video", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanCameraImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "start_image": ["IMAGE", {}], "camera_conditions": ["WAN_CAMERA_EMBEDDING", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["clip_vision_output", "start_image", "camera_conditions"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanCameraImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanPhantomSubjectToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"images": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["images"]}, "output": ["CONDITIONING", "CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false, false], "output_name": ["positive", "negative_text", "negative_img_text", "latent"], "output_tooltips": [null, null, null, null], "name": "WanPhantomSubjectToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanSoundImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 77, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"audio_encoder_output": ["AUDIO_ENCODER_OUTPUT", {}], "ref_image": ["IMAGE", {}], "control_video": ["IMAGE", {}], "ref_motion": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["audio_encoder_output", "ref_image", "control_video", "ref_motion"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanSoundImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanSoundImageToVideoExtend": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "length": ["INT", {"default": 77, "min": 1, "max": 16384, "step": 4}], "video_latent": ["LATENT", {}]}, "optional": {"audio_encoder_output": ["AUDIO_ENCODER_OUTPUT", {}], "ref_image": ["IMAGE", {}], "control_video": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "length", "video_latent"], "optional": ["audio_encoder_output", "ref_image", "control_video"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanSoundImageToVideoExtend", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanHuMoImageToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 97, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"audio_encoder_output": ["AUDIO_ENCODER_OUTPUT", {}], "ref_image": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size"], "optional": ["audio_encoder_output", "ref_image"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_is_list": [false, false, false], "output_name": ["positive", "negative", "latent"], "output_tooltips": [null, null, null], "name": "WanHuMoImageToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "WanAnimateToVideo": {"input": {"required": {"positive": ["CONDITIONING", {}], "negative": ["CONDITIONING", {}], "vae": ["VAE", {}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 77, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}], "continue_motion_max_frames": ["INT", {"default": 5, "min": 1, "max": 16384, "step": 4}], "video_frame_offset": ["INT", {"tooltip": "The amount of frames to seek in all the input videos. Used for generating longer videos by chunk. Connect to the video_frame_offset output of the previous node for extending a video.", "default": 0, "min": 0, "max": 16384, "step": 1}]}, "optional": {"clip_vision_output": ["CLIP_VISION_OUTPUT", {}], "reference_image": ["IMAGE", {}], "face_video": ["IMAGE", {}], "pose_video": ["IMAGE", {}], "background_video": ["IMAGE", {}], "character_mask": ["MASK", {}], "continue_motion": ["IMAGE", {}]}}, "input_order": {"required": ["positive", "negative", "vae", "width", "height", "length", "batch_size", "continue_motion_max_frames", "video_frame_offset"], "optional": ["clip_vision_output", "reference_image", "face_video", "pose_video", "background_video", "character_mask", "continue_motion"]}, "output": ["CONDITIONING", "CONDITIONING", "LATENT", "INT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false], "output_name": ["positive", "negative", "latent", "trim_latent", "trim_image", "video_frame_offset"], "output_tooltips": [null, null, null, null, null, null], "name": "WanAnimateToVideo", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/video_models", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "Wan22ImageToVideoLatent": {"input": {"required": {"vae": ["VAE", {}], "width": ["INT", {"default": 1280, "min": 32, "max": 16384, "step": 32}], "height": ["INT", {"default": 704, "min": 32, "max": 16384, "step": 32}], "length": ["INT", {"default": 49, "min": 1, "max": 16384, "step": 4}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}, "optional": {"start_image": ["IMAGE", {}]}}, "input_order": {"required": ["vae", "width", "height", "length", "batch_size"], "optional": ["start_image"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "Wan22ImageToVideoLatent", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_wan", "category": "conditioning/inpaint", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LotusConditioning": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["conditioning"], "output_tooltips": [null], "name": "LotusConditioning", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_lotus", "category": "conditioning/lotus", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyLatentHunyuan3Dv2": {"input": {"required": {"resolution": ["INT", {"default": 3072, "min": 1, "max": 8192}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096, "tooltip": "The number of latent images in the batch."}]}}, "input_order": {"required": ["resolution", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "EmptyLatentHunyuan3Dv2", "display_name": "EmptyLatentHunyuan3Dv2", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "latent/3d", "output_node": false}, "Hunyuan3Dv2Conditioning": {"input": {"required": {"clip_vision_output": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": ["clip_vision_output"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "Hunyuan3Dv2Conditioning", "display_name": "Hunyuan3Dv2Conditioning", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "conditioning/video_models", "output_node": false}, "Hunyuan3Dv2ConditioningMultiView": {"input": {"required": {}, "optional": {"front": ["CLIP_VISION_OUTPUT"], "left": ["CLIP_VISION_OUTPUT"], "back": ["CLIP_VISION_OUTPUT"], "right": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": [], "optional": ["front", "left", "back", "right"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "Hunyuan3Dv2ConditioningMultiView", "display_name": "Hunyuan3Dv2ConditioningMultiView", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "conditioning/video_models", "output_node": false}, "VAEDecodeHunyuan3D": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "num_chunks": ["INT", {"default": 8000, "min": 1000, "max": 500000}], "octree_resolution": ["INT", {"default": 256, "min": 16, "max": 512}]}}, "input_order": {"required": ["samples", "vae", "num_chunks", "octree_resolution"]}, "output": ["VOXEL"], "output_is_list": [false], "output_name": ["VOXEL"], "name": "VAEDecodeHunyuan3D", "display_name": "VAEDecodeHunyuan3D", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "latent/3d", "output_node": false}, "VoxelToMeshBasic": {"input": {"required": {"voxel": ["VOXEL"], "threshold": ["FLOAT", {"default": 0.6, "min": -1.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["voxel", "threshold"]}, "output": ["MESH"], "output_is_list": [false], "output_name": ["MESH"], "name": "VoxelToMeshBasic", "display_name": "VoxelToMeshBasic", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": false}, "VoxelToMesh": {"input": {"required": {"voxel": ["VOXEL"], "algorithm": [["surface net", "basic"]], "threshold": ["FLOAT", {"default": 0.6, "min": -1.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["voxel", "algorithm", "threshold"]}, "output": ["MESH"], "output_is_list": [false], "output_name": ["MESH"], "name": "VoxelToMesh", "display_name": "VoxelToMesh", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": false}, "SaveGLB": {"input": {"required": {"mesh": ["MESH"], "filename_prefix": ["STRING", {"default": "mesh/ComfyUI"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["mesh", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveGLB", "display_name": "SaveGLB", "description": "", "python_module": "comfy_extras.nodes_hunyuan3d", "category": "3d", "output_node": true}, "PrimitiveString": {"input": {"required": {"value": ["STRING", {"multiline": false}]}}, "input_order": {"required": ["value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "PrimitiveString", "display_name": "String", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveStringMultiline": {"input": {"required": {"value": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["value"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "PrimitiveStringMultiline", "display_name": "String (Multiline)", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveInt": {"input": {"required": {"value": ["INT", {"min": -9223372036854775807, "max": 9223372036854775807, "control_after_generate": true}]}}, "input_order": {"required": ["value"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["INT"], "output_tooltips": [null], "name": "PrimitiveInt", "display_name": "Int", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveFloat": {"input": {"required": {"value": ["FLOAT", {"min": -9223372036854775807, "max": 9223372036854775807}]}}, "input_order": {"required": ["value"]}, "output": ["FLOAT"], "output_is_list": [false], "output_name": ["FLOAT"], "output_tooltips": [null], "name": "PrimitiveFloat", "display_name": "Float", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PrimitiveBoolean": {"input": {"required": {"value": ["BOOLEAN", {}]}}, "input_order": {"required": ["value"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "output_tooltips": [null], "name": "PrimitiveBoolean", "display_name": "Boolean", "description": "", "python_module": "comfy_extras.nodes_primitive", "category": "utils/primitive", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CFGZeroStar": {"input": {"required": {"model": ["MODEL", {}]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "CFGZeroStar", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cfg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CFGNorm": {"input": {"required": {"model": ["MODEL", {}], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01}]}}, "input_order": {"required": ["model", "strength"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "CFGNorm", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_cfg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "OptimalStepsScheduler": {"input": {"required": {"model_type": ["COMBO", {"multiselect": false, "options": ["FLUX", "Wan", "Chroma"]}], "steps": ["INT", {"default": 20, "min": 3, "max": 1000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model_type", "steps", "denoise"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "output_tooltips": [null], "name": "OptimalStepsScheduler", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_optimalsteps", "category": "sampling/custom_sampling/schedulers", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "QuadrupleCLIPLoader": {"input": {"required": {"clip_name1": ["COMBO", {"multiselect": false, "options": []}], "clip_name2": ["COMBO", {"multiselect": false, "options": []}], "clip_name3": ["COMBO", {"multiselect": false, "options": []}], "clip_name4": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["clip_name1", "clip_name2", "clip_name3", "clip_name4"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["CLIP"], "output_tooltips": [null], "name": "QuadrupleCLIPLoader", "display_name": null, "description": "[Recipes]\n\nhidream: long clip-l, long clip-g, t5xxl, llama_8b_3.1_instruct", "python_module": "comfy_extras.nodes_hidream", "category": "advanced/loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CLIPTextEncodeHiDream": {"input": {"required": {"clip": ["CLIP", {}], "clip_l": ["STRING", {"multiline": true, "dynamicPrompts": true}], "clip_g": ["STRING", {"multiline": true, "dynamicPrompts": true}], "t5xxl": ["STRING", {"multiline": true, "dynamicPrompts": true}], "llama": ["STRING", {"multiline": true, "dynamicPrompts": true}]}}, "input_order": {"required": ["clip", "clip_l", "clip_g", "t5xxl", "llama"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "CLIPTextEncodeHiDream", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_hidream", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "FreSca": {"input": {"required": {"model": ["MODEL", {}], "scale_low": ["FLOAT", {"tooltip": "Scaling factor for low-frequency components", "default": 1.0, "min": 0, "max": 10, "step": 0.01}], "scale_high": ["FLOAT", {"tooltip": "Scaling factor for high-frequency components", "default": 1.25, "min": 0, "max": 10, "step": 0.01}], "freq_cutoff": ["INT", {"tooltip": "Number of frequency indices around center to consider as low-frequency", "default": 20, "min": 1, "max": 10000, "step": 1}]}}, "input_order": {"required": ["model", "scale_low", "scale_high", "freq_cutoff"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "FreSca", "display_name": "FreSca", "description": "Applies frequency-dependent scaling to the guidance", "python_module": "comfy_extras.nodes_fresca", "category": "_for_testing", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "APG": {"input": {"required": {"model": ["MODEL", {}], "eta": ["FLOAT", {"tooltip": "Controls the scale of the parallel guidance vector. Default CFG behavior at a setting of 1.", "default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}], "norm_threshold": ["FLOAT", {"tooltip": "Normalize guidance vector to this value, normalization disable at a setting of 0.", "default": 5.0, "min": 0.0, "max": 50.0, "step": 0.1}], "momentum": ["FLOAT", {"tooltip": "Controls a running average of guidance during diffusion, disabled at a setting of 0.", "default": 0.0, "min": -5.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "eta", "norm_threshold", "momentum"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "APG", "display_name": "Adaptive Projected Guidance", "description": "", "python_module": "comfy_extras.nodes_apg", "category": "sampling/custom_sampling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PreviewAny": {"input": {"required": {"source": ["*", {}]}}, "input_order": {"required": ["source"]}, "output": [], "output_is_list": [], "output_name": [], "name": "PreviewAny", "display_name": "Preview Any", "description": "", "python_module": "comfy_extras.nodes_preview_any", "category": "utils", "output_node": true}, "TextEncodeAceStepAudio": {"input": {"required": {"clip": ["CLIP", {}], "tags": ["STRING", {"multiline": true, "dynamicPrompts": true}], "lyrics": ["STRING", {"multiline": true, "dynamicPrompts": true}], "lyrics_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}]}}, "input_order": {"required": ["clip", "tags", "lyrics", "lyrics_strength"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeAceStepAudio", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_ace", "category": "conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyAceStepLatentAudio": {"input": {"required": {"seconds": ["FLOAT", {"default": 120.0, "min": 1.0, "max": 1000.0, "step": 0.1}], "batch_size": ["INT", {"tooltip": "The number of latent images in the batch.", "default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["seconds", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyAceStepLatentAudio", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_ace", "category": "latent/audio", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringConcatenate": {"input": {"required": {"string_a": ["STRING", {"multiline": true}], "string_b": ["STRING", {"multiline": true}], "delimiter": ["STRING", {"default": "", "multiline": false}]}}, "input_order": {"required": ["string_a", "string_b", "delimiter"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringConcatenate", "display_name": "Concatenate", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringSubstring": {"input": {"required": {"string": ["STRING", {"multiline": true}], "start": ["INT", {}], "end": ["INT", {}]}}, "input_order": {"required": ["string", "start", "end"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringSubstring", "display_name": "Substring", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringLength": {"input": {"required": {"string": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["string"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["length"], "output_tooltips": [null], "name": "StringLength", "display_name": "Length", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "CaseConverter": {"input": {"required": {"string": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["UPPERCASE", "lowercase", "Capitalize", "Title Case"]}]}}, "input_order": {"required": ["string", "mode"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "CaseConverter", "display_name": "Case Converter", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringTrim": {"input": {"required": {"string": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["Both", "Left", "Right"]}]}}, "input_order": {"required": ["string", "mode"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringTrim", "display_name": "Trim", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringReplace": {"input": {"required": {"string": ["STRING", {"multiline": true}], "find": ["STRING", {"multiline": true}], "replace": ["STRING", {"multiline": true}]}}, "input_order": {"required": ["string", "find", "replace"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "StringReplace", "display_name": "Replace", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringContains": {"input": {"required": {"string": ["STRING", {"multiline": true}], "substring": ["STRING", {"multiline": true}], "case_sensitive": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["string", "substring", "case_sensitive"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["contains"], "output_tooltips": [null], "name": "StringContains", "display_name": "Contains", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StringCompare": {"input": {"required": {"string_a": ["STRING", {"multiline": true}], "string_b": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["Starts With", "Ends With", "Equal"]}], "case_sensitive": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["string_a", "string_b", "mode", "case_sensitive"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["BOOLEAN"], "output_tooltips": [null], "name": "StringCompare", "display_name": "Compare", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RegexMatch": {"input": {"required": {"string": ["STRING", {"multiline": true}], "regex_pattern": ["STRING", {"multiline": true}], "case_insensitive": ["BOOLEAN", {"default": true}], "multiline": ["BOOLEAN", {"default": false}], "dotall": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["string", "regex_pattern", "case_insensitive", "multiline", "dotall"]}, "output": ["BOOLEAN"], "output_is_list": [false], "output_name": ["matches"], "output_tooltips": [null], "name": "RegexMatch", "display_name": "Regex Match", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RegexExtract": {"input": {"required": {"string": ["STRING", {"multiline": true}], "regex_pattern": ["STRING", {"multiline": true}], "mode": ["COMBO", {"multiselect": false, "options": ["First Match", "All Matches", "First Group", "All Groups"]}], "case_insensitive": ["BOOLEAN", {"default": true}], "multiline": ["BOOLEAN", {"default": false}], "dotall": ["BOOLEAN", {"default": false}], "group_index": ["INT", {"default": 1, "min": 0, "max": 100}]}}, "input_order": {"required": ["string", "regex_pattern", "mode", "case_insensitive", "multiline", "dotall", "group_index"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "RegexExtract", "display_name": "Regex Extract", "description": "", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RegexReplace": {"input": {"required": {"string": ["STRING", {"multiline": true}], "regex_pattern": ["STRING", {"multiline": true}], "replace": ["STRING", {"multiline": true}]}, "optional": {"case_insensitive": ["BOOLEAN", {"default": true}], "multiline": ["BOOLEAN", {"default": false}], "dotall": ["BOOLEAN", {"tooltip": "When enabled, the dot (.) character will match any character including newline characters. When disabled, dots won't match newlines.", "default": false}], "count": ["INT", {"tooltip": "Maximum number of replacements to make. Set to 0 to replace all occurrences (default). Set to 1 to replace only the first match, 2 for the first two matches, etc.", "default": 0, "min": 0, "max": 100}]}}, "input_order": {"required": ["string", "regex_pattern", "replace"], "optional": ["case_insensitive", "multiline", "dotall", "count"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "RegexReplace", "display_name": "Regex Replace", "description": "Find and replace text using regex patterns.", "python_module": "comfy_extras.nodes_string", "category": "utils/string", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "WanCameraEmbedding": {"input": {"required": {"camera_pose": ["COMBO", {"default": "Static", "multiselect": false, "options": ["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Anti Clockwise (ACW)", "ClockWise (CW)"]}], "width": ["INT", {"default": 832, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 480, "min": 16, "max": 16384, "step": 16}], "length": ["INT", {"default": 81, "min": 1, "max": 16384, "step": 4}]}, "optional": {"speed": ["FLOAT", {"default": 1.0, "min": 0, "max": 10.0, "step": 0.1}], "fx": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 1e-09}], "fy": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 1e-09}], "cx": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}], "cy": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["camera_pose", "width", "height", "length"], "optional": ["speed", "fx", "fy", "cx", "cy"]}, "output": ["WAN_CAMERA_EMBEDDING", "INT", "INT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["camera_embedding", "width", "height", "length"], "output_tooltips": [null, null, null, null], "name": "WanCameraEmbedding", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_camera_trajectory", "category": "camera", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ReferenceLatent": {"input": {"required": {"conditioning": ["CONDITIONING", {}]}, "optional": {"latent": ["LATENT", {}]}}, "input_order": {"required": ["conditioning"], "optional": ["latent"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "ReferenceLatent", "display_name": null, "description": "This node sets the guiding latent for an edit model. If the model supports it you can chain multiple to set multiple reference images.", "python_module": "comfy_extras.nodes_edit_model", "category": "advanced/conditioning/edit_models", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TCFG": {"input": {"required": {"model": ["MODEL", {}]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["patched_model"], "output_tooltips": [null], "name": "TCFG", "display_name": "Tangential Damping CFG", "description": "TCFG \u2013 Tangential Damping CFG (2503.18137)\n\nRefine the uncond (negative) to align with the cond (positive) for improving quality.", "python_module": "comfy_extras.nodes_tcfg", "category": "advanced/guidance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ContextWindowsManual": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to apply context windows to during sampling."}], "context_length": ["INT", {"tooltip": "The length of the context window.", "default": 16, "min": 1}], "context_overlap": ["INT", {"tooltip": "The overlap of the context window.", "default": 4, "min": 0}], "context_schedule": ["COMBO", {"tooltip": "The stride of the context window.", "multiselect": false, "options": ["standard_static", "standard_uniform", "looped_uniform", "batched"]}], "context_stride": ["INT", {"tooltip": "The stride of the context window; only applicable to uniform schedules.", "default": 1, "min": 1}], "closed_loop": ["BOOLEAN", {"tooltip": "Whether to close the context window loop; only applicable to looped schedules.", "default": false}], "fuse_method": ["COMBO", {"tooltip": "The method to use to fuse the context windows.", "default": "pyramid", "multiselect": false, "options": ["pyramid", "relative", "flat", "overlap-linear"]}], "dim": ["INT", {"tooltip": "The dimension to apply the context windows to.", "default": 0, "min": 0, "max": 5}]}}, "input_order": {"required": ["model", "context_length", "context_overlap", "context_schedule", "context_stride", "closed_loop", "fuse_method", "dim"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with context windows applied during sampling."], "name": "ContextWindowsManual", "display_name": "Context Windows (Manual)", "description": "Manually set context windows.", "python_module": "comfy_extras.nodes_context_windows", "category": "context", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "WanContextWindowsManual": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to apply context windows to during sampling."}], "context_length": ["INT", {"tooltip": "The length of the context window.", "default": 81, "min": 1, "max": 16384, "step": 4}], "context_overlap": ["INT", {"tooltip": "The overlap of the context window.", "default": 30, "min": 0}], "context_schedule": ["COMBO", {"tooltip": "The stride of the context window.", "multiselect": false, "options": ["standard_static", "standard_uniform", "looped_uniform", "batched"]}], "context_stride": ["INT", {"tooltip": "The stride of the context window; only applicable to uniform schedules.", "default": 1, "min": 1}], "closed_loop": ["BOOLEAN", {"tooltip": "Whether to close the context window loop; only applicable to looped schedules.", "default": false}], "fuse_method": ["COMBO", {"tooltip": "The method to use to fuse the context windows.", "default": "pyramid", "multiselect": false, "options": ["pyramid", "relative", "flat", "overlap-linear"]}]}}, "input_order": {"required": ["model", "context_length", "context_overlap", "context_schedule", "context_stride", "closed_loop", "fuse_method"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with context windows applied during sampling."], "name": "WanContextWindowsManual", "display_name": "WAN Context Windows (Manual)", "description": "Manually set context windows for WAN-like models (dim=2).", "python_module": "comfy_extras.nodes_context_windows", "category": "context", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "TextEncodeQwenImageEdit": {"input": {"required": {"clip": ["CLIP", {}], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"vae": ["VAE", {}], "image": ["IMAGE", {}]}}, "input_order": {"required": ["clip", "prompt"], "optional": ["vae", "image"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeQwenImageEdit", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_qwen", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "TextEncodeQwenImageEditPlus": {"input": {"required": {"clip": ["CLIP", {}], "prompt": ["STRING", {"multiline": true, "dynamicPrompts": true}]}, "optional": {"vae": ["VAE", {}], "image1": ["IMAGE", {}], "image2": ["IMAGE", {}], "image3": ["IMAGE", {}]}}, "input_order": {"required": ["clip", "prompt"], "optional": ["vae", "image1", "image2", "image3"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "output_tooltips": [null], "name": "TextEncodeQwenImageEditPlus", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_qwen", "category": "advanced/conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "EmptyChromaRadianceLatentImage": {"input": {"required": {"width": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "height": ["INT", {"default": 1024, "min": 16, "max": 16384, "step": 16}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 4096}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "output_tooltips": [null], "name": "EmptyChromaRadianceLatentImage", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_chroma_radiance", "category": "latent/chroma_radiance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ChromaRadianceOptions": {"input": {"required": {"model": ["MODEL", {}], "preserve_wrapper": ["BOOLEAN", {"tooltip": "When enabled, will delegate to an existing model function wrapper if it exists. Generally should be left enabled.", "default": true}], "start_sigma": ["FLOAT", {"tooltip": "First sigma that these options will be in effect.", "default": 1.0, "min": 0.0, "max": 1.0}], "end_sigma": ["FLOAT", {"tooltip": "Last sigma that these options will be in effect.", "default": 0.0, "min": 0.0, "max": 1.0}], "nerf_tile_size": ["INT", {"tooltip": "Allows overriding the default NeRF tile size. -1 means use the default (32). 0 means use non-tiling mode (may require a lot of VRAM).", "default": -1, "min": -1}]}}, "input_order": {"required": ["model", "preserve_wrapper", "start_sigma", "end_sigma", "nerf_tile_size"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "ChromaRadianceOptions", "display_name": null, "description": "Allows setting advanced options for the Chroma Radiance model.", "python_module": "comfy_extras.nodes_chroma_radiance", "category": "model_patches/chroma_radiance", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ModelPatchLoader": {"input": {"required": {"name": [[]]}}, "input_order": {"required": ["name"]}, "output": ["MODEL_PATCH"], "output_is_list": [false], "output_name": ["MODEL_PATCH"], "name": "ModelPatchLoader", "display_name": "ModelPatchLoader", "description": "", "python_module": "comfy_extras.nodes_model_patch", "category": "advanced/loaders", "output_node": false, "experimental": true}, "QwenImageDiffsynthControlnet": {"input": {"required": {"model": ["MODEL"], "model_patch": ["MODEL_PATCH"], "vae": ["VAE"], "image": ["IMAGE"], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.01}]}, "optional": {"mask": ["MASK"]}}, "input_order": {"required": ["model", "model_patch", "vae", "image", "strength"], "optional": ["mask"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "QwenImageDiffsynthControlnet", "display_name": "QwenImageDiffsynthControlnet", "description": "", "python_module": "comfy_extras.nodes_model_patch", "category": "advanced/loaders/qwen", "output_node": false, "experimental": true}, "USOStyleReference": {"input": {"required": {"model": ["MODEL"], "model_patch": ["MODEL_PATCH"], "clip_vision_output": ["CLIP_VISION_OUTPUT"]}}, "input_order": {"required": ["model", "model_patch", "clip_vision_output"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "USOStyleReference", "display_name": "USOStyleReference", "description": "", "python_module": "comfy_extras.nodes_model_patch", "category": "advanced/model_patches/flux", "output_node": false, "experimental": true}, "EasyCache": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to add EasyCache to."}], "reuse_threshold": ["FLOAT", {"tooltip": "The threshold for reusing cached steps.", "default": 0.2, "min": 0.0, "max": 3.0, "step": 0.01}], "start_percent": ["FLOAT", {"tooltip": "The relative sampling step to begin use of EasyCache.", "default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01}], "end_percent": ["FLOAT", {"tooltip": "The relative sampling step to end use of EasyCache.", "default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01}], "verbose": ["BOOLEAN", {"tooltip": "Whether to log verbose information.", "default": false}]}}, "input_order": {"required": ["model", "reuse_threshold", "start_percent", "end_percent", "verbose"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with EasyCache."], "name": "EasyCache", "display_name": "EasyCache", "description": "Native EasyCache implementation.", "python_module": "comfy_extras.nodes_easycache", "category": "advanced/debug/model", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "LazyCache": {"input": {"required": {"model": ["MODEL", {"tooltip": "The model to add LazyCache to."}], "reuse_threshold": ["FLOAT", {"tooltip": "The threshold for reusing cached steps.", "default": 0.2, "min": 0.0, "max": 3.0, "step": 0.01}], "start_percent": ["FLOAT", {"tooltip": "The relative sampling step to begin use of LazyCache.", "default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01}], "end_percent": ["FLOAT", {"tooltip": "The relative sampling step to end use of LazyCache.", "default": 0.95, "min": 0.0, "max": 1.0, "step": 0.01}], "verbose": ["BOOLEAN", {"tooltip": "Whether to log verbose information.", "default": false}]}}, "input_order": {"required": ["model", "reuse_threshold", "start_percent", "end_percent", "verbose"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": ["The model with LazyCache."], "name": "LazyCache", "display_name": "LazyCache", "description": "A homebrew version of EasyCache - even 'easier' version of EasyCache to implement. Overall works worse than EasyCache, but better in some rare cases AND universal compatibility with everything in ComfyUI.", "python_module": "comfy_extras.nodes_easycache", "category": "advanced/debug/model", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "AudioEncoderLoader": {"input": {"required": {"audio_encoder_name": ["COMBO", {"multiselect": false, "options": []}]}}, "input_order": {"required": ["audio_encoder_name"]}, "output": ["AUDIO_ENCODER"], "output_is_list": [false], "output_name": ["AUDIO_ENCODER"], "output_tooltips": [null], "name": "AudioEncoderLoader", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_audio_encoder", "category": "loaders", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "AudioEncoderEncode": {"input": {"required": {"audio_encoder": ["AUDIO_ENCODER", {}], "audio": ["AUDIO", {}]}}, "input_order": {"required": ["audio_encoder", "audio"]}, "output": ["AUDIO_ENCODER_OUTPUT"], "output_is_list": [false], "output_name": ["AUDIO_ENCODER_OUTPUT"], "output_tooltips": [null], "name": "AudioEncoderEncode", "display_name": null, "description": "", "python_module": "comfy_extras.nodes_audio_encoder", "category": "conditioning", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ScaleROPE": {"input": {"required": {"model": ["MODEL", {}], "scale_x": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "shift_x": ["FLOAT", {"default": 0.0, "min": -256.0, "max": 256.0, "step": 0.1}], "scale_y": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "shift_y": ["FLOAT", {"default": 0.0, "min": -256.0, "max": 256.0, "step": 0.1}], "scale_t": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.1}], "shift_t": ["FLOAT", {"default": 0.0, "min": -256.0, "max": 256.0, "step": 0.1}]}}, "input_order": {"required": ["model", "scale_x", "shift_x", "scale_y", "shift_y", "scale_t", "shift_t"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "output_tooltips": [null], "name": "ScaleROPE", "display_name": null, "description": "Scale and shift the ROPE of the model.", "python_module": "comfy_extras.nodes_rope", "category": "advanced/model_patches", "output_node": false, "deprecated": false, "experimental": true, "api_node": false}, "IdeogramV1": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "turbo": ["BOOLEAN", {"tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)", "default": false}]}, "optional": {"aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio for image generation.", "default": "1:1", "multiselect": false, "options": ["1:1", "4:3", "3:4", "16:9", "9:16", "2:1", "1:2", "3:2", "2:3", "4:5", "5:4"]}], "magic_prompt_option": ["COMBO", {"tooltip": "Determine if MagicPrompt should be used in generation", "default": "AUTO", "multiselect": false, "options": ["AUTO", "ON", "OFF"]}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "negative_prompt": ["STRING", {"tooltip": "Description of what to exclude from the image", "default": "", "multiline": true}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "turbo"], "optional": ["aspect_ratio", "magic_prompt_option", "seed", "negative_prompt", "num_images"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "IdeogramV1", "display_name": "Ideogram V1", "description": "Generates images using the Ideogram V1 model.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "IdeogramV2": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "turbo": ["BOOLEAN", {"tooltip": "Whether to use turbo mode (faster generation, potentially lower quality)", "default": false}]}, "optional": {"aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to AUTO.", "default": "1:1", "multiselect": false, "options": ["1:1", "4:3", "3:4", "16:9", "9:16", "2:1", "1:2", "3:2", "2:3", "4:5", "5:4"]}], "resolution": ["COMBO", {"tooltip": "The resolution for image generation. If not set to AUTO, this overrides the aspect_ratio setting.", "default": "Auto", "multiselect": false, "options": ["Auto", "512 x 1536", "576 x 1408", "576 x 1472", "576 x 1536", "640 x 1024", "640 x 1344", "640 x 1408", "640 x 1472", "640 x 1536", "704 x 1152", "704 x 1216", "704 x 1280", "704 x 1344", "704 x 1408", "704 x 1472", "720 x 1280", "736 x 1312", "768 x 1024", "768 x 1088", "768 x 1152", "768 x 1216", "768 x 1232", "768 x 1280", "768 x 1344", "832 x 960", "832 x 1024", "832 x 1088", "832 x 1152", "832 x 1216", "832 x 1248", "864 x 1152", "896 x 960", "896 x 1024", "896 x 1088", "896 x 1120", "896 x 1152", "960 x 832", "960 x 896", "960 x 1024", "960 x 1088", "1024 x 640", "1024 x 768", "1024 x 832", "1024 x 896", "1024 x 960", "1024 x 1024", "1088 x 768", "1088 x 832", "1088 x 896", "1088 x 960", "1120 x 896", "1152 x 704", "1152 x 768", "1152 x 832", "1152 x 864", "1152 x 896", "1216 x 704", "1216 x 768", "1216 x 832", "1232 x 768", "1248 x 832", "1280 x 704", "1280 x 720", "1280 x 768", "1280 x 800", "1312 x 736", "1344 x 640", "1344 x 704", "1344 x 768", "1408 x 576", "1408 x 640", "1408 x 704", "1472 x 576", "1472 x 640", "1472 x 704", "1536 x 512", "1536 x 576", "1536 x 640"]}], "magic_prompt_option": ["COMBO", {"tooltip": "Determine if MagicPrompt should be used in generation", "default": "AUTO", "multiselect": false, "options": ["AUTO", "ON", "OFF"]}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "style_type": ["COMBO", {"tooltip": "Style type for generation (V2 only)", "default": "NONE", "multiselect": false, "options": ["AUTO", "GENERAL", "REALISTIC", "DESIGN", "RENDER_3D", "ANIME"]}], "negative_prompt": ["STRING", {"tooltip": "Description of what to exclude from the image", "default": "", "multiline": true}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "turbo"], "optional": ["aspect_ratio", "resolution", "magic_prompt_option", "seed", "style_type", "negative_prompt", "num_images"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "IdeogramV2", "display_name": "Ideogram V2", "description": "Generates images using the Ideogram V2 model.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "IdeogramV3": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation or editing", "default": "", "multiline": true}]}, "optional": {"image": ["IMAGE", {"tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"tooltip": "Optional mask for inpainting (white areas will be replaced)"}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio for image generation. Ignored if resolution is not set to Auto.", "default": "1:1", "multiselect": false, "options": ["1:3", "3:1", "1:2", "2:1", "9:16", "16:9", "10:16", "16:10", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "1:1"]}], "resolution": ["COMBO", {"tooltip": "The resolution for image generation. If not set to Auto, this overrides the aspect_ratio setting.", "default": "Auto", "multiselect": false, "options": ["Auto", "512x1536", "576x1408", "576x1472", "576x1536", "640x1344", "640x1408", "640x1472", "640x1536", "704x1152", "704x1216", "704x1280", "704x1344", "704x1408", "704x1472", "736x1312", "768x1088", "768x1216", "768x1280", "768x1344", "800x1280", "832x960", "832x1024", "832x1088", "832x1152", "832x1216", "832x1248", "864x1152", "896x960", "896x1024", "896x1088", "896x1120", "896x1152", "960x832", "960x896", "960x1024", "960x1088", "1024x832", "1024x896", "1024x960", "1024x1024", "1088x768", "1088x832", "1088x896", "1088x960", "1120x896", "1152x704", "1152x832", "1152x864", "1152x896", "1216x704", "1216x768", "1216x832", "1248x832", "1280x704", "1280x768", "1280x800", "1312x736", "1344x640", "1344x704", "1344x768", "1408x576", "1408x640", "1408x704", "1472x576", "1472x640", "1472x704", "1536x512", "1536x576", "1536x640"]}], "magic_prompt_option": ["COMBO", {"tooltip": "Determine if MagicPrompt should be used in generation", "default": "AUTO", "multiselect": false, "options": ["AUTO", "ON", "OFF"]}], "seed": ["INT", {"default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "num_images": ["INT", {"default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}], "rendering_speed": ["COMBO", {"tooltip": "Controls the trade-off between generation speed and quality", "default": "DEFAULT", "multiselect": false, "options": ["DEFAULT", "TURBO", "QUALITY"]}], "character_image": ["IMAGE", {"tooltip": "Image to use as character reference."}], "character_mask": ["MASK", {"tooltip": "Optional mask for character reference image."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt"], "optional": ["image", "mask", "aspect_ratio", "resolution", "magic_prompt_option", "seed", "num_images", "rendering_speed", "character_image", "character_mask"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "IdeogramV3", "display_name": "Ideogram V3", "description": "Generates images using the Ideogram V3 model. Supports both regular image generation from text prompts and image editing with mask.", "python_module": "comfy_api_nodes.nodes_ideogram", "category": "api node/image/Ideogram", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIDalle2": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for DALL\u00b7E", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "not implemented yet in backend", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "size": ["COMBO", {"tooltip": "Image size", "default": "1024x1024", "multiselect": false, "options": ["256x256", "512x512", "1024x1024"]}], "n": ["INT", {"tooltip": "How many images to generate", "default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}], "image": ["IMAGE", {"tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"tooltip": "Optional mask for inpainting (white areas will be replaced)"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt"], "optional": ["seed", "size", "n", "image", "mask"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "OpenAIDalle2", "display_name": "OpenAI DALL\u00b7E 2", "description": "Generates images synchronously via OpenAI's DALL\u00b7E 2 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIDalle3": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for DALL\u00b7E", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "not implemented yet in backend", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "quality": ["COMBO", {"tooltip": "Image quality", "default": "standard", "multiselect": false, "options": ["standard", "hd"]}], "style": ["COMBO", {"tooltip": "Vivid causes the model to lean towards generating hyper-real and dramatic images. Natural causes the model to produce more natural, less hyper-real looking images.", "default": "natural", "multiselect": false, "options": ["natural", "vivid"]}], "size": ["COMBO", {"tooltip": "Image size", "default": "1024x1024", "multiselect": false, "options": ["1024x1024", "1024x1792", "1792x1024"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt"], "optional": ["seed", "quality", "style", "size"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "OpenAIDalle3", "display_name": "OpenAI DALL\u00b7E 3", "description": "Generates images synchronously via OpenAI's DALL\u00b7E 3 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIGPTImage1": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for GPT Image 1", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "not implemented yet in backend", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "quality": ["COMBO", {"tooltip": "Image quality, affects cost and generation time.", "default": "low", "multiselect": false, "options": ["low", "medium", "high"]}], "background": ["COMBO", {"tooltip": "Return image with or without background", "default": "opaque", "multiselect": false, "options": ["opaque", "transparent"]}], "size": ["COMBO", {"tooltip": "Image size", "default": "auto", "multiselect": false, "options": ["auto", "1024x1024", "1024x1536", "1536x1024"]}], "n": ["INT", {"tooltip": "How many images to generate", "default": 1, "min": 1, "max": 8, "step": 1, "display": "number"}], "image": ["IMAGE", {"tooltip": "Optional reference image for image editing."}], "mask": ["MASK", {"tooltip": "Optional mask for inpainting (white areas will be replaced)"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt"], "optional": ["seed", "quality", "background", "size", "n", "image", "mask"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "OpenAIGPTImage1", "display_name": "OpenAI GPT Image 1", "description": "Generates images synchronously via OpenAI's GPT Image 1 endpoint.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/image/OpenAI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIChatNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text inputs to the model, used to generate a response.", "default": "", "multiline": true}], "persist_context": ["BOOLEAN", {"tooltip": "This parameter is deprecated and has no effect.", "default": false}], "model": ["COMBO", {"tooltip": "The model used to generate the response", "multiselect": false, "options": ["o4-mini", "o1", "o3", "o1-pro", "gpt-4o", "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano", "gpt-5", "gpt-5-mini", "gpt-5-nano"]}]}, "optional": {"images": ["IMAGE", {"tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."}], "files": ["OPENAI_INPUT_FILES", {"tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the OpenAI Chat Input Files node."}], "advanced_options": ["OPENAI_CHAT_CONFIG", {"tooltip": "Optional configuration for the model. Accepts inputs from the OpenAI Chat Advanced Options node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "persist_context", "model"], "optional": ["images", "files", "advanced_options"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "OpenAIChatNode", "display_name": "OpenAI ChatGPT", "description": "Generate text responses from an OpenAI model.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/text/OpenAI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIInputFiles": {"input": {"required": {"file": ["COMBO", {"tooltip": "Input files to include as context for the model. Only accepts text (.txt) and PDF (.pdf) files for now.", "multiselect": false, "options": []}]}, "optional": {"OPENAI_INPUT_FILES": ["OPENAI_INPUT_FILES", {"tooltip": "An optional additional file(s) to batch together with the file loaded from this node. Allows chaining of input files so that a single message can include multiple input files."}]}}, "input_order": {"required": ["file"], "optional": ["OPENAI_INPUT_FILES"]}, "output": ["OPENAI_INPUT_FILES"], "output_is_list": [false], "output_name": ["OPENAI_INPUT_FILES"], "output_tooltips": [null], "name": "OpenAIInputFiles", "display_name": "OpenAI ChatGPT Input Files", "description": "Loads and prepares input files (text, pdf, etc.) to include as inputs for the OpenAI Chat Node. The files will be read by the OpenAI model when generating a response. \ud83d\udec8 TIP: Can be chained together with other OpenAI Input File nodes.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/text/OpenAI", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "OpenAIChatConfig": {"input": {"required": {"truncation": ["COMBO", {"tooltip": "The truncation strategy to use for the model response. auto: If the context of this response and previous ones exceeds the model's context window size, the model will truncate the response to fit the context window by dropping input items in the middle of the conversation.disabled: If a model response will exceed the context window size for a model, the request will fail with a 400 error", "default": "auto", "multiselect": false, "options": ["auto", "disabled"]}]}, "optional": {"max_output_tokens": ["INT", {"tooltip": "An upper bound for the number of tokens that can be generated for a response, including visible output tokens", "default": 4096, "min": 16, "max": 16384}], "instructions": ["STRING", {"tooltip": "Instructions for the model on how to generate the response", "multiline": true}]}}, "input_order": {"required": ["truncation"], "optional": ["max_output_tokens", "instructions"]}, "output": ["OPENAI_CHAT_CONFIG"], "output_is_list": [false], "output_name": ["OPENAI_CHAT_CONFIG"], "output_tooltips": [null], "name": "OpenAIChatConfig", "display_name": "OpenAI ChatGPT Advanced Options", "description": "Allows specifying advanced configuration options for the OpenAI Chat Nodes.", "python_module": "comfy_api_nodes.nodes_openai", "category": "api node/text/OpenAI", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "MinimaxTextToVideoNode": {"input": {"required": {"prompt_text": ["STRING", {"tooltip": "Text prompt to guide the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "Model to use for video generation", "default": "T2V-01", "multiselect": false, "options": ["T2V-01", "T2V-01-Director"]}]}, "optional": {"seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "step": 1, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text", "model"], "optional": ["seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MinimaxTextToVideoNode", "display_name": "MiniMax Text to Video", "description": "Generates videos synchronously based on a prompt, and optional parameters.", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MinimaxImageToVideoNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "Image to use as first frame of video generation"}], "prompt_text": ["STRING", {"tooltip": "Text prompt to guide the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "Model to use for video generation", "default": "I2V-01", "multiselect": false, "options": ["I2V-01-Director", "I2V-01", "I2V-01-live"]}]}, "optional": {"seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "step": 1, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt_text", "model"], "optional": ["seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MinimaxImageToVideoNode", "display_name": "MiniMax Image to Video", "description": "Generates videos synchronously based on an image and prompt, and optional parameters.", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MinimaxHailuoVideoNode": {"input": {"required": {"prompt_text": ["STRING", {"tooltip": "Text prompt to guide the video generation.", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "step": 1, "control_after_generate": true}], "first_frame_image": ["IMAGE", {"tooltip": "Optional image to use as the first frame to generate a video."}], "prompt_optimizer": ["BOOLEAN", {"tooltip": "Optimize prompt to improve generation quality when needed.", "default": true}], "duration": ["COMBO", {"tooltip": "The length of the output video in seconds.", "default": 6, "multiselect": false, "options": [6, 10]}], "resolution": ["COMBO", {"tooltip": "The dimensions of the video display. 1080p is 1920x1080, 768p is 1366x768.", "default": "768P", "multiselect": false, "options": ["768P", "1080P"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text"], "optional": ["seed", "first_frame_image", "prompt_optimizer", "duration", "resolution"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MinimaxHailuoVideoNode", "display_name": "MiniMax Hailuo Video", "description": "Generates videos from prompt, with optional start frame using the new MiniMax Hailuo-02 model.", "python_module": "comfy_api_nodes.nodes_minimax", "category": "api node/video/MiniMax", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "VeoVideoGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text description of the video", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16"]}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid in the video", "default": "", "multiline": true}], "duration_seconds": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 8, "step": 1, "display": "number"}], "enhance_prompt": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance", "default": true}], "person_generation": ["COMBO", {"tooltip": "Whether to allow generating people in the video", "default": "ALLOW", "multiselect": false, "options": ["ALLOW", "BLOCK"]}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "image": ["IMAGE", {"tooltip": "Optional reference image to guide video generation"}], "model": ["COMBO", {"tooltip": "Veo 2 model to use for video generation", "default": "veo-2.0-generate-001", "multiselect": false, "options": ["veo-2.0-generate-001"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio"], "optional": ["negative_prompt", "duration_seconds", "enhance_prompt", "person_generation", "seed", "image", "model"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "VeoVideoGenerationNode", "display_name": "Google Veo 2 Video Generation", "description": "Generates videos from text prompts using Google's Veo 2 API", "python_module": "comfy_api_nodes.nodes_veo2", "category": "api node/video/Veo", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Veo3VideoGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text description of the video", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16"]}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid in the video", "default": "", "multiline": true}], "duration_seconds": ["INT", {"tooltip": "Duration of the output video in seconds (Veo 3 only supports 8 seconds)", "default": 8, "min": 8, "max": 8, "step": 1, "display": "number"}], "enhance_prompt": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance", "default": true}], "person_generation": ["COMBO", {"tooltip": "Whether to allow generating people in the video", "default": "ALLOW", "multiselect": false, "options": ["ALLOW", "BLOCK"]}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "image": ["IMAGE", {"tooltip": "Optional reference image to guide video generation"}], "model": ["COMBO", {"tooltip": "Veo 3 model to use for video generation", "default": "veo-3.0-generate-001", "multiselect": false, "options": ["veo-3.1-generate", "veo-3.1-fast-generate", "veo-3.0-generate-001", "veo-3.0-fast-generate-001"]}], "generate_audio": ["BOOLEAN", {"tooltip": "Generate audio for the video. Supported by all Veo 3 models.", "default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio"], "optional": ["negative_prompt", "duration_seconds", "enhance_prompt", "person_generation", "seed", "image", "model", "generate_audio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Veo3VideoGenerationNode", "display_name": "Google Veo 3 Video Generation", "description": "Generates videos from text prompts using Google's Veo 3 API", "python_module": "comfy_api_nodes.nodes_veo2", "category": "api node/video/Veo", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingCameraControls": {"input": {"required": {"camera_control_type": ["COMBO", {"multiselect": false, "options": ["simple", "down_back", "forward_up", "right_turn_forward", "left_turn_forward"]}], "horizontal_movement": ["FLOAT", {"tooltip": "Controls camera's movement along horizontal axis (x-axis). Negative indicates left, positive indicates right", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "vertical_movement": ["FLOAT", {"tooltip": "Controls camera's movement along vertical axis (y-axis). Negative indicates downward, positive indicates upward.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "pan": ["FLOAT", {"tooltip": "Controls camera's rotation in vertical plane (x-axis). Negative indicates downward rotation, positive indicates upward rotation.", "default": 0.5, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "tilt": ["FLOAT", {"tooltip": "Controls camera's rotation in horizontal plane (y-axis). Negative indicates left rotation, positive indicates right rotation.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "roll": ["FLOAT", {"tooltip": "Controls camera's rolling amount (z-axis). Negative indicates counterclockwise, positive indicates clockwise.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}], "zoom": ["FLOAT", {"tooltip": "Controls change in camera's focal length. Negative indicates narrower field of view, positive indicates wider field of view.", "default": 0.0, "min": -10.0, "max": 10.0, "step": 0.25, "display": "slider"}]}}, "input_order": {"required": ["camera_control_type", "horizontal_movement", "vertical_movement", "pan", "tilt", "roll", "zoom"]}, "output": ["CAMERA_CONTROL"], "output_is_list": [false], "output_name": ["camera_control"], "output_tooltips": [null], "name": "KlingCameraControls", "display_name": "Kling Camera Controls", "description": "Allows specifying configuration options for Kling Camera Controls and motion control effects.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "KlingTextToVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "mode": ["COMBO", {"tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name.", "default": "standard mode / 5s duration / kling-v1-6", "multiselect": false, "options": ["standard mode / 5s duration / kling-v1", "standard mode / 10s duration / kling-v1", "pro mode / 5s duration / kling-v1", "pro mode / 10s duration / kling-v1", "standard mode / 5s duration / kling-v1-6", "standard mode / 10s duration / kling-v1-6", "pro mode / 5s duration / kling-v2-master", "pro mode / 10s duration / kling-v2-master", "standard mode / 5s duration / kling-v2-master", "standard mode / 10s duration / kling-v2-master", "pro mode / 5s duration / kling-v2-1-master", "pro mode / 10s duration / kling-v2-1-master", "pro mode / 5s duration / kling-v2-5-turbo", "pro mode / 10s duration / kling-v2-5-turbo"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "mode"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingTextToVideoNode", "display_name": "Kling Text to Video", "description": "Kling Text to Video Node", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingImage2VideoNode": {"input": {"required": {"start_frame": ["IMAGE", {"tooltip": "The reference image used to generate the video."}], "prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "model_name": ["COMBO", {"default": "kling-v2-master", "multiselect": false, "options": ["kling-v1", "kling-v1-5", "kling-v1-6", "kling-v2-master", "kling-v2-1", "kling-v2-1-master", "kling-v2-5-turbo"]}], "cfg_scale": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0}], "mode": ["COMBO", {"default": "std", "multiselect": false, "options": ["std", "pro"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "duration": ["COMBO", {"default": "5", "multiselect": false, "options": ["5", "10"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["start_frame", "prompt", "negative_prompt", "model_name", "cfg_scale", "mode", "aspect_ratio", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingImage2VideoNode", "display_name": "Kling Image to Video", "description": "Kling Image to Video Node", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingCameraControlI2VNode": {"input": {"required": {"start_frame": ["IMAGE", {"tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."}], "prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "camera_control": ["CAMERA_CONTROL", {"tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["start_frame", "prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "camera_control"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingCameraControlI2VNode", "display_name": "Kling Image to Video (Camera Control)", "description": "Transform still images into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original image.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingCameraControlT2VNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.75, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "camera_control": ["CAMERA_CONTROL", {"tooltip": "Can be created using the Kling Camera Controls node. Controls the camera movement and motion during the video generation."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "camera_control"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingCameraControlT2VNode", "display_name": "Kling Text to Video (Camera Control)", "description": "Transform text into cinematic videos with professional camera movements that simulate real-world cinematography. Control virtual camera actions including zoom, rotation, pan, tilt, and first-person view, while maintaining focus on your original text.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingStartEndFrameNode": {"input": {"required": {"start_frame": ["IMAGE", {"tooltip": "Reference Image - URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1. Base64 should not include data:image prefix."}], "end_frame": ["IMAGE", {"tooltip": "Reference Image - End frame control. URL or Base64 encoded string, cannot exceed 10MB, resolution not less than 300*300px. Base64 should not include data:image prefix."}], "prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "mode": ["COMBO", {"tooltip": "The configuration to use for the video generation following the format: mode / duration / model_name.", "default": "pro mode / 5s duration / kling-v1-5", "multiselect": false, "options": ["standard mode / 5s duration / kling-v1", "pro mode / 5s duration / kling-v1", "pro mode / 5s duration / kling-v1-5", "pro mode / 10s duration / kling-v1-5", "pro mode / 5s duration / kling-v1-6", "pro mode / 10s duration / kling-v1-6", "pro mode / 5s duration / kling-v2-1", "pro mode / 10s duration / kling-v2-1"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["start_frame", "end_frame", "prompt", "negative_prompt", "cfg_scale", "aspect_ratio", "mode"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingStartEndFrameNode", "display_name": "Kling Start-End Frame to Video", "description": "Generate a video sequence that transitions between your provided start and end images. The node creates all frames in between, producing a smooth transformation from the first frame to the last.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingVideoExtendNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt for guiding the video extension", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt for elements to avoid in the extended video", "multiline": true}], "cfg_scale": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0}], "video_id": ["STRING", {"tooltip": "The ID of the video to be extended. Supports videos generated by text-to-video, image-to-video, and previous video extension operations. Cannot exceed 3 minutes total duration after extension.", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "cfg_scale", "video_id"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingVideoExtendNode", "display_name": "Kling Video Extend", "description": "Kling Video Extend Node. Extend videos made by other Kling nodes. The video_id is created by using other Kling Nodes.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingLipSyncAudioToVideoNode": {"input": {"required": {"video": ["VIDEO", {}], "audio": ["AUDIO", {}], "voice_language": ["COMBO", {"default": "en", "multiselect": false, "options": ["zh", "en"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video", "audio", "voice_language"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingLipSyncAudioToVideoNode", "display_name": "Kling Lip Sync Video with Audio", "description": "Kling Lip Sync Audio to Video Node. Syncs mouth movements in a video file to the audio content of an audio file. When using, ensure that the audio contains clearly distinguishable vocals and that the video contains a distinct face. The audio file should not be larger than 5MB. The video file should not be larger than 100MB, should have height/width between 720px and 1920px, and should be between 2s and 10s in length.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingLipSyncTextToVideoNode": {"input": {"required": {"video": ["VIDEO", {}], "text": ["STRING", {"tooltip": "Text Content for Lip-Sync Video Generation. Required when mode is text2video. Maximum length is 120 characters.", "multiline": true}], "voice": ["COMBO", {"default": "Melody", "multiselect": false, "options": ["Melody", "Sunny", "Sage", "Ace", "Blossom", "Peppy", "Dove", "Shine", "Anchor", "Lyric", "Tender", "Siren", "Zippy", "Bud", "Sprite", "Candy", "Beacon", "Rock", "Titan", "Grace", "Helen", "Lore", "Crag", "Prattle", "Hearth", "The Reader", "Commercial Lady", "\u9633\u5149\u5c11\u5e74", "\u61c2\u4e8b\u5c0f\u5f1f", "\u8fd0\u52a8\u5c11\u5e74", "\u9752\u6625\u5c11\u5973", "\u6e29\u67d4\u5c0f\u59b9", "\u5143\u6c14\u5c11\u5973", "\u9633\u5149\u7537\u751f", "\u5e7d\u9ed8\u5c0f\u54e5", "\u6587\u827a\u5c0f\u54e5", "\u751c\u7f8e\u90bb\u5bb6", "\u6e29\u67d4\u59d0\u59d0", "\u804c\u573a\u5973\u9752", "\u6d3b\u6cfc\u7537\u7ae5", "\u4fcf\u76ae\u5973\u7ae5", "\u7a33\u91cd\u8001\u7238", "\u6e29\u67d4\u5988\u5988", "\u4e25\u8083\u4e0a\u53f8", "\u4f18\u96c5\u8d35\u5987", "\u6148\u7965\u7237\u7237", "\u5520\u53e8\u7237\u7237", "\u5520\u53e8\u5976\u5976", "\u548c\u853c\u5976\u5976", "\u4e1c\u5317\u8001\u94c1", "\u91cd\u5e86\u5c0f\u4f19", "\u56db\u5ddd\u59b9\u5b50", "\u6f6e\u6c55\u5927\u53d4", "\u53f0\u6e7e\u7537\u751f", "\u897f\u5b89\u638c\u67dc", "\u5929\u6d25\u59d0\u59d0", "\u65b0\u95fb\u64ad\u62a5\u7537", "\u8bd1\u5236\u7247\u7537", "\u6492\u5a07\u5973\u53cb", "\u5200\u7247\u70df\u55d3", "\u4e56\u5de7\u6b63\u592a"]}], "voice_speed": ["FLOAT", {"tooltip": "Speech Rate. Valid range: 0.8~2.0, accurate to one decimal place.", "default": 1, "min": 0.8, "max": 2.0, "display": "slider"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video", "text", "voice", "voice_speed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingLipSyncTextToVideoNode", "display_name": "Kling Lip Sync Video with Text", "description": "Kling Lip Sync Text to Video Node. Syncs mouth movements in a video file to a text prompt. The video file should not be larger than 100MB, should have height/width between 720px and 1920px, and should be between 2s and 10s in length.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingVirtualTryOnNode": {"input": {"required": {"human_image": ["IMAGE", {}], "cloth_image": ["IMAGE", {}], "model_name": ["COMBO", {"default": "kolors-virtual-try-on-v1", "multiselect": false, "options": ["kolors-virtual-try-on-v1", "kolors-virtual-try-on-v1-5"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["human_image", "cloth_image", "model_name"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "KlingVirtualTryOnNode", "display_name": "Kling Virtual Try On", "description": "Kling Virtual Try On Node. Input a human image and a cloth image to try on the cloth on the human. You can merge multiple clothing item pictures into one image with a white background.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/image/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingImageGenerationNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Positive text prompt", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative text prompt", "multiline": true}], "image_type": ["COMBO", {"multiselect": false, "options": ["subject", "face"]}], "image_fidelity": ["FLOAT", {"tooltip": "Reference intensity for user-uploaded images", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "display": "slider"}], "human_fidelity": ["FLOAT", {"tooltip": "Subject reference similarity", "default": 0.45, "min": 0.0, "max": 1.0, "step": 0.01, "display": "slider"}], "model_name": ["COMBO", {"default": "kling-v1", "multiselect": false, "options": ["kling-v1", "kling-v1-5", "kling-v2"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1", "4:3", "3:4", "3:2", "2:3", "21:9"]}], "n": ["INT", {"tooltip": "Number of generated images", "default": 1, "min": 1, "max": 9}]}, "optional": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "image_type", "image_fidelity", "human_fidelity", "model_name", "aspect_ratio", "n"], "optional": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "KlingImageGenerationNode", "display_name": "Kling Image Generation", "description": "Kling Image Generation Node. Generate an image from a text prompt with an optional reference image.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/image/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingSingleImageVideoEffectNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": " Reference Image. URL or Base64 encoded string (without data:image prefix). File size cannot exceed 10MB, resolution not less than 300*300px, aspect ratio between 1:2.5 ~ 2.5:1"}], "effect_scene": ["COMBO", {"multiselect": false, "options": ["bloombloom", "dizzydizzy", "fuzzyfuzzy", "squish", "expansion"]}], "model_name": ["COMBO", {"multiselect": false, "options": ["kling-v1-6"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5", "10"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "effect_scene", "model_name", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING", "STRING"], "output_is_list": [false, false, false], "output_name": ["VIDEO", "video_id", "duration"], "output_tooltips": [null, null, null], "name": "KlingSingleImageVideoEffectNode", "display_name": "Kling Video Effects", "description": "Achieve different special effects when generating a video based on the effect_scene.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "KlingDualCharacterVideoEffectNode": {"input": {"required": {"image_left": ["IMAGE", {"tooltip": "Left side image"}], "image_right": ["IMAGE", {"tooltip": "Right side image"}], "effect_scene": ["COMBO", {"multiselect": false, "options": ["hug", "kiss", "heart_gesture"]}], "model_name": ["COMBO", {"default": "kling-v1", "multiselect": false, "options": ["kling-v1", "kling-v1-5", "kling-v1-6"]}], "mode": ["COMBO", {"default": "std", "multiselect": false, "options": ["std", "pro"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5", "10"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image_left", "image_right", "effect_scene", "model_name", "mode", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO", "STRING"], "output_is_list": [false, false], "output_name": ["VIDEO", "duration"], "output_tooltips": [null, null], "name": "KlingDualCharacterVideoEffectNode", "display_name": "Kling Dual Character Video Effects", "description": "Achieve different special effects when generating a video based on the effect_scene. First image will be positioned on left side, second on right side of the composite.", "python_module": "comfy_api_nodes.nodes_kling", "category": "api node/video/Kling", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxProUltraImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "aspect_ratio": ["STRING", {"tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.", "default": "16:9", "multiline": false}], "raw": ["BOOLEAN", {"tooltip": "When True, generate less processed, more natural-looking images.", "default": false}]}, "optional": {"image_prompt": ["IMAGE", {}], "image_prompt_strength": ["FLOAT", {"tooltip": "Blend between the prompt and the image prompt.", "default": 0.1, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "prompt_upsampling", "seed", "aspect_ratio", "raw"], "optional": ["image_prompt", "image_prompt_strength"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxProUltraImageNode", "display_name": "Flux 1.1 [pro] Ultra Image", "description": "Generates images using Flux Pro 1.1 Ultra via api based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxKontextProImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation - specify what and how to edit.", "default": "", "multiline": true}], "aspect_ratio": ["STRING", {"tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.", "default": "16:9", "multiline": false}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 3.0, "min": 0.1, "max": 99.0, "step": 0.1}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 1, "max": 150}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 1234, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}]}, "optional": {"input_image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "guidance", "steps", "seed", "prompt_upsampling"], "optional": ["input_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxKontextProImageNode", "display_name": "Flux.1 Kontext [pro] Image", "description": "Edits images using Flux.1 Kontext [pro] via api based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxKontextMaxImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation - specify what and how to edit.", "default": "", "multiline": true}], "aspect_ratio": ["STRING", {"tooltip": "Aspect ratio of image; must be between 1:4 and 4:1.", "default": "16:9", "multiline": false}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 3.0, "min": 0.1, "max": 99.0, "step": 0.1}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 1, "max": 150}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 1234, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}]}, "optional": {"input_image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "guidance", "steps", "seed", "prompt_upsampling"], "optional": ["input_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxKontextMaxImageNode", "display_name": "Flux.1 Kontext [max] Image", "description": "Edits images using Flux.1 Kontext [max] via api based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxProExpandNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}], "top": ["INT", {"tooltip": "Number of pixels to expand at the top of the image", "default": 0, "min": 0, "max": 2048}], "bottom": ["INT", {"tooltip": "Number of pixels to expand at the bottom of the image", "default": 0, "min": 0, "max": 2048}], "left": ["INT", {"tooltip": "Number of pixels to expand at the left of the image", "default": 0, "min": 0, "max": 2048}], "right": ["INT", {"tooltip": "Number of pixels to expand at the right of the image", "default": 0, "min": 0, "max": 2048}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 60, "min": 1.5, "max": 100}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 15, "max": 50}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "prompt_upsampling", "top", "bottom", "left", "right", "guidance", "steps", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxProExpandNode", "display_name": "Flux.1 Expand Image", "description": "Outpaints image based on prompt.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "FluxProFillNode": {"input": {"required": {"image": ["IMAGE", {}], "mask": ["MASK", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "prompt_upsampling": ["BOOLEAN", {"tooltip": "Whether to perform upsampling on the prompt. If active, automatically modifies the prompt for more creative generation, but results are nondeterministic (same seed will not produce exactly the same result).", "default": false}], "guidance": ["FLOAT", {"tooltip": "Guidance strength for the image generation process", "default": 60, "min": 1.5, "max": 100}], "steps": ["INT", {"tooltip": "Number of steps for the image generation process", "default": 50, "min": 15, "max": 50}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "mask", "prompt", "prompt_upsampling", "guidance", "steps", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "FluxProFillNode", "display_name": "Flux.1 Fill Image", "description": "Inpaints image based on mask and prompt.", "python_module": "comfy_api_nodes.nodes_bfl", "category": "api node/image/BFL", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedream-3-0-t2i-250415", "multiselect": false, "options": ["seedream-3-0-t2i-250415"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the image", "multiline": true}], "size_preset": ["COMBO", {"tooltip": "Pick a recommended size. Select Custom to use the width and height below", "multiselect": false, "options": ["1024x1024 (1:1)", "864x1152 (3:4)", "1152x864 (4:3)", "1280x720 (16:9)", "720x1280 (9:16)", "832x1248 (2:3)", "1248x832 (3:2)", "1512x648 (21:9)", "2048x2048 (1:1)", "Custom"]}], "width": ["INT", {"tooltip": "Custom width for image. Value is working only if `size_preset` is set to `Custom`", "default": 1024, "min": 512, "max": 2048, "step": 64}], "height": ["INT", {"tooltip": "Custom height for image. Value is working only if `size_preset` is set to `Custom`", "default": 1024, "min": 512, "max": 2048, "step": 64}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "guidance_scale": ["FLOAT", {"tooltip": "Higher value makes the image follow the prompt more closely", "default": 2.5, "min": 1.0, "max": 10.0, "step": 0.01, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the image", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "size_preset", "width", "height"], "optional": ["seed", "guidance_scale", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ByteDanceImageNode", "display_name": "ByteDance Image", "description": "Generate images using ByteDance models via api based on prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/image/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageEditNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seededit-3-0-i2i-250628", "multiselect": false, "options": ["seededit-3-0-i2i-250628"]}], "image": ["IMAGE", {"tooltip": "The base image to edit"}], "prompt": ["STRING", {"tooltip": "Instruction to edit image", "default": "", "multiline": true}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "guidance_scale": ["FLOAT", {"tooltip": "Higher value makes the image follow the prompt more closely", "default": 5.5, "min": 1.0, "max": 10.0, "step": 0.01, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the image", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image", "prompt"], "optional": ["seed", "guidance_scale", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ByteDanceImageEditNode", "display_name": "ByteDance Image Edit", "description": "Edit images using ByteDance models via api based on prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/image/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceSeedreamNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "multiselect": false, "options": ["seedream-4-0-250828"]}], "prompt": ["STRING", {"tooltip": "Text prompt for creating or editing an image.", "default": "", "multiline": true}], "size_preset": ["COMBO", {"tooltip": "Pick a recommended size. Select Custom to use the width and height below.", "multiselect": false, "options": ["2048x2048 (1:1)", "2304x1728 (4:3)", "1728x2304 (3:4)", "2560x1440 (16:9)", "1440x2560 (9:16)", "2496x1664 (3:2)", "1664x2496 (2:3)", "3024x1296 (21:9)", "4096x4096 (1:1)", "Custom"]}]}, "optional": {"image": ["IMAGE", {"tooltip": "Input image(s) for image-to-image generation. List of 1-10 images for single or multi-reference generation."}], "width": ["INT", {"tooltip": "Custom width for image. Value is working only if `size_preset` is set to `Custom`", "default": 2048, "min": 1024, "max": 4096, "step": 64}], "height": ["INT", {"tooltip": "Custom height for image. Value is working only if `size_preset` is set to `Custom`", "default": 2048, "min": 1024, "max": 4096, "step": 64}], "sequential_image_generation": ["COMBO", {"tooltip": "Group image generation mode. 'disabled' generates a single image. 'auto' lets the model decide whether to generate multiple related images (e.g., story scenes, character variations).", "multiselect": false, "options": ["disabled", "auto"]}], "max_images": ["INT", {"tooltip": "Maximum number of images to generate when sequential_image_generation='auto'. Total images (input + generated) cannot exceed 15.", "default": 1, "min": 1, "max": 15, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the image.", "default": true}], "fail_on_partial": ["BOOLEAN", {"tooltip": "If enabled, abort execution if any requested images are missing or return an error.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "size_preset"], "optional": ["image", "width", "height", "sequential_image_generation", "max_images", "seed", "watermark", "fail_on_partial"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "ByteDanceSeedreamNode", "display_name": "ByteDance Seedream 4", "description": "Unified text-to-image generation and precise single-sentence editing at up to 4K resolution.", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/image/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceTextToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-pro-250528", "multiselect": false, "options": ["seedance-1-0-pro-250528", "seedance-1-0-lite-t2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p", "1080p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "camera_fixed": ["BOOLEAN", {"tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.", "default": false}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "camera_fixed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceTextToVideoNode", "display_name": "ByteDance Text to Video", "description": "Generate video using ByteDance models via api based on prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-pro-250528", "multiselect": false, "options": ["seedance-1-0-pro-250528", "seedance-1-0-lite-i2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "image": ["IMAGE", {"tooltip": "First frame to be used for the video."}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p", "1080p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["adaptive", "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "camera_fixed": ["BOOLEAN", {"tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.", "default": false}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "image", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "camera_fixed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceImageToVideoNode", "display_name": "ByteDance Image to Video", "description": "Generate video using ByteDance models via api based on image and prompt", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceFirstLastFrameNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-lite-i2v-250428", "multiselect": false, "options": ["seedance-1-0-pro-250528", "seedance-1-0-lite-i2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "first_frame": ["IMAGE", {"tooltip": "First frame to be used for the video."}], "last_frame": ["IMAGE", {"tooltip": "Last frame to be used for the video."}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p", "1080p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["adaptive", "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "camera_fixed": ["BOOLEAN", {"tooltip": "Specifies whether to fix the camera. The platform appends an instruction to fix the camera to your prompt, but does not guarantee the actual effect.", "default": false}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "first_frame", "last_frame", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "camera_fixed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceFirstLastFrameNode", "display_name": "ByteDance First-Last-Frame to Video", "description": "Generate video using prompt and first and last frames.", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ByteDanceImageReferenceNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "seedance-1-0-lite-i2v-250428", "multiselect": false, "options": ["seedance-1-0-lite-i2v-250428"]}], "prompt": ["STRING", {"tooltip": "The text prompt used to generate the video.", "multiline": true}], "images": ["IMAGE", {"tooltip": "One to four images."}], "resolution": ["COMBO", {"tooltip": "The resolution of the output video.", "multiselect": false, "options": ["480p", "720p"]}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video.", "multiselect": false, "options": ["adaptive", "16:9", "4:3", "1:1", "3:4", "9:16", "21:9"]}], "duration": ["INT", {"tooltip": "The duration of the output video in seconds.", "default": 5, "min": 3, "max": 12, "step": 1, "display": "slider"}]}, "optional": {"seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the video.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "images", "resolution", "aspect_ratio", "duration"], "optional": ["seed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ByteDanceImageReferenceNode", "display_name": "ByteDance Reference Images to Video", "description": "Generate video using prompt and reference images.", "python_module": "comfy_api_nodes.nodes_bytedance", "category": "api node/video/ByteDance", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LtxvApiTextToVideo": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["LTX-2 (Pro)", "LTX-2 (Fast)"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "duration": ["COMBO", {"default": 8, "multiselect": false, "options": [6, 8, 10, 12, 14, 16, 18, 20]}], "resolution": ["COMBO", {"multiselect": false, "options": ["1920x1080", "2560x1440", "3840x2160"]}], "fps": ["COMBO", {"default": 25, "multiselect": false, "options": [25, 50]}]}, "optional": {"generate_audio": ["BOOLEAN", {"tooltip": "When true, the generated video will include AI-generated audio matching the scene.", "default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "duration", "resolution", "fps"], "optional": ["generate_audio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LtxvApiTextToVideo", "display_name": "LTXV Text To Video", "description": "Professional-quality videos with customizable duration and resolution.", "python_module": "comfy_api_nodes.nodes_ltxv", "category": "api node/video/LTXV", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LtxvApiImageToVideo": {"input": {"required": {"image": ["IMAGE", {"tooltip": "First frame to be used for the video."}], "model": ["COMBO", {"multiselect": false, "options": ["LTX-2 (Pro)", "LTX-2 (Fast)"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "duration": ["COMBO", {"default": 8, "multiselect": false, "options": [6, 8, 10, 12, 14, 16, 18, 20]}], "resolution": ["COMBO", {"multiselect": false, "options": ["1920x1080", "2560x1440", "3840x2160"]}], "fps": ["COMBO", {"default": 25, "multiselect": false, "options": [25, 50]}]}, "optional": {"generate_audio": ["BOOLEAN", {"tooltip": "When true, the generated video will include AI-generated audio matching the scene.", "default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "model", "prompt", "duration", "resolution", "fps"], "optional": ["generate_audio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LtxvApiImageToVideo", "display_name": "LTXV Image To Video", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "python_module": "comfy_api_nodes.nodes_ltxv", "category": "api node/video/LTXV", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["photon-1", "photon-flash-1"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"]}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}], "style_image_weight": ["FLOAT", {"tooltip": "Weight of style image. Ignored if no style_image provided.", "default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"image_luma_ref": ["LUMA_REF", {"tooltip": "Luma Reference node connection to influence generation with input images; up to 4 images can be considered."}], "style_image": ["IMAGE", {"tooltip": "Style reference image; only 1 image will be used."}], "character_image": ["IMAGE", {"tooltip": "Character reference images; can be a batch of multiple, up to 4 images can be considered."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "seed", "style_image_weight"], "optional": ["image_luma_ref", "style_image", "character_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "LumaImageNode", "display_name": "Luma Text to Image", "description": "Generates images synchronously based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaImageModifyNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation", "default": "", "multiline": true}], "image_weight": ["FLOAT", {"tooltip": "Weight of the image; the closer to 1.0, the less the image will be modified.", "default": 0.1, "min": 0.0, "max": 0.98, "step": 0.01}], "model": ["COMBO", {"multiselect": false, "options": ["photon-1", "photon-flash-1"]}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "image_weight", "model", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "LumaImageModifyNode", "display_name": "Luma Image to Image", "description": "Modifies images synchronously based on prompt and aspect ratio.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["ray-2", "ray-flash-2", "ray-1-6"]}], "aspect_ratio": ["COMBO", {"default": "16:9", "multiselect": false, "options": ["1:1", "16:9", "9:16", "4:3", "3:4", "21:9", "9:21"]}], "resolution": ["COMBO", {"default": "540p", "multiselect": false, "options": ["540p", "720p", "1080p", "4k"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5s", "9s"]}], "loop": ["BOOLEAN", {"default": false}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "resolution", "duration", "loop", "seed"], "optional": ["luma_concepts"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LumaVideoNode", "display_name": "Luma Text to Video", "description": "Generates videos synchronously based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaImageToVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["ray-2", "ray-flash-2", "ray-1-6"]}], "resolution": ["COMBO", {"default": "540p", "multiselect": false, "options": ["540p", "720p", "1080p", "4k"]}], "duration": ["COMBO", {"multiselect": false, "options": ["5s", "9s"]}], "loop": ["BOOLEAN", {"default": false}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"first_image": ["IMAGE", {"tooltip": "First frame of generated video."}], "last_image": ["IMAGE", {"tooltip": "Last frame of generated video."}], "luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to dictate camera motion via the Luma Concepts node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "resolution", "duration", "loop", "seed"], "optional": ["first_image", "last_image", "luma_concepts"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "LumaImageToVideoNode", "display_name": "Luma Image to Video", "description": "Generates videos synchronously based on prompt, input images, and output_size.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "LumaReferenceNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "Image to use as reference."}], "weight": ["FLOAT", {"tooltip": "Weight of image reference.", "default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"luma_ref": ["LUMA_REF", {}]}}, "input_order": {"required": ["image", "weight"], "optional": ["luma_ref"]}, "output": ["LUMA_REF"], "output_is_list": [false], "output_name": ["luma_ref"], "output_tooltips": [null], "name": "LumaReferenceNode", "display_name": "Luma Reference", "description": "Holds an image and weight for use with Luma Generate Image node.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/image/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "LumaConceptsNode": {"input": {"required": {"concept1": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}], "concept2": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}], "concept3": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}], "concept4": ["COMBO", {"multiselect": false, "options": ["None", "truck_left", "pan_right", "pedestal_down", "low_angle", "pedestal_up", "selfie", "pan_left", "roll_right", "zoom_in", "over_the_shoulder", "orbit_right", "orbit_left", "static", "tiny_planet", "high_angle", "bolt_cam", "dolly_zoom", "overhead", "zoom_out", "handheld", "roll_left", "pov", "aerial_drone", "push_in", "crane_down", "truck_right", "tilt_down", "elevator_doors", "tilt_up", "ground_level", "pull_out", "aerial", "crane_up", "eye_level"]}]}, "optional": {"luma_concepts": ["LUMA_CONCEPTS", {"tooltip": "Optional Camera Concepts to add to the ones chosen here."}]}}, "input_order": {"required": ["concept1", "concept2", "concept3", "concept4"], "optional": ["luma_concepts"]}, "output": ["LUMA_CONCEPTS"], "output_is_list": [false], "output_name": ["luma_concepts"], "output_tooltips": [null], "name": "LumaConceptsNode", "display_name": "Luma Concepts", "description": "Camera Concepts for use with Luma Text to Video and Luma Image to Video nodes.", "python_module": "comfy_api_nodes.nodes_luma", "category": "api node/video/Luma", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftTextToImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "size": ["COMBO", {"tooltip": "The size of the generated image.", "default": "1024x1024", "multiselect": false, "options": ["1024x1024", "1365x1024", "1024x1365", "1536x1024", "1024x1536", "1820x1024", "1024x1820", "1024x2048", "2048x1024", "1434x1024", "1024x1434", "1024x1280", "1280x1024", "1024x1707", "1707x1024"]}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "size", "n", "seed"], "optional": ["recraft_style", "negative_prompt", "recraft_controls"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftTextToImageNode", "display_name": "Recraft Text to Image", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftImageToImageNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "strength": ["FLOAT", {"tooltip": "Defines the difference with the original image, should lie in [0, 1], where 0 means almost identical, and 1 means miserable similarity.", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "n", "strength", "seed"], "optional": ["recraft_style", "negative_prompt", "recraft_controls"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftImageToImageNode", "display_name": "Recraft Image to Image", "description": "Modify image based on prompt and strength.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftImageInpaintingNode": {"input": {"required": {"image": ["IMAGE", {}], "mask": ["MASK", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "mask", "prompt", "n", "seed"], "optional": ["recraft_style", "negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftImageInpaintingNode", "display_name": "Recraft Image Inpainting", "description": "Modify image based on prompt and mask.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftTextToVectorNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "substyle": ["COMBO", {"multiselect": false, "options": ["None", "bold_stroke", "chemistry", "colored_stencil", "contour_pop_art", "cosmics", "cutout", "depressive", "editorial", "emotional_flat", "engraving", "infographical", "line_art", "line_circuit", "linocut", "marker_outline", "mosaic", "naivector", "roundish_flat", "seamless", "segmented_colors", "sharp_contrast", "thin", "vector_photo", "vivid_shapes"]}], "size": ["COMBO", {"tooltip": "The size of the generated image.", "default": "1024x1024", "multiselect": false, "options": ["1024x1024", "1365x1024", "1024x1365", "1536x1024", "1024x1536", "1820x1024", "1024x1820", "1024x2048", "2048x1024", "1434x1024", "1024x1434", "1024x1280", "1280x1024", "1024x1707", "1707x1024"]}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}], "recraft_controls": ["RECRAFT_CONTROLS", {"tooltip": "Optional additional controls over the generation via the Recraft Controls node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "substyle", "size", "n", "seed"], "optional": ["negative_prompt", "recraft_controls"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["SVG"], "output_is_list": [false], "output_name": ["SVG"], "output_tooltips": [null], "name": "RecraftTextToVectorNode", "display_name": "Recraft Text to Vector", "description": "Generates SVG synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftVectorizeImageNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["SVG"], "output_is_list": [false], "output_name": ["SVG"], "output_tooltips": [null], "name": "RecraftVectorizeImageNode", "display_name": "Recraft Vectorize Image", "description": "Generates SVG synchronously from an input image.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftRemoveBackgroundNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "MASK"], "output_tooltips": [null, null], "name": "RecraftRemoveBackgroundNode", "display_name": "Recraft Remove Background", "description": "Remove background from image, and return processed image and mask.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftReplaceBackgroundNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the image generation.", "default": "", "multiline": true}], "n": ["INT", {"tooltip": "The number of images to generate.", "default": 1, "min": 1, "max": 6}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"recraft_style": ["RECRAFT_V3_STYLE", {}], "negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "n", "seed"], "optional": ["recraft_style", "negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftReplaceBackgroundNode", "display_name": "Recraft Replace Background", "description": "Replace background on image, based on provided prompt.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftCrispUpscaleNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftCrispUpscaleNode", "display_name": "Recraft Crisp Upscale Image", "description": "Upscale image synchronously.\nEnhances a given raster image using \u2018crisp upscale\u2019 tool, increasing image resolution, making the image sharper and cleaner.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftCreativeUpscaleNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RecraftCreativeUpscaleNode", "display_name": "Recraft Creative Upscale Image", "description": "Upscale image synchronously.\nEnhances a given raster image using \u2018creative upscale\u2019 tool, boosting resolution with a focus on refining small details and faces.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RecraftStyleV3RealisticImage": {"input": {"required": {"substyle": ["COMBO", {"multiselect": false, "options": ["None", "b_and_w", "enterprise", "evening_light", "faded_nostalgia", "forest_life", "hard_flash", "hdr", "motion_blur", "mystic_naturalism", "natural_light", "natural_tones", "organic_calm", "real_life_glow", "retro_realism", "retro_snapshot", "studio_portrait", "urban_drama", "village_realism", "warm_folk"]}]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3RealisticImage", "display_name": "Recraft Style - Realistic Image", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftStyleV3DigitalIllustration": {"input": {"required": {"substyle": ["COMBO", {"multiselect": false, "options": ["None", "2d_art_poster", "2d_art_poster_2", "antiquarian", "bold_fantasy", "child_book", "child_books", "cover", "crosshatch", "digital_engraving", "engraving_color", "expressionism", "freehand_details", "grain", "grain_20", "graphic_intensity", "hand_drawn", "hand_drawn_outline", "handmade_3d", "hard_comics", "infantile_sketch", "long_shadow", "modern_folk", "multicolor", "neon_calm", "noir", "nostalgic_pastel", "outline_details", "pastel_gradient", "pastel_sketch", "pixel_art", "plastic", "pop_art", "pop_renaissance", "seamless", "street_art", "tablet_sketch", "urban_glow", "urban_sketching", "vanilla_dreams", "young_adult_book", "young_adult_book_2"]}]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3DigitalIllustration", "display_name": "Recraft Style - Digital Illustration", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftStyleV3LogoRaster": {"input": {"required": {"substyle": ["COMBO", {"multiselect": false, "options": ["emblem_graffiti", "emblem_pop_art", "emblem_punk", "emblem_stamp", "emblem_vintage"]}]}}, "input_order": {"required": ["substyle"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3LogoRaster", "display_name": "Recraft Style - Logo Raster", "description": "Select realistic_image style and optional substyle.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftStyleV3InfiniteStyleLibrary": {"input": {"required": {"style_id": ["STRING", {"tooltip": "UUID of style from Infinite Style Library.", "default": "", "multiline": false}]}}, "input_order": {"required": ["style_id"]}, "output": ["RECRAFT_V3_STYLE"], "output_is_list": [false], "output_name": ["recraft_style"], "output_tooltips": [null], "name": "RecraftStyleV3InfiniteStyleLibrary", "display_name": "Recraft Style - Infinite Style Library", "description": "Select style based on preexisting UUID from Recraft's Infinite Style Library.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftColorRGB": {"input": {"required": {"r": ["INT", {"tooltip": "Red value of color.", "default": 0, "min": 0, "max": 255}], "g": ["INT", {"tooltip": "Green value of color.", "default": 0, "min": 0, "max": 255}], "b": ["INT", {"tooltip": "Blue value of color.", "default": 0, "min": 0, "max": 255}]}, "optional": {"recraft_color": ["RECRAFT_COLOR", {}]}}, "input_order": {"required": ["r", "g", "b"], "optional": ["recraft_color"]}, "output": ["RECRAFT_COLOR"], "output_is_list": [false], "output_name": ["recraft_color"], "output_tooltips": [null], "name": "RecraftColorRGB", "display_name": "Recraft Color RGB", "description": "Create Recraft Color by choosing specific RGB values.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "RecraftControls": {"input": {"required": {}, "optional": {"colors": ["RECRAFT_COLOR", {}], "background_color": ["RECRAFT_COLOR", {}]}}, "input_order": {"required": [], "optional": ["colors", "background_color"]}, "output": ["RECRAFT_CONTROLS"], "output_is_list": [false], "output_name": ["recraft_controls"], "output_tooltips": [null], "name": "RecraftControls", "display_name": "Recraft Controls", "description": "Create Recraft Controls for customizing Recraft generation.", "python_module": "comfy_api_nodes.nodes_recraft", "category": "api node/image/Recraft", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "PixverseTextToVideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"multiselect": false, "options": ["16:9", "4:3", "1:1", "3:4", "9:16"]}], "quality": ["COMBO", {"default": "540p", "multiselect": false, "options": ["360p", "540p", "720p", "1080p"]}], "duration_seconds": ["COMBO", {"multiselect": false, "options": [5, 8]}], "motion_mode": ["COMBO", {"multiselect": false, "options": ["normal", "fast"]}], "seed": ["INT", {"tooltip": "Seed for video generation.", "default": 0, "min": 0, "max": 2147483647, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "multiline": true}], "pixverse_template": ["PIXVERSE_TEMPLATE", {"tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt", "pixverse_template"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PixverseTextToVideoNode", "display_name": "PixVerse Text to Video", "description": "Generates videos based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PixverseImageToVideoNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "quality": ["COMBO", {"default": "540p", "multiselect": false, "options": ["360p", "540p", "720p", "1080p"]}], "duration_seconds": ["COMBO", {"multiselect": false, "options": [5, 8]}], "motion_mode": ["COMBO", {"multiselect": false, "options": ["normal", "fast"]}], "seed": ["INT", {"tooltip": "Seed for video generation.", "default": 0, "min": 0, "max": 2147483647, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "multiline": true}], "pixverse_template": ["PIXVERSE_TEMPLATE", {"tooltip": "An optional template to influence style of generation, created by the PixVerse Template node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt", "pixverse_template"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PixverseImageToVideoNode", "display_name": "PixVerse Image to Video", "description": "Generates videos based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PixverseTransitionVideoNode": {"input": {"required": {"first_frame": ["IMAGE", {}], "last_frame": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt for the video generation", "default": "", "multiline": true}], "quality": ["COMBO", {"default": "540p", "multiselect": false, "options": ["360p", "540p", "720p", "1080p"]}], "duration_seconds": ["COMBO", {"multiselect": false, "options": [5, 8]}], "motion_mode": ["COMBO", {"multiselect": false, "options": ["normal", "fast"]}], "seed": ["INT", {"tooltip": "Seed for video generation.", "default": 0, "min": 0, "max": 2147483647, "control_after_generate": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "An optional text description of undesired elements on an image.", "default": "", "multiline": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["first_frame", "last_frame", "prompt", "quality", "duration_seconds", "motion_mode", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PixverseTransitionVideoNode", "display_name": "PixVerse Transition Video", "description": "Generates videos based on prompt and output_size.", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PixverseTemplateNode": {"input": {"required": {"template": ["COMBO", {"multiselect": false, "options": ["Microwave", "Suit Swagger", "Anything, Robot", "Subject 3 Fever", "kiss kiss"]}]}}, "input_order": {"required": ["template"]}, "output": ["PIXVERSE_TEMPLATE"], "output_is_list": [false], "output_name": ["pixverse_template"], "output_tooltips": [null], "name": "PixverseTemplateNode", "display_name": "PixVerse Template", "description": "", "python_module": "comfy_api_nodes.nodes_pixverse", "category": "api node/video/PixVerse", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "StabilityStableImageUltraNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defineselements, colors, and subjects will lead to better results. To control the weight of a given word use the format `(word:weight)`,where `word` is the word you'd like to control the weight of and `weight`is a value between 0 and 1. For example: `The sky was a crisp (blue:0.3) and (green:0.8)`would convey a sky that was blue and green, but more green than blue.", "default": "", "multiline": true}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of generated image.", "default": "1:1", "multiselect": false, "options": ["1:1", "16:9", "9:16", "3:2", "2:3", "5:4", "4:5", "21:9", "9:21"]}], "style_preset": ["COMBO", {"tooltip": "Optional desired style of generated image.", "multiselect": false, "options": ["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"]}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"image": ["IMAGE", {}], "negative_prompt": ["STRING", {"tooltip": "A blurb of text describing what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}], "image_denoise": ["FLOAT", {"tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "aspect_ratio", "style_preset", "seed"], "optional": ["image", "negative_prompt", "image_denoise"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityStableImageUltraNode", "display_name": "Stability AI Stable Image Ultra", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityStableImageSD_3_5Node": {"input": {"required": {"prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.", "default": "", "multiline": true}], "model": ["COMBO", {"multiselect": false, "options": ["sd3.5-large", "sd3.5-medium"]}], "aspect_ratio": ["COMBO", {"tooltip": "Aspect ratio of generated image.", "default": "1:1", "multiselect": false, "options": ["1:1", "16:9", "9:16", "3:2", "2:3", "5:4", "4:5", "21:9", "9:21"]}], "style_preset": ["COMBO", {"tooltip": "Optional desired style of generated image.", "multiselect": false, "options": ["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"]}], "cfg_scale": ["FLOAT", {"tooltip": "How strictly the diffusion process adheres to the prompt text (higher values keep your image closer to your prompt)", "default": 4.0, "min": 1.0, "max": 10.0, "step": 0.1}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"image": ["IMAGE", {}], "negative_prompt": ["STRING", {"tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}], "image_denoise": ["FLOAT", {"tooltip": "Denoise of input image; 0.0 yields image identical to input, 1.0 is as if no image was provided at all.", "default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "aspect_ratio", "style_preset", "cfg_scale", "seed"], "optional": ["image", "negative_prompt", "image_denoise"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityStableImageSD_3_5Node", "display_name": "Stability AI Stable Diffusion 3.5 Image", "description": "Generates images synchronously based on prompt and resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityUpscaleConservativeNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.", "default": "", "multiline": true}], "creativity": ["FLOAT", {"tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image.", "default": 0.35, "min": 0.2, "max": 0.5, "step": 0.01}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "creativity", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityUpscaleConservativeNode", "display_name": "Stability AI Upscale Conservative", "description": "Upscale image with minimal alterations to 4K resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityUpscaleCreativeNode": {"input": {"required": {"image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "What you wish to see in the output image. A strong, descriptive prompt that clearly defines elements, colors, and subjects will lead to better results.", "default": "", "multiline": true}], "creativity": ["FLOAT", {"tooltip": "Controls the likelihood of creating additional details not heavily conditioned by the init image.", "default": 0.3, "min": 0.1, "max": 0.5, "step": 0.01}], "style_preset": ["COMBO", {"tooltip": "Optional desired style of generated image.", "multiselect": false, "options": ["None", "3d-model", "analog-film", "anime", "cinematic", "comic-book", "digital-art", "enhance", "fantasy-art", "isometric", "line-art", "low-poly", "modeling-compound", "neon-punk", "origami", "photographic", "pixel-art", "tile-texture"]}], "seed": ["INT", {"tooltip": "The random seed used for creating the noise.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Keywords of what you do not wish to see in the output image. This is an advanced feature.", "default": "", "forceInput": true, "multiline": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "creativity", "style_preset", "seed"], "optional": ["negative_prompt"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityUpscaleCreativeNode", "display_name": "Stability AI Upscale Creative", "description": "Upscale image with minimal alterations to 4K resolution.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityUpscaleFastNode": {"input": {"required": {"image": ["IMAGE", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "StabilityUpscaleFastNode", "display_name": "Stability AI Upscale Fast", "description": "Quickly upscales an image via Stability API call to 4x its original size; intended for upscaling low-quality/compressed images.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/image/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityTextToAudio": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["stable-audio-2.5"]}], "prompt": ["STRING", {"default": "", "multiline": true}]}, "optional": {"duration": ["INT", {"tooltip": "Controls the duration in seconds of the generated audio.", "default": 190, "min": 1, "max": 190, "step": 1}], "seed": ["INT", {"tooltip": "The random seed used for generation.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Controls the number of sampling steps.", "default": 8, "min": 4, "max": 8, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["duration", "seed", "steps"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "output_tooltips": [null], "name": "StabilityTextToAudio", "display_name": "Stability AI Text To Audio", "description": "Generates high-quality music and sound effects from text descriptions.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/audio/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityAudioToAudio": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["stable-audio-2.5"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "audio": ["AUDIO", {"tooltip": "Audio must be between 6 and 190 seconds long."}]}, "optional": {"duration": ["INT", {"tooltip": "Controls the duration in seconds of the generated audio.", "default": 190, "min": 1, "max": 190, "step": 1}], "seed": ["INT", {"tooltip": "The random seed used for generation.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Controls the number of sampling steps.", "default": 8, "min": 4, "max": 8, "step": 1}], "strength": ["FLOAT", {"tooltip": "Parameter controls how much influence the audio parameter has on the generated audio.", "default": 1, "min": 0.01, "max": 1.0, "step": 0.01, "display": "slider"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "audio"], "optional": ["duration", "seed", "steps", "strength"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "output_tooltips": [null], "name": "StabilityAudioToAudio", "display_name": "Stability AI Audio To Audio", "description": "Transforms existing audio samples into new high-quality compositions using text instructions.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/audio/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "StabilityAudioInpaint": {"input": {"required": {"model": ["COMBO", {"multiselect": false, "options": ["stable-audio-2.5"]}], "prompt": ["STRING", {"default": "", "multiline": true}], "audio": ["AUDIO", {"tooltip": "Audio must be between 6 and 190 seconds long."}]}, "optional": {"duration": ["INT", {"tooltip": "Controls the duration in seconds of the generated audio.", "default": 190, "min": 1, "max": 190, "step": 1}], "seed": ["INT", {"tooltip": "The random seed used for generation.", "default": 0, "min": 0, "max": 4294967294, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Controls the number of sampling steps.", "default": 8, "min": 4, "max": 8, "step": 1}], "mask_start": ["INT", {"default": 30, "min": 0, "max": 190, "step": 1}], "mask_end": ["INT", {"default": 190, "min": 0, "max": 190, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "audio"], "optional": ["duration", "seed", "steps", "mask_start", "mask_end"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["AUDIO"], "output_tooltips": [null], "name": "StabilityAudioInpaint", "display_name": "Stability AI Audio Inpaint", "description": "Transforms part of existing audio sample using text instructions.", "python_module": "comfy_api_nodes.nodes_stability", "category": "api node/audio/Stability AI", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaImageToVideoNode2_2": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The image to convert to video"}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt_text", "negative_prompt", "seed", "resolution", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaImageToVideoNode2_2", "display_name": "Pika Image to Video", "description": "Sends an image and prompt to the Pika API v2.2 to generate a video.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaTextToVideoNode2_2": {"input": {"required": {"prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}], "aspect_ratio": ["FLOAT", {"tooltip": "Aspect ratio (width / height)", "default": 1.7777777777777777, "min": 0.4, "max": 2.5, "step": 0.001}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text", "negative_prompt", "seed", "resolution", "duration", "aspect_ratio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaTextToVideoNode2_2", "display_name": "Pika Text to Video", "description": "Sends a text prompt to the Pika API v2.2 to generate a video.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaScenesV2_2": {"input": {"required": {"prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}], "ingredients_mode": ["COMBO", {"default": "creative", "multiselect": false, "options": ["creative", "precise"]}], "aspect_ratio": ["FLOAT", {"tooltip": "Aspect ratio (width / height)", "default": 1.7777777777777777, "min": 0.4, "max": 2.5, "step": 0.001}]}, "optional": {"image_ingredient_1": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_2": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_3": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_4": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}], "image_ingredient_5": ["IMAGE", {"tooltip": "Image that will be used as ingredient to create a video."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt_text", "negative_prompt", "seed", "resolution", "duration", "ingredients_mode", "aspect_ratio"], "optional": ["image_ingredient_1", "image_ingredient_2", "image_ingredient_3", "image_ingredient_4", "image_ingredient_5"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaScenesV2_2", "display_name": "Pika Scenes (Video Image Composition)", "description": "Combine your images to create a video with the objects in them. Upload multiple images as ingredients and generate a high-quality video that incorporates all of them.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Pikadditions": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to add an image to."}], "image": ["IMAGE", {"tooltip": "The image to add to the video."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video", "image", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Pikadditions", "display_name": "Pikadditions (Video Object Insertion)", "description": "Add any object or image into your video. Upload a video and specify what you'd like to add to create a seamlessly integrated result.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Pikaswaps": {"input": {"required": {"video": ["VIDEO", {"tooltip": "The video to swap an object in."}]}, "optional": {"image": ["IMAGE", {"tooltip": "The image used to replace the masked object in the video."}], "mask": ["MASK", {"tooltip": "Use the mask to define areas in the video to replace."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "region_to_modify": ["STRING", {"tooltip": "Plaintext description of the object / region to modify.", "multiline": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["video"], "optional": ["image", "mask", "prompt_text", "negative_prompt", "seed", "region_to_modify"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Pikaswaps", "display_name": "Pika Swaps (Video Object Replacement)", "description": "Swap out any object or region of your video with a new image or object. Define areas to replace either with a mask or coordinates.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Pikaffects": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The reference image to apply the Pikaffect to."}], "pikaffect": ["COMBO", {"default": "Cake-ify", "multiselect": false, "options": ["Cake-ify", "Crumble", "Crush", "Decapitate", "Deflate", "Dissolve", "Explode", "Eye-pop", "Inflate", "Levitate", "Melt", "Peel", "Poke", "Squish", "Ta-da", "Tear"]}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "pikaffect", "prompt_text", "negative_prompt", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "Pikaffects", "display_name": "Pikaffects (Video Effects)", "description": "Generate a video with a specific Pikaffect. Supported Pikaffects: Cake-ify, Crumble, Crush, Decapitate, Deflate, Dissolve, Explode, Eye-pop, Inflate, Levitate, Melt, Peel, Poke, Squish, Ta-da, Tear", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "PikaStartEndFrameNode2_2": {"input": {"required": {"image_start": ["IMAGE", {"tooltip": "The first image to combine."}], "image_end": ["IMAGE", {"tooltip": "The last image to combine."}], "prompt_text": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"multiline": true}], "seed": ["INT", {"min": 0, "max": 4294967295, "control_after_generate": true}], "resolution": ["COMBO", {"default": "1080p", "multiselect": false, "options": ["1080p", "720p"]}], "duration": ["COMBO", {"default": 5, "multiselect": false, "options": [5, 10]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image_start", "image_end", "prompt_text", "negative_prompt", "seed", "resolution", "duration"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "PikaStartEndFrameNode2_2", "display_name": "Pika Start and End Frame to Video", "description": "Generate a video by combining your first and last frame. Upload two images to define the start and end points, and let the AI create a smooth transition between them.", "python_module": "comfy_api_nodes.nodes_pika", "category": "api node/video/Pika", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayFirstLastFrameNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "start_frame": ["IMAGE", {"tooltip": "Start frame to be used for the video"}], "end_frame": ["IMAGE", {"tooltip": "End frame to be used for the video. Supported for gen3a_turbo only."}], "duration": ["COMBO", {"multiselect": false, "options": [5, 10]}], "ratio": ["COMBO", {"multiselect": false, "options": ["768:1280", "1280:768"]}], "seed": ["INT", {"tooltip": "Random seed for generation", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "start_frame", "end_frame", "duration", "ratio", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "RunwayFirstLastFrameNode", "display_name": "Runway First-Last-Frame to Video", "description": "Upload first and last keyframes, draft a prompt, and generate a video. More complex transitions, such as cases where the Last frame is completely different from the First frame, may benefit from the longer 10s duration. This would give the generation more time to smoothly transition between the two inputs. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/34170748696595-Creating-with-Keyframes-on-Gen-3.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/video/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayImageToVideoNodeGen3a": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "start_frame": ["IMAGE", {"tooltip": "Start frame to be used for the video"}], "duration": ["COMBO", {"multiselect": false, "options": [5, 10]}], "ratio": ["COMBO", {"multiselect": false, "options": ["768:1280", "1280:768"]}], "seed": ["INT", {"tooltip": "Random seed for generation", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "start_frame", "duration", "ratio", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "RunwayImageToVideoNodeGen3a", "display_name": "Runway Image to Video (Gen3a Turbo)", "description": "Generate a video from a single starting frame using Gen3a Turbo model. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/33927968552339-Creating-with-Act-One-on-Gen-3-Alpha-and-Turbo.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/video/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayImageToVideoNodeGen4": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "start_frame": ["IMAGE", {"tooltip": "Start frame to be used for the video"}], "duration": ["COMBO", {"multiselect": false, "options": [5, 10]}], "ratio": ["COMBO", {"multiselect": false, "options": ["1280:720", "720:1280", "1104:832", "832:1104", "960:960", "1584:672"]}], "seed": ["INT", {"tooltip": "Random seed for generation", "default": 0, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "start_frame", "duration", "ratio", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "RunwayImageToVideoNodeGen4", "display_name": "Runway Image to Video (Gen4 Turbo)", "description": "Generate a video from a single starting frame using Gen4 Turbo model. Before diving in, review these best practices to ensure that your input selections will set your generation up for success: https://help.runwayml.com/hc/en-us/articles/37327109429011-Creating-with-Gen-4-Video.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/video/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "RunwayTextToImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for the generation", "default": "", "multiline": true}], "ratio": ["COMBO", {"multiselect": false, "options": ["1920:1080", "1080:1920", "1024:1024", "1360:768", "1080:1080", "1168:880", "1440:1080", "1080:1440", "1808:768", "2112:912"]}]}, "optional": {"reference_image": ["IMAGE", {"tooltip": "Optional reference image to guide the generation"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "ratio"], "optional": ["reference_image"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "RunwayTextToImageNode", "display_name": "Runway Text to Image", "description": "Generate an image from a text prompt using Runway's Gen 4 model. You can also include reference image to guide the generation.", "python_module": "comfy_api_nodes.nodes_runway", "category": "api node/image/Runway", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "OpenAIVideoSora2": {"input": {"required": {"model": ["COMBO", {"default": "sora-2", "multiselect": false, "options": ["sora-2", "sora-2-pro"]}], "prompt": ["STRING", {"tooltip": "Guiding text; may be empty if an input image is present.", "default": "", "multiline": true}], "size": ["COMBO", {"default": "1280x720", "multiselect": false, "options": ["720x1280", "1280x720", "1024x1792", "1792x1024"]}], "duration": ["COMBO", {"default": 8, "multiselect": false, "options": [4, 8, 12]}]}, "optional": {"image": ["IMAGE", {}], "seed": ["INT", {"tooltip": "Seed to determine if node should re-run; actual results are nondeterministic regardless of seed.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt", "size", "duration"], "optional": ["image", "seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "OpenAIVideoSora2", "display_name": "OpenAI Sora - Video", "description": "OpenAI video and audio generation.", "python_module": "comfy_api_nodes.nodes_sora", "category": "api node/video/Sora", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "TripoTextToModelNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"multiline": true}], "model_version": ["COMBO", {"default": "v2.5-20250123", "multiselect": false, "options": ["v2.5-20250123", "v2.0-20240919", "v1.4-20240625"]}], "style": ["COMBO", {"default": "None", "multiselect": false, "options": ["person:person2cartoon", "animal:venom", "object:clay", "object:steampunk", "object:christmas", "object:barbie", "gold", "ancient_bronze", "None"]}], "texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "image_seed": ["INT", {"default": 42}], "model_seed": ["INT", {"default": 42}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "quad": ["BOOLEAN", {"default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["prompt"], "optional": ["negative_prompt", "model_version", "style", "texture", "pbr", "image_seed", "model_seed", "texture_seed", "texture_quality", "face_limit", "quad"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoTextToModelNode", "display_name": "Tripo: Text to Model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoImageToModelNode": {"input": {"required": {"image": ["IMAGE", {}]}, "optional": {"model_version": ["COMBO", {"tooltip": "The model version to use for generation", "multiselect": false, "options": ["v2.5-20250123", "v2.0-20240919", "v1.4-20240625"]}], "style": ["COMBO", {"default": "None", "multiselect": false, "options": ["person:person2cartoon", "animal:venom", "object:clay", "object:steampunk", "object:christmas", "object:barbie", "gold", "ancient_bronze", "None"]}], "texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "model_seed": ["INT", {"default": 42}], "orientation": ["COMBO", {"default": "default", "multiselect": false, "options": ["align_image", "default"]}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "texture_alignment": ["COMBO", {"default": "original_image", "multiselect": false, "options": ["original_image", "geometry"]}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "quad": ["BOOLEAN", {"default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["image"], "optional": ["model_version", "style", "texture", "pbr", "model_seed", "orientation", "texture_seed", "texture_quality", "texture_alignment", "face_limit", "quad"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoImageToModelNode", "display_name": "Tripo: Image to Model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoMultiviewToModelNode": {"input": {"required": {"image": ["IMAGE", {}]}, "optional": {"image_left": ["IMAGE", {}], "image_back": ["IMAGE", {}], "image_right": ["IMAGE", {}], "model_version": ["COMBO", {"tooltip": "The model version to use for generation", "multiselect": false, "options": ["v2.5-20250123", "v2.0-20240919", "v1.4-20240625"]}], "orientation": ["COMBO", {"default": "default", "multiselect": false, "options": ["align_image", "default"]}], "texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "model_seed": ["INT", {"default": 42}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "texture_alignment": ["COMBO", {"default": "original_image", "multiselect": false, "options": ["original_image", "geometry"]}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "quad": ["BOOLEAN", {"default": false}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["image"], "optional": ["image_left", "image_back", "image_right", "model_version", "orientation", "texture", "pbr", "model_seed", "texture_seed", "texture_quality", "texture_alignment", "face_limit", "quad"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoMultiviewToModelNode", "display_name": "Tripo: Multiview to Model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoTextureNode": {"input": {"required": {"model_task_id": ["MODEL_TASK_ID", {}]}, "optional": {"texture": ["BOOLEAN", {"default": true}], "pbr": ["BOOLEAN", {"default": true}], "texture_seed": ["INT", {"default": 42}], "texture_quality": ["COMBO", {"default": "standard", "multiselect": false, "options": ["standard", "detailed"]}], "texture_alignment": ["COMBO", {"default": "original_image", "multiselect": false, "options": ["original_image", "geometry"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["model_task_id"], "optional": ["texture", "pbr", "texture_seed", "texture_quality", "texture_alignment"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoTextureNode", "display_name": "Tripo: Texture model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoRefineNode": {"input": {"required": {"model_task_id": ["MODEL_TASK_ID", {"tooltip": "Must be a v1.4 Tripo model"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["model_task_id"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "MODEL_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "model task_id"], "output_tooltips": [null, null], "name": "TripoRefineNode", "display_name": "Tripo: Refine Draft model", "description": "Refine a draft model created by v1.4 Tripo models only.", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoRigNode": {"input": {"required": {"original_model_task_id": ["MODEL_TASK_ID", {}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["original_model_task_id"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "RIG_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "rig task_id"], "output_tooltips": [null, null], "name": "TripoRigNode", "display_name": "Tripo: Rig model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoRetargetNode": {"input": {"required": {"original_model_task_id": ["RIG_TASK_ID", {}], "animation": ["COMBO", {"multiselect": false, "options": ["preset:idle", "preset:walk", "preset:climb", "preset:jump", "preset:slash", "preset:shoot", "preset:hurt", "preset:fall", "preset:turn"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["original_model_task_id", "animation"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": ["STRING", "RETARGET_TASK_ID"], "output_is_list": [false, false], "output_name": ["model_file", "retarget task_id"], "output_tooltips": [null, null], "name": "TripoRetargetNode", "display_name": "Tripo: Retarget rigged model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "TripoConversionNode": {"input": {"required": {"original_model_task_id": ["MODEL_TASK_ID,RIG_TASK_ID,RETARGET_TASK_ID", {}], "format": ["COMBO", {"multiselect": false, "options": ["GLTF", "USDZ", "FBX", "OBJ", "STL", "3MF"]}]}, "optional": {"quad": ["BOOLEAN", {"default": false}], "face_limit": ["INT", {"default": -1, "min": -1, "max": 500000}], "texture_size": ["INT", {"default": 4096, "min": 128, "max": 4096}], "texture_format": ["COMBO", {"default": "JPEG", "multiselect": false, "options": ["BMP", "DPX", "HDR", "JPEG", "OPEN_EXR", "PNG", "TARGA", "TIFF", "WEBP"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"], "prompt": ["PROMPT"], "extra_pnginfo": ["EXTRA_PNGINFO"]}}, "input_order": {"required": ["original_model_task_id", "format"], "optional": ["quad", "face_limit", "texture_size", "texture_format"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id", "prompt", "extra_pnginfo"]}, "output": [], "output_is_list": [], "output_name": [], "output_tooltips": [], "name": "TripoConversionNode", "display_name": "Tripo: Convert model", "description": "", "python_module": "comfy_api_nodes.nodes_tripo", "category": "api node/3d/Tripo", "output_node": true, "deprecated": false, "experimental": false, "api_node": true}, "MoonvalleyImg2VideoNode": {"input": {"required": {"image": ["IMAGE", {"tooltip": "The reference image used to generate the video"}], "prompt": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative prompt text", "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring", "multiline": true}], "resolution": ["COMBO", {"tooltip": "Resolution of the output video", "default": "16:9 (1920 x 1080)", "multiselect": false, "options": ["16:9 (1920 x 1080)", "9:16 (1080 x 1920)", "1:1 (1152 x 1152)", "4:3 (1536 x 1152)", "3:4 (1152 x 1536)"]}], "prompt_adherence": ["FLOAT", {"tooltip": "Guidance scale for generation control", "default": 4.5, "min": 1.0, "max": 20.0, "step": 1.0}], "seed": ["INT", {"tooltip": "Random seed value", "default": 9, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Number of denoising steps", "default": 33, "min": 1, "max": 100, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["image", "prompt", "negative_prompt", "resolution", "prompt_adherence", "seed", "steps"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MoonvalleyImg2VideoNode", "display_name": "Moonvalley Marey Image to Video", "description": "Moonvalley Marey Image to Video Node", "python_module": "comfy_api_nodes.nodes_moonvalley", "category": "api node/video/Moonvalley Marey", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MoonvalleyTxt2VideoNode": {"input": {"required": {"prompt": ["STRING", {"multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative prompt text", "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring", "multiline": true}], "resolution": ["COMBO", {"tooltip": "Resolution of the output video", "default": "16:9 (1920 x 1080)", "multiselect": false, "options": ["16:9 (1920 x 1080)", "9:16 (1080 x 1920)", "1:1 (1152 x 1152)", "4:3 (1536 x 1152)", "3:4 (1152 x 1536)", "21:9 (2560 x 1080)"]}], "prompt_adherence": ["FLOAT", {"tooltip": "Guidance scale for generation control", "default": 4.0, "min": 1.0, "max": 20.0, "step": 1.0}], "seed": ["INT", {"tooltip": "Random seed value", "default": 9, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": true, "display": "number"}], "steps": ["INT", {"tooltip": "Inference steps", "default": 33, "min": 1, "max": 100, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "resolution", "prompt_adherence", "seed", "steps"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MoonvalleyTxt2VideoNode", "display_name": "Moonvalley Marey Text to Video", "description": "", "python_module": "comfy_api_nodes.nodes_moonvalley", "category": "api node/video/Moonvalley Marey", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "MoonvalleyVideo2VideoNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Describes the video to generate", "multiline": true}], "negative_prompt": ["STRING", {"tooltip": "Negative prompt text", "default": "<synthetic> <scene cut> gopro, bright, contrast, static, overexposed, vignette, artifacts, still, noise, texture, scanlines, videogame, 360 camera, VR, transition, flare, saturation, distorted, warped, wide angle, saturated, vibrant, glowing, cross dissolve, cheesy, ugly hands, mutated hands, mutant, disfigured, extra fingers, blown out, horrible, blurry, worst quality, bad, dissolve, melt, fade in, fade out, wobbly, weird, low quality, plastic, stock footage, video camera, boring", "multiline": true}], "seed": ["INT", {"tooltip": "Random seed value", "default": 9, "min": 0, "max": 4294967295, "step": 1, "control_after_generate": false, "display": "number"}], "video": ["VIDEO", {"tooltip": "The reference video used to generate the output video. Must be at least 5 seconds long. Videos longer than 5s will be automatically trimmed. Only MP4 format supported."}], "steps": ["INT", {"tooltip": "Number of inference steps", "default": 33, "min": 1, "max": 100, "step": 1, "display": "number"}]}, "optional": {"control_type": ["COMBO", {"default": "Motion Transfer", "multiselect": false, "options": ["Motion Transfer", "Pose Transfer"]}], "motion_intensity": ["INT", {"tooltip": "Only used if control_type is 'Motion Transfer'", "default": 100, "min": 0, "max": 100, "step": 1}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "negative_prompt", "seed", "video", "steps"], "optional": ["control_type", "motion_intensity"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "MoonvalleyVideo2VideoNode", "display_name": "Moonvalley Marey Video to Video", "description": "", "python_module": "comfy_api_nodes.nodes_moonvalley", "category": "api node/video/Moonvalley Marey", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Regular": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "18K-Quad", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "200K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["Images"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Regular", "display_name": "Rodin 3D Generate - Regular Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Detail": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "18K-Quad", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "200K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["Images"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Detail", "display_name": "Rodin 3D Generate - Detail Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Smooth": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "18K-Quad", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "200K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["Images"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Smooth", "display_name": "Rodin 3D Generate - Smooth Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Sketch": {"input": {"required": {"Images": ["IMAGE", {}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["Images"], "optional": ["Seed"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Sketch", "display_name": "Rodin 3D Generate - Sketch Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "Rodin3D_Gen2": {"input": {"required": {"Images": ["IMAGE", {}], "TAPose": ["BOOLEAN", {"default": false}]}, "optional": {"Seed": ["INT", {"default": 0, "min": 0, "max": 65535, "display": "number"}], "Material_Type": ["COMBO", {"default": "PBR", "multiselect": false, "options": ["PBR", "Shaded"]}], "Polygon_count": ["COMBO", {"default": "500K-Triangle", "multiselect": false, "options": ["4K-Quad", "8K-Quad", "18K-Quad", "50K-Quad", "2K-Triangle", "20K-Triangle", "150K-Triangle", "500K-Triangle"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["Images", "TAPose"], "optional": ["Seed", "Material_Type", "Polygon_count"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["3D Model Path"], "output_tooltips": [null], "name": "Rodin3D_Gen2", "display_name": "Rodin 3D Generate - Gen-2 Generate", "description": "Generate 3D Assets using Rodin API", "python_module": "comfy_api_nodes.nodes_rodin", "category": "api node/3d/Rodin", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "GeminiNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text inputs to the model, used to generate a response. You can include detailed instructions, questions, or context for the model.", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "The Gemini model to use for generating responses.", "default": "gemini-2.5-pro", "multiselect": false, "options": ["gemini-2.5-pro-preview-05-06", "gemini-2.5-flash-preview-04-17", "gemini-2.5-pro", "gemini-2.5-flash"]}], "seed": ["INT", {"tooltip": "When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.", "default": 42, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"images": ["IMAGE", {"tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."}], "audio": ["AUDIO", {"tooltip": "Optional audio to use as context for the model."}], "video": ["VIDEO", {"tooltip": "Optional video to use as context for the model."}], "files": ["GEMINI_INPUT_FILES", {"tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "seed"], "optional": ["images", "audio", "video", "files"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["STRING"], "output_tooltips": [null], "name": "GeminiNode", "display_name": "Google Gemini", "description": "Generate text responses with Google's Gemini AI model. You can provide multiple types of inputs (text, images, audio, video) as context for generating more relevant and meaningful responses.", "python_module": "comfy_api_nodes.nodes_gemini", "category": "api node/text/Gemini", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "GeminiImageNode": {"input": {"required": {"prompt": ["STRING", {"tooltip": "Text prompt for generation", "default": "", "multiline": true}], "model": ["COMBO", {"tooltip": "The Gemini model to use for generating responses.", "default": "gemini-2.5-flash-image", "multiselect": false, "options": ["gemini-2.5-flash-image-preview", "gemini-2.5-flash-image"]}], "seed": ["INT", {"tooltip": "When seed is fixed to a specific value, the model makes a best effort to provide the same response for repeated requests. Deterministic output isn't guaranteed. Also, changing the model or parameter settings, such as the temperature, can cause variations in the response even when you use the same seed value. By default, a random seed value is used.", "default": 42, "min": 0, "max": 18446744073709551615, "control_after_generate": true}]}, "optional": {"images": ["IMAGE", {"tooltip": "Optional image(s) to use as context for the model. To include multiple images, you can use the Batch Images node."}], "files": ["GEMINI_INPUT_FILES", {"tooltip": "Optional file(s) to use as context for the model. Accepts inputs from the Gemini Generate Content Input Files node."}], "aspect_ratio": ["COMBO", {"tooltip": "Defaults to matching the output image size to that of your input image, or otherwise generates 1:1 squares.", "default": "auto", "multiselect": false, "options": ["auto", "1:1", "2:3", "3:2", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["prompt", "model", "seed"], "optional": ["images", "files", "aspect_ratio"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["IMAGE", "STRING"], "output_tooltips": [null, null], "name": "GeminiImageNode", "display_name": "Google Gemini Image", "description": "Edit images synchronously via Google API.", "python_module": "comfy_api_nodes.nodes_gemini", "category": "api node/image/Gemini", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "GeminiInputFiles": {"input": {"required": {"file": ["COMBO", {"tooltip": "Input files to include as context for the model. Only accepts text (.txt) and PDF (.pdf) files for now.", "multiselect": false, "options": []}]}, "optional": {"GEMINI_INPUT_FILES": ["GEMINI_INPUT_FILES", {"tooltip": "An optional additional file(s) to batch together with the file loaded from this node. Allows chaining of input files so that a single message can include multiple input files."}]}}, "input_order": {"required": ["file"], "optional": ["GEMINI_INPUT_FILES"]}, "output": ["GEMINI_INPUT_FILES"], "output_is_list": [false], "output_name": ["GEMINI_INPUT_FILES"], "output_tooltips": [null], "name": "GeminiInputFiles", "display_name": "Gemini Input Files", "description": "Loads and prepares input files to include as inputs for Gemini LLM nodes. The files will be read by the Gemini model when generating a response. The contents of the text file count toward the token limit. \ud83d\udec8 TIP: Can be chained together with other Gemini Input File nodes.", "python_module": "comfy_api_nodes.nodes_gemini", "category": "api node/text/Gemini", "output_node": false, "deprecated": false, "experimental": false, "api_node": false}, "ViduTextToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "prompt": ["STRING", {"tooltip": "A textual description for video generation", "multiline": true}]}, "optional": {"duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["duration", "seed", "aspect_ratio", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduTextToVideoNode", "display_name": "Vidu Text To Video Generation", "description": "Generate video from text prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ViduImageToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "image": ["IMAGE", {"tooltip": "An image to be used as the start frame of the generated video"}]}, "optional": {"prompt": ["STRING", {"tooltip": "A textual description for video generation", "default": "", "multiline": true}], "duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image"], "optional": ["prompt", "duration", "seed", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduImageToVideoNode", "display_name": "Vidu Image To Video Generation", "description": "Generate video from image and optional prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ViduReferenceVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "images": ["IMAGE", {"tooltip": "Images to use as references to generate a video with consistent subjects (max 7 images)."}], "prompt": ["STRING", {"tooltip": "A textual description for video generation", "multiline": true}]}, "optional": {"duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "aspect_ratio": ["COMBO", {"tooltip": "The aspect ratio of the output video", "default": "16:9", "multiselect": false, "options": ["16:9", "9:16", "1:1"]}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "images", "prompt"], "optional": ["duration", "seed", "aspect_ratio", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduReferenceVideoNode", "display_name": "Vidu Reference To Video Generation", "description": "Generate video from multiple images and prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "ViduStartEndToVideoNode": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model name", "default": "viduq1", "multiselect": false, "options": ["viduq1"]}], "first_frame": ["IMAGE", {"tooltip": "Start frame"}], "end_frame": ["IMAGE", {"tooltip": "End frame"}]}, "optional": {"prompt": ["STRING", {"tooltip": "A textual description for video generation", "multiline": true}], "duration": ["INT", {"tooltip": "Duration of the output video in seconds", "default": 5, "min": 5, "max": 5, "step": 1, "display": "number"}], "seed": ["INT", {"tooltip": "Seed for video generation (0 for random)", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "resolution": ["COMBO", {"tooltip": "Supported values may vary by model & duration", "default": "1080p", "multiselect": false, "options": ["1080p"]}], "movement_amplitude": ["COMBO", {"tooltip": "The movement amplitude of objects in the frame", "default": "auto", "multiselect": false, "options": ["auto", "small", "medium", "large"]}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "first_frame", "end_frame"], "optional": ["prompt", "duration", "seed", "resolution", "movement_amplitude"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "ViduStartEndToVideoNode", "display_name": "Vidu Start End To Video Generation", "description": "Generate a video from start and end frames and a prompt", "python_module": "comfy_api_nodes.nodes_vidu", "category": "api node/video/Vidu", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanTextToImageApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-t2i-preview", "multiselect": false, "options": ["wan2.5-t2i-preview"]}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "width": ["INT", {"default": 1024, "min": 768, "max": 1440, "step": 32}], "height": ["INT", {"default": 1024, "min": 768, "max": 1440, "step": 32}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "prompt_extend": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance.", "default": true}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["negative_prompt", "width", "height", "seed", "prompt_extend", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "WanTextToImageApi", "display_name": "Wan Text to Image", "description": "Generates image based on text prompt.", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/image/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanImageToImageApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-i2i-preview", "multiselect": false, "options": ["wan2.5-i2i-preview"]}], "image": ["IMAGE", {"tooltip": "Single-image editing or multi-image fusion, maximum 2 images."}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image", "prompt"], "optional": ["negative_prompt", "seed", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "output_tooltips": [null], "name": "WanImageToImageApi", "display_name": "Wan Image to Image", "description": "Generates an image from one or two input images and a text prompt. The output image is currently fixed at 1.6 MP; its aspect ratio matches the input image(s).", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/image/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanTextToVideoApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-t2v-preview", "multiselect": false, "options": ["wan2.5-t2v-preview"]}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "size": ["COMBO", {"default": "480p: 1:1 (624x624)", "multiselect": false, "options": ["480p: 1:1 (624x624)", "480p: 16:9 (832x480)", "480p: 9:16 (480x832)", "720p: 1:1 (960x960)", "720p: 16:9 (1280x720)", "720p: 9:16 (720x1280)", "720p: 4:3 (1088x832)", "720p: 3:4 (832x1088)", "1080p: 1:1 (1440x1440)", "1080p: 16:9 (1920x1080)", "1080p: 9:16 (1080x1920)", "1080p: 4:3 (1632x1248)", "1080p: 3:4 (1248x1632)"]}], "duration": ["INT", {"tooltip": "Available durations: 5 and 10 seconds", "default": 5, "min": 5, "max": 10, "step": 5, "display": "number"}], "audio": ["AUDIO", {"tooltip": "Audio must contain a clear, loud voice, without extraneous noise, background music."}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "generate_audio": ["BOOLEAN", {"tooltip": "If there is no audio input, generate audio automatically.", "default": false}], "prompt_extend": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance.", "default": true}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "prompt"], "optional": ["negative_prompt", "size", "duration", "audio", "seed", "generate_audio", "prompt_extend", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "WanTextToVideoApi", "display_name": "Wan Text to Video", "description": "Generates video based on text prompt.", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/video/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "WanImageToVideoApi": {"input": {"required": {"model": ["COMBO", {"tooltip": "Model to use.", "default": "wan2.5-i2v-preview", "multiselect": false, "options": ["wan2.5-i2v-preview"]}], "image": ["IMAGE", {}], "prompt": ["STRING", {"tooltip": "Prompt used to describe the elements and visual features, supports English/Chinese.", "default": "", "multiline": true}]}, "optional": {"negative_prompt": ["STRING", {"tooltip": "Negative text prompt to guide what to avoid.", "default": "", "multiline": true}], "resolution": ["COMBO", {"default": "480P", "multiselect": false, "options": ["480P", "720P", "1080P"]}], "duration": ["INT", {"tooltip": "Available durations: 5 and 10 seconds", "default": 5, "min": 5, "max": 10, "step": 5, "display": "number"}], "audio": ["AUDIO", {"tooltip": "Audio must contain a clear, loud voice, without extraneous noise, background music."}], "seed": ["INT", {"tooltip": "Seed to use for generation.", "default": 0, "min": 0, "max": 2147483647, "step": 1, "control_after_generate": true, "display": "number"}], "generate_audio": ["BOOLEAN", {"tooltip": "If there is no audio input, generate audio automatically.", "default": false}], "prompt_extend": ["BOOLEAN", {"tooltip": "Whether to enhance the prompt with AI assistance.", "default": true}], "watermark": ["BOOLEAN", {"tooltip": "Whether to add an \"AI generated\" watermark to the result.", "default": true}]}, "hidden": {"auth_token_comfy_org": ["AUTH_TOKEN_COMFY_ORG"], "api_key_comfy_org": ["API_KEY_COMFY_ORG"], "unique_id": ["UNIQUE_ID"]}}, "input_order": {"required": ["model", "image", "prompt"], "optional": ["negative_prompt", "resolution", "duration", "audio", "seed", "generate_audio", "prompt_extend", "watermark"], "hidden": ["auth_token_comfy_org", "api_key_comfy_org", "unique_id"]}, "output": ["VIDEO"], "output_is_list": [false], "output_name": ["VIDEO"], "output_tooltips": [null], "name": "WanImageToVideoApi", "display_name": "Wan Image to Video", "description": "Generates video based on the first frame and text prompt.", "python_module": "comfy_api_nodes.nodes_wan", "category": "api node/video/Wan", "output_node": false, "deprecated": false, "experimental": false, "api_node": true}, "SaveImageWebsocket": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": [], "output_is_list": [], "output_name": [], "name": "SaveImageWebsocket", "display_name": "SaveImageWebsocket", "description": "", "python_module": "custom_nodes.websocket_image_save", "category": "api/image", "output_node": true}, "HyVideoSampler": {"input": {"required": {"model": ["HYVIDEOMODEL"], "hyvid_embeds": ["HYVIDEMBEDS"], "width": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 16}], "height": ["INT", {"default": 512, "min": 64, "max": 4096, "step": 16}], "num_frames": ["INT", {"default": 49, "min": 1, "max": 1024, "step": 4}], "steps": ["INT", {"default": 30, "min": 1}], "embedded_guidance_scale": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 30.0, "step": 0.01}], "flow_shift": ["FLOAT", {"default": 9.0, "min": 0.0, "max": 1000.0, "step": 0.01}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "force_offload": ["BOOLEAN", {"default": true}]}, "optional": {"samples": ["LATENT", {"tooltip": "init Latents to use for video2video process"}], "image_cond_latents": ["LATENT", {"tooltip": "init Latents to use for image2video process"}], "denoise_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "stg_args": ["STGARGS"], "context_options": ["HYVIDCONTEXT"], "feta_args": ["FETAARGS"], "teacache_args": ["TEACACHEARGS"], "scheduler": [["FlowMatchDiscreteScheduler", "SDE-DPMSolverMultistepScheduler", "DPMSolverMultistepScheduler", "SASolverScheduler", "UniPCMultistepScheduler"], {"default": "FlowMatchDiscreteScheduler"}], "riflex_freq_index": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1, "tooltip": "Frequency index for RIFLEX, disabled when 0, default 4. Allows for new frames to be generated after 129 without looping"}], "i2v_mode": [["stability", "dynamic"], {"default": "dynamic", "tooltip": "I2V mode for image2video process"}], "loop_args": ["LOOPARGS"], "fresca_args": ["FRESCA_ARGS"], "slg_args": ["SLGARGS"], "mask": ["MASK"]}}, "input_order": {"required": ["model", "hyvid_embeds", "width", "height", "num_frames", "steps", "embedded_guidance_scale", "flow_shift", "seed", "force_offload"], "optional": ["samples", "image_cond_latents", "denoise_strength", "stg_args", "context_options", "feta_args", "teacache_args", "scheduler", "riflex_freq_index", "i2v_mode", "loop_args", "fresca_args", "slg_args", "mask"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "HyVideoSampler", "display_name": "HunyuanVideo Sampler", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoDecode": {"input": {"required": {"vae": ["VAE"], "samples": ["LATENT"], "enable_vae_tiling": ["BOOLEAN", {"default": true, "tooltip": "Drastically reduces memory use but may introduce seams"}], "temporal_tiling_sample_size": ["INT", {"default": 64, "min": 4, "max": 256, "tooltip": "Smaller values use less VRAM, model default is 64, any other value will cause stutter"}], "spatial_tile_sample_min_size": ["INT", {"default": 256, "min": 32, "max": 2048, "step": 32, "tooltip": "Spatial tile minimum size in pixels, smaller values use less VRAM, may introduce more seams"}], "auto_tile_size": ["BOOLEAN", {"default": true, "tooltip": "Automatically set tile size based on defaults, above settings are ignored"}]}, "optional": {"skip_latents": ["INT", {"default": 0, "min": 0, "max": 1000, "step": 1, "tooltip": "Number of latents to skip from the start, can help with flashing"}], "balance_brightness": ["BOOLEAN", {"default": false, "tooltip": "Attempt to balance brightness of the output frames"}]}}, "input_order": {"required": ["vae", "samples", "enable_vae_tiling", "temporal_tiling_sample_size", "spatial_tile_sample_min_size", "auto_tile_size"], "optional": ["skip_latents", "balance_brightness"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["images"], "name": "HyVideoDecode", "display_name": "HunyuanVideo Decode", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoTextEncode": {"input": {"required": {"text_encoders": ["HYVIDTEXTENCODER"], "prompt": ["STRING", {"default": "", "multiline": true}]}, "optional": {"force_offload": ["BOOLEAN", {"default": true}], "prompt_template": [["video", "image", "custom", "disabled"], {"default": "video", "tooltip": "Use the default prompt templates for the llm text encoder"}], "custom_prompt_template": ["PROMPT_TEMPLATE", {"default": {"template": "<|start_header_id|>system<|end_header_id|>\n\nDescribe the video by detailing the following aspects: 1. The main content and theme of the video.2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.4. background environment, light, style and atmosphere.5. camera angles, movements, and transitions used in the video:<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|>", "crop_start": 95}, "multiline": true}], "clip_l": ["CLIP", {"tooltip": "Use comfy clip model instead, in this case the text encoder loader's clip_l should be disabled"}], "hyvid_cfg": ["HYVID_CFG"], "model_to_offload": ["HYVIDEOMODEL", {"tooltip": "If connected, moves the video model to the offload device"}]}}, "input_order": {"required": ["text_encoders", "prompt"], "optional": ["force_offload", "prompt_template", "custom_prompt_template", "clip_l", "hyvid_cfg", "model_to_offload"]}, "output": ["HYVIDEMBEDS"], "output_is_list": [false], "output_name": ["hyvid_embeds"], "name": "HyVideoTextEncode", "display_name": "HunyuanVideo TextEncode", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoTextImageEncode": {"input": {"required": {"text_encoders": ["HYVIDTEXTENCODER"], "prompt": ["STRING", {"default": "", "multiline": true}], "image_token_selection_expr": ["STRING", {"default": "::4", "multiline": false}]}, "optional": {"force_offload": ["BOOLEAN", {"default": true}], "prompt_template": [["video", "image", "custom", "disabled"], {"default": "video", "tooltip": "Use the default prompt templates for the llm text encoder"}], "custom_prompt_template": ["PROMPT_TEMPLATE", {"default": {"template": "<|start_header_id|>system<|end_header_id|>\n\nDescribe the video by detailing the following aspects: 1. The main content and theme of the video.2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.4. background environment, light, style and atmosphere.5. camera angles, movements, and transitions used in the video:<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|>", "crop_start": 95}, "multiline": true}], "clip_l": ["CLIP", {"tooltip": "Use comfy clip model instead, in this case the text encoder loader's clip_l should be disabled"}], "image1": ["IMAGE", {"default": null}], "image2": ["IMAGE", {"default": null}], "clip_text_override": ["STRING", {"default": "", "multiline": true}], "hyvid_cfg": ["HYVID_CFG"], "model_to_offload": ["HYVIDEOMODEL", {"tooltip": "Model to move to offload_device before encoding"}]}}, "input_order": {"required": ["text_encoders", "prompt", "image_token_selection_expr"], "optional": ["force_offload", "prompt_template", "custom_prompt_template", "clip_l", "image1", "image2", "clip_text_override", "hyvid_cfg", "model_to_offload"]}, "output": ["HYVIDEMBEDS"], "output_is_list": [false], "output_name": ["hyvid_embeds"], "name": "HyVideoTextImageEncode", "display_name": "HunyuanVideo TextImageEncode (IP2V)", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoModelLoader": {"input": {"required": {"model": [[], {"tooltip": "These models are loaded from the 'ComfyUI/models/diffusion_models' -folder"}], "base_precision": [["fp32", "bf16"], {"default": "bf16"}], "quantization": [["disabled", "fp8_e4m3fn", "fp8_e4m3fn_fast", "fp8_e5m2", "fp8_scaled"], {"default": "disabled", "tooltip": "optional quantization method"}], "load_device": [["main_device", "offload_device"], {"default": "main_device"}]}, "optional": {"attention_mode": [["sdpa", "flash_attn_varlen", "sageattn", "sageattn_varlen", "comfy"], {"default": "flash_attn"}], "compile_args": ["COMPILEARGS"], "block_swap_args": ["BLOCKSWAPARGS"], "lora": ["HYVIDLORA", {"default": null}], "auto_cpu_offload": ["BOOLEAN", {"default": false, "tooltip": "Enable auto offloading for reduced VRAM usage, implementation from DiffSynth-Studio, slightly different from block swapping and uses even less VRAM, but can be slower as you can't define how much VRAM to use"}], "upcast_rope": ["BOOLEAN", {"default": true, "tooltip": "Upcast RoPE to fp32 for better accuracy, this is the default behaviour, disabling can improve speed and reduce memory use slightly"}]}}, "input_order": {"required": ["model", "base_precision", "quantization", "load_device"], "optional": ["attention_mode", "compile_args", "block_swap_args", "lora", "auto_cpu_offload", "upcast_rope"]}, "output": ["HYVIDEOMODEL"], "output_is_list": [false], "output_name": ["model"], "name": "HyVideoModelLoader", "display_name": "HunyuanVideo Model Loader", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoVAELoader": {"input": {"required": {"model_name": [["vae-ft-mse-840000-ema-pruned.safetensors"], {"tooltip": "These models are loaded from 'ComfyUI/models/vae'"}]}, "optional": {"precision": [["fp16", "fp32", "bf16"], {"default": "bf16"}], "compile_args": ["COMPILEARGS"]}}, "input_order": {"required": ["model_name"], "optional": ["precision", "compile_args"]}, "output": ["VAE"], "output_is_list": [false], "output_name": ["vae"], "name": "HyVideoVAELoader", "display_name": "HunyuanVideo VAE Loader", "description": "Loads Hunyuan VAE model from 'ComfyUI/models/vae'", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "DownloadAndLoadHyVideoTextEncoder": {"input": {"required": {"llm_model": [["Kijai/llava-llama-3-8b-text-encoder-tokenizer", "xtuner/llava-llama-3-8b-v1_1-transformers"]], "clip_model": [["disabled", "openai/clip-vit-large-patch14"]], "precision": [["fp16", "fp32", "bf16"], {"default": "bf16"}]}, "optional": {"apply_final_norm": ["BOOLEAN", {"default": false}], "hidden_state_skip_layer": ["INT", {"default": 2}], "quantization": [["disabled", "bnb_nf4", "fp8_e4m3fn"], {"default": "disabled"}], "load_device": [["main_device", "offload_device"], {"default": "offload_device"}]}}, "input_order": {"required": ["llm_model", "clip_model", "precision"], "optional": ["apply_final_norm", "hidden_state_skip_layer", "quantization", "load_device"]}, "output": ["HYVIDTEXTENCODER"], "output_is_list": [false], "output_name": ["hyvid_text_encoder"], "name": "DownloadAndLoadHyVideoTextEncoder", "display_name": "(Down)Load HunyuanVideo TextEncoder", "description": "Loads Hunyuan text_encoder model from 'ComfyUI/models/LLM'", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoEncode": {"input": {"required": {"vae": ["VAE"], "image": ["IMAGE"], "enable_vae_tiling": ["BOOLEAN", {"default": true, "tooltip": "Drastically reduces memory use but may introduce seams"}], "temporal_tiling_sample_size": ["INT", {"default": 64, "min": 4, "max": 256, "tooltip": "Smaller values use less VRAM, model default is 64, any other value will cause stutter"}], "spatial_tile_sample_min_size": ["INT", {"default": 256, "min": 32, "max": 2048, "step": 32, "tooltip": "Spatial tile minimum size in pixels, smaller values use less VRAM, may introduce more seams"}], "auto_tile_size": ["BOOLEAN", {"default": true, "tooltip": "Automatically set tile size based on defaults, above settings are ignored"}]}, "optional": {"noise_aug_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Strength of noise augmentation, helpful for leapfusion I2V where some noise can add motion and give sharper results"}], "latent_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Additional latent multiplier, helpful for leapfusion I2V where lower values allow for more motion"}], "latent_dist": [["sample", "mode"], {"default": "sample", "tooltip": "Sampling mode for the VAE, sample uses the latent distribution, mode uses the mode of the latent distribution"}]}}, "input_order": {"required": ["vae", "image", "enable_vae_tiling", "temporal_tiling_sample_size", "spatial_tile_sample_min_size", "auto_tile_size"], "optional": ["noise_aug_strength", "latent_strength", "latent_dist"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "HyVideoEncode", "display_name": "HunyuanVideo Encode", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoBlockSwap": {"input": {"required": {"double_blocks_to_swap": ["INT", {"default": 20, "min": 0, "max": 20, "step": 1, "tooltip": "Number of double blocks to swap"}], "single_blocks_to_swap": ["INT", {"default": 0, "min": 0, "max": 40, "step": 1, "tooltip": "Number of single blocks to swap"}], "offload_txt_in": ["BOOLEAN", {"default": false, "tooltip": "Offload txt_in layer"}], "offload_img_in": ["BOOLEAN", {"default": false, "tooltip": "Offload img_in layer"}]}}, "input_order": {"required": ["double_blocks_to_swap", "single_blocks_to_swap", "offload_txt_in", "offload_img_in"]}, "output": ["BLOCKSWAPARGS"], "output_is_list": [false], "output_name": ["block_swap_args"], "name": "HyVideoBlockSwap", "display_name": "HunyuanVideo BlockSwap", "description": "Settings for block swapping, reduces VRAM use by swapping blocks to CPU memory", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoTorchCompileSettings": {"input": {"required": {"backend": [["inductor", "cudagraphs"], {"default": "inductor"}], "fullgraph": ["BOOLEAN", {"default": false, "tooltip": "Enable full graph mode"}], "mode": [["default", "max-autotune", "max-autotune-no-cudagraphs", "reduce-overhead"], {"default": "default"}], "dynamic": ["BOOLEAN", {"default": false, "tooltip": "Enable dynamic mode"}], "dynamo_cache_size_limit": ["INT", {"default": 64, "min": 0, "max": 1024, "step": 1, "tooltip": "torch._dynamo.config.cache_size_limit"}], "compile_single_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile single blocks"}], "compile_double_blocks": ["BOOLEAN", {"default": true, "tooltip": "Compile double blocks"}], "compile_txt_in": ["BOOLEAN", {"default": false, "tooltip": "Compile txt_in layers"}], "compile_vector_in": ["BOOLEAN", {"default": false, "tooltip": "Compile vector_in layers"}], "compile_final_layer": ["BOOLEAN", {"default": false, "tooltip": "Compile final layer"}]}}, "input_order": {"required": ["backend", "fullgraph", "mode", "dynamic", "dynamo_cache_size_limit", "compile_single_blocks", "compile_double_blocks", "compile_txt_in", "compile_vector_in", "compile_final_layer"]}, "output": ["COMPILEARGS"], "output_is_list": [false], "output_name": ["torch_compile_args"], "name": "HyVideoTorchCompileSettings", "display_name": "HunyuanVideo Torch Compile Settings", "description": "torch.compile settings, when connected to the model loader, torch.compile of the selected layers is attempted. Requires Triton and torch 2.5.0 is recommended", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoSTG": {"input": {"required": {"stg_mode": [["STG-A", "STG-R"]], "stg_block_idx": ["INT", {"default": 0, "min": -1, "max": 39, "step": 1, "tooltip": "Block index to apply STG"}], "stg_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01, "tooltip": "Recommended values are \u22642.0"}], "stg_start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Start percentage of the steps to apply STG"}], "stg_end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "End percentage of the steps to apply STG"}]}}, "input_order": {"required": ["stg_mode", "stg_block_idx", "stg_scale", "stg_start_percent", "stg_end_percent"]}, "output": ["STGARGS"], "output_is_list": [false], "output_name": ["stg_args"], "name": "HyVideoSTG", "display_name": "HunyuanVideo STG", "description": "Spatio Temporal Guidance, https://github.com/junhahyung/STGuidance", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoCFG": {"input": {"required": {"negative_prompt": ["STRING", {"default": "Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion", "multiline": true}], "cfg": ["FLOAT", {"default": 2.0, "min": 0.0, "max": 100.0, "step": 0.01, "tooltip": "guidance scale"}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Start percentage of the steps to apply CFG, rest of the steps use guidance_embeds"}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "End percentage of the steps to apply CFG, rest of the steps use guidance_embeds"}], "batched_cfg": ["BOOLEAN", {"default": false, "tooltip": "Calculate cond and uncond as a batch, increases memory usage but can be faster"}], "use_cfg_zero_star": ["BOOLEAN", {"default": false, "tooltip": "Use CFG zero star"}]}}, "input_order": {"required": ["negative_prompt", "cfg", "start_percent", "end_percent", "batched_cfg", "use_cfg_zero_star"]}, "output": ["HYVID_CFG"], "output_is_list": [false], "output_name": ["hyvid_cfg"], "name": "HyVideoCFG", "display_name": "HunyuanVideo CFG", "description": "To use CFG with HunyuanVideo", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoCustomPromptTemplate": {"input": {"required": {"custom_prompt_template": ["STRING", {"default": "<|start_header_id|>system<|end_header_id|>\n\nDescribe the video by detailing the following aspects: 1. The main content and theme of the video.2. The color, shape, size, texture, quantity, text, and spatial relationships of the objects.3. Actions, events, behaviors temporal relationships, physical movement changes of the objects.4. background environment, light, style and atmosphere.5. camera angles, movements, and transitions used in the video:<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|>", "multiline": true}], "crop_start": ["INT", {"default": 95, "tooltip": "To cropt the system prompt"}]}}, "input_order": {"required": ["custom_prompt_template", "crop_start"]}, "output": ["PROMPT_TEMPLATE"], "output_is_list": [false], "output_name": ["hyvid_prompt_template"], "name": "HyVideoCustomPromptTemplate", "display_name": "HunyuanVideo Custom Prompt Template", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoLatentPreview": {"input": {"required": {"samples": ["LATENT"], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "min_val": ["FLOAT", {"default": -0.15, "min": -1.0, "max": 0.0, "step": 0.001}], "max_val": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}], "r_bias": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001}], "g_bias": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001}], "b_bias": ["FLOAT", {"default": 0.0, "min": -1.0, "max": 1.0, "step": 0.001}]}}, "input_order": {"required": ["samples", "seed", "min_val", "max_val", "r_bias", "g_bias", "b_bias"]}, "output": ["IMAGE", "STRING"], "output_is_list": [false, false], "output_name": ["images", "latent_rgb_factors"], "name": "HyVideoLatentPreview", "display_name": "HunyuanVideo Latent Preview", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoLoraSelect": {"input": {"required": {"lora": [[], {"tooltip": "LORA models are expected to be in ComfyUI/models/loras with .safetensors extension"}], "strength": ["FLOAT", {"default": 1.0, "min": -10.0, "max": 10.0, "step": 0.0001, "tooltip": "LORA strength, set to 0.0 to unmerge the LORA"}]}, "optional": {"prev_lora": ["HYVIDLORA", {"default": null, "tooltip": "For loading multiple LoRAs"}], "blocks": ["SELECTEDBLOCKS"]}}, "input_order": {"required": ["lora", "strength"], "optional": ["prev_lora", "blocks"]}, "output": ["HYVIDLORA"], "output_is_list": [false], "output_name": ["lora"], "name": "HyVideoLoraSelect", "display_name": "HunyuanVideo Lora Select", "description": "Select a LoRA model from ComfyUI/models/loras", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoLoraBlockEdit": {"input": {"required": {"double_blocks.0.": ["BOOLEAN", {"default": true}], "double_blocks.1.": ["BOOLEAN", {"default": true}], "double_blocks.2.": ["BOOLEAN", {"default": true}], "double_blocks.3.": ["BOOLEAN", {"default": true}], "double_blocks.4.": ["BOOLEAN", {"default": true}], "double_blocks.5.": ["BOOLEAN", {"default": true}], "double_blocks.6.": ["BOOLEAN", {"default": true}], "double_blocks.7.": ["BOOLEAN", {"default": true}], "double_blocks.8.": ["BOOLEAN", {"default": true}], "double_blocks.9.": ["BOOLEAN", {"default": true}], "double_blocks.10.": ["BOOLEAN", {"default": true}], "double_blocks.11.": ["BOOLEAN", {"default": true}], "double_blocks.12.": ["BOOLEAN", {"default": true}], "double_blocks.13.": ["BOOLEAN", {"default": true}], "double_blocks.14.": ["BOOLEAN", {"default": true}], "double_blocks.15.": ["BOOLEAN", {"default": true}], "double_blocks.16.": ["BOOLEAN", {"default": true}], "double_blocks.17.": ["BOOLEAN", {"default": true}], "double_blocks.18.": ["BOOLEAN", {"default": true}], "double_blocks.19.": ["BOOLEAN", {"default": true}], "single_blocks.0.": ["BOOLEAN", {"default": true}], "single_blocks.1.": ["BOOLEAN", {"default": true}], "single_blocks.2.": ["BOOLEAN", {"default": true}], "single_blocks.3.": ["BOOLEAN", {"default": true}], "single_blocks.4.": ["BOOLEAN", {"default": true}], "single_blocks.5.": ["BOOLEAN", {"default": true}], "single_blocks.6.": ["BOOLEAN", {"default": true}], "single_blocks.7.": ["BOOLEAN", {"default": true}], "single_blocks.8.": ["BOOLEAN", {"default": true}], "single_blocks.9.": ["BOOLEAN", {"default": true}], "single_blocks.10.": ["BOOLEAN", {"default": true}], "single_blocks.11.": ["BOOLEAN", {"default": true}], "single_blocks.12.": ["BOOLEAN", {"default": true}], "single_blocks.13.": ["BOOLEAN", {"default": true}], "single_blocks.14.": ["BOOLEAN", {"default": true}], "single_blocks.15.": ["BOOLEAN", {"default": true}], "single_blocks.16.": ["BOOLEAN", {"default": true}], "single_blocks.17.": ["BOOLEAN", {"default": true}], "single_blocks.18.": ["BOOLEAN", {"default": true}], "single_blocks.19.": ["BOOLEAN", {"default": true}], "single_blocks.20.": ["BOOLEAN", {"default": true}], "single_blocks.21.": ["BOOLEAN", {"default": true}], "single_blocks.22.": ["BOOLEAN", {"default": true}], "single_blocks.23.": ["BOOLEAN", {"default": true}], "single_blocks.24.": ["BOOLEAN", {"default": true}], "single_blocks.25.": ["BOOLEAN", {"default": true}], "single_blocks.26.": ["BOOLEAN", {"default": true}], "single_blocks.27.": ["BOOLEAN", {"default": true}], "single_blocks.28.": ["BOOLEAN", {"default": true}], "single_blocks.29.": ["BOOLEAN", {"default": true}], "single_blocks.30.": ["BOOLEAN", {"default": true}], "single_blocks.31.": ["BOOLEAN", {"default": true}], "single_blocks.32.": ["BOOLEAN", {"default": true}], "single_blocks.33.": ["BOOLEAN", {"default": true}], "single_blocks.34.": ["BOOLEAN", {"default": true}], "single_blocks.35.": ["BOOLEAN", {"default": true}], "single_blocks.36.": ["BOOLEAN", {"default": true}], "single_blocks.37.": ["BOOLEAN", {"default": true}], "single_blocks.38.": ["BOOLEAN", {"default": true}], "single_blocks.39.": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["double_blocks.0.", "double_blocks.1.", "double_blocks.2.", "double_blocks.3.", "double_blocks.4.", "double_blocks.5.", "double_blocks.6.", "double_blocks.7.", "double_blocks.8.", "double_blocks.9.", "double_blocks.10.", "double_blocks.11.", "double_blocks.12.", "double_blocks.13.", "double_blocks.14.", "double_blocks.15.", "double_blocks.16.", "double_blocks.17.", "double_blocks.18.", "double_blocks.19.", "single_blocks.0.", "single_blocks.1.", "single_blocks.2.", "single_blocks.3.", "single_blocks.4.", "single_blocks.5.", "single_blocks.6.", "single_blocks.7.", "single_blocks.8.", "single_blocks.9.", "single_blocks.10.", "single_blocks.11.", "single_blocks.12.", "single_blocks.13.", "single_blocks.14.", "single_blocks.15.", "single_blocks.16.", "single_blocks.17.", "single_blocks.18.", "single_blocks.19.", "single_blocks.20.", "single_blocks.21.", "single_blocks.22.", "single_blocks.23.", "single_blocks.24.", "single_blocks.25.", "single_blocks.26.", "single_blocks.27.", "single_blocks.28.", "single_blocks.29.", "single_blocks.30.", "single_blocks.31.", "single_blocks.32.", "single_blocks.33.", "single_blocks.34.", "single_blocks.35.", "single_blocks.36.", "single_blocks.37.", "single_blocks.38.", "single_blocks.39."]}, "output": ["SELECTEDBLOCKS"], "output_is_list": [false], "output_name": ["blocks"], "name": "HyVideoLoraBlockEdit", "display_name": "HunyuanVideo Lora Block Edit", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false, "output_tooltips": ["The modified diffusion model."]}, "HyVideoTextEmbedsSave": {"input": {"required": {"hyvid_embeds": ["HYVIDEMBEDS"], "filename_prefix": ["STRING", {"default": "hyvid_embeds/hyvid_embed"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["hyvid_embeds", "filename_prefix"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["output_path"], "name": "HyVideoTextEmbedsSave", "display_name": "HunyuanVideo TextEmbeds Save", "description": "Save the text embeds", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoTextEmbedsLoad": {"input": {"required": {"embeds": [[], {"tooltip": "The saved embeds to load from output/hyvid_embeds."}]}}, "input_order": {"required": ["embeds"]}, "output": ["HYVIDEMBEDS"], "output_is_list": [false], "output_name": ["hyvid_embeds"], "name": "HyVideoTextEmbedsLoad", "display_name": "HunyuanVideo TextEmbeds Load", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoContextOptions": {"input": {"required": {"context_schedule": [["uniform_standard", "uniform_looped", "static_standard"]], "context_frames": ["INT", {"default": 65, "min": 2, "max": 1000, "step": 1, "tooltip": "Number of pixel frames in the context, NOTE: the latent space has 4 frames in 1"}], "context_stride": ["INT", {"default": 4, "min": 4, "max": 100, "step": 1, "tooltip": "Context stride as pixel frames, NOTE: the latent space has 4 frames in 1"}], "context_overlap": ["INT", {"default": 4, "min": 4, "max": 100, "step": 1, "tooltip": "Context overlap as pixel frames, NOTE: the latent space has 4 frames in 1"}], "freenoise": ["BOOLEAN", {"default": true, "tooltip": "Shuffle the noise"}]}}, "input_order": {"required": ["context_schedule", "context_frames", "context_stride", "context_overlap", "freenoise"]}, "output": ["HYVIDCONTEXT"], "output_is_list": [false], "output_name": ["context_options"], "name": "HyVideoContextOptions", "display_name": "HunyuanVideo Context Options", "description": "Context options for HunyuanVideo, allows splitting the video into context windows and attemps blending them for longer generations than the model and memory otherwise would allow.", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoEnhanceAVideo": {"input": {"required": {"weight": ["FLOAT", {"default": 2.0, "min": 0, "max": 100, "step": 0.01, "tooltip": "The feta Weight of the Enhance-A-Video"}], "single_blocks": ["BOOLEAN", {"default": true, "tooltip": "Enable Enhance-A-Video for single blocks"}], "double_blocks": ["BOOLEAN", {"default": true, "tooltip": "Enable Enhance-A-Video for double blocks"}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Start percentage of the steps to apply Enhance-A-Video"}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "End percentage of the steps to apply Enhance-A-Video"}]}}, "input_order": {"required": ["weight", "single_blocks", "double_blocks", "start_percent", "end_percent"]}, "output": ["FETAARGS"], "output_is_list": [false], "output_name": ["feta_args"], "name": "HyVideoEnhanceAVideo", "display_name": "HunyuanVideo Enhance A Video", "description": "https://github.com/NUS-HPC-AI-Lab/Enhance-A-Video", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoTeaCache": {"input": {"required": {"rel_l1_thresh": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Higher values will make TeaCache more aggressive, faster, but may cause artifacts"}], "cache_device": [["main_device", "offload_device"], {"default": "offload_device", "tooltip": "Device to cache to"}], "start_step": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1, "tooltip": "Start step to apply TeaCache"}], "end_step": ["INT", {"default": -1, "min": -1, "max": 100, "step": 1, "tooltip": "End step to apply TeaCache"}]}}, "input_order": {"required": ["rel_l1_thresh", "cache_device", "start_step", "end_step"]}, "output": ["TEACACHEARGS"], "output_is_list": [false], "output_name": ["teacache_args"], "name": "HyVideoTeaCache", "display_name": "HunyuanVideo TeaCache", "description": "TeaCache settings for HunyuanVideo to speed up inference", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoGetClosestBucketSize": {"input": {"required": {"image": ["IMAGE"], "base_size": [["360", "540", "720"], {"default": "540", "tooltip": "Resizes the input image to closest original training bucket size"}]}}, "input_order": {"required": ["image", "base_size"]}, "output": ["INT", "INT"], "output_is_list": [false, false], "output_name": ["width", "height"], "name": "HyVideoGetClosestBucketSize", "display_name": "HunyuanVideo Get Closest Bucket Size", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoI2VEncode": {"input": {"required": {"text_encoders": ["HYVIDTEXTENCODER"], "prompt": ["STRING", {"default": "", "multiline": true}]}, "optional": {"force_offload": ["BOOLEAN", {"default": true}], "prompt_template": [["I2V_video", "I2V_image", "disabled"], {"default": "I2V_video", "tooltip": "Use the default prompt templates for the llm text encoder"}], "clip_l": ["CLIP", {"tooltip": "Use comfy clip model instead, in this case the text encoder loader's clip_l should be disabled"}], "image": ["IMAGE", {"default": null}], "hyvid_cfg": ["HYVID_CFG"], "image_embed_interleave": ["INT", {"default": 2}], "model_to_offload": ["HYVIDEOMODEL", {"tooltip": "Model to move to offload_device before encoding"}]}}, "input_order": {"required": ["text_encoders", "prompt"], "optional": ["force_offload", "prompt_template", "clip_l", "image", "hyvid_cfg", "image_embed_interleave", "model_to_offload"]}, "output": ["HYVIDEMBEDS"], "output_is_list": [false], "output_name": ["hyvid_embeds"], "name": "HyVideoI2VEncode", "display_name": "HyVideo I2V Encode", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoEncodeKeyframes": {"input": {"required": {"vae": ["VAE"], "start_image": ["IMAGE"], "end_image": ["IMAGE", {"default": null, "tooltip": "End frame for dashtoon keyframe LoRA"}], "num_frames": ["INT", {"default": 49, "min": 1, "max": 1024, "step": 4}], "enable_vae_tiling": ["BOOLEAN", {"default": true, "tooltip": "Drastically reduces memory use but may introduce seams"}], "temporal_tiling_sample_size": ["INT", {"default": 64, "min": 4, "max": 256, "tooltip": "Smaller values use less VRAM, model default is 64, any other value will cause stutter"}], "spatial_tile_sample_min_size": ["INT", {"default": 256, "min": 32, "max": 2048, "step": 32, "tooltip": "Spatial tile minimum size in pixels, smaller values use less VRAM, may introduce more seams"}], "auto_tile_size": ["BOOLEAN", {"default": true, "tooltip": "Automatically set tile size based on defaults, above settings are ignored"}]}, "optional": {"noise_aug_strength": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Strength of noise augmentation, helpful for leapfusion I2V where some noise can add motion and give sharper results"}], "latent_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001, "tooltip": "Additional latent multiplier, helpful for leapfusion I2V where lower values allow for more motion"}], "latent_dist": [["sample", "mode"], {"default": "sample", "tooltip": "Sampling mode for the VAE, sample uses the latent distribution, mode uses the mode of the latent distribution"}]}}, "input_order": {"required": ["vae", "start_image", "end_image", "num_frames", "enable_vae_tiling", "temporal_tiling_sample_size", "spatial_tile_sample_min_size", "auto_tile_size"], "optional": ["noise_aug_strength", "latent_strength", "latent_dist"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "HyVideoEncodeKeyframes", "display_name": "HyVideo Encode Keyframes", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoTextEmbedBridge": {"input": {"required": {"positive": ["CONDITIONING"], "cfg": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 100.0, "step": 0.01, "tooltip": "guidance scale"}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Start percentage of the steps to apply CFG, rest of the steps use guidance_embeds"}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "End percentage of the steps to apply CFG, rest of the steps use guidance_embeds"}], "batched_cfg": ["BOOLEAN", {"default": false, "tooltip": "Calculate cond and uncond as a batch, increases memory usage but can be faster"}], "use_cfg_zero_star": ["BOOLEAN", {"default": true, "tooltip": "Use CFG zero star"}]}, "optional": {"negative": ["CONDITIONING"]}}, "input_order": {"required": ["positive", "cfg", "start_percent", "end_percent", "batched_cfg", "use_cfg_zero_star"], "optional": ["negative"]}, "output": ["HYVIDEMBEDS"], "output_is_list": [false], "output_name": ["hyvid_embeds"], "name": "HyVideoTextEmbedBridge", "display_name": "HyVideo TextEmbed Bridge", "description": "Acts as a bridge between the native ComfyUI conditioning and the HunyuanVideoWrapper embeds", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoLoopArgs": {"input": {"required": {"shift_skip": ["INT", {"default": 6, "min": 0, "tooltip": "Skip step of latent shift"}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Start percent of the looping effect"}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "End percent of the looping effect"}]}}, "input_order": {"required": ["shift_skip", "start_percent", "end_percent"]}, "output": ["LOOPARGS"], "output_is_list": [false], "output_name": ["loop_args"], "name": "HyVideoLoopArgs", "display_name": "HyVideo Loop Args", "description": "Looping through latent shift as shown in https://github.com/YisuiTT/Mobius/", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HunyuanVideoFresca": {"input": {"required": {"fresca_scale_low": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "fresca_scale_high": ["FLOAT", {"default": 1.25, "min": 0.0, "max": 10.0, "step": 0.01}], "fresca_freq_cutoff": ["INT", {"default": 20, "min": 0, "max": 10000, "step": 1}]}}, "input_order": {"required": ["fresca_scale_low", "fresca_scale_high", "fresca_freq_cutoff"]}, "output": ["FRESCA_ARGS"], "output_is_list": [false], "output_name": ["fresca_args"], "name": "HunyuanVideoFresca", "display_name": "HunyuanVideo Fresca", "description": "https://github.com/WikiChao/FreSca", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HunyuanVideoSLG": {"input": {"required": {"double_blocks": ["STRING", {"default": "", "tooltip": "Blocks to skip uncond on, separated by comma, index starts from 0"}], "single_blocks": ["STRING", {"default": "20", "tooltip": "Blocks to skip uncond on, separated by comma, index starts from 0"}], "start_percent": ["FLOAT", {"default": 0.4, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Start percent of SLG signal"}], "end_percent": ["FLOAT", {"default": 0.8, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "End percent of SLG signal"}]}}, "input_order": {"required": ["double_blocks", "single_blocks", "start_percent", "end_percent"]}, "output": ["SLGARGS"], "output_is_list": [false], "output_name": ["slg_args"], "name": "HunyuanVideoSLG", "display_name": "HunyuanVideo SLG", "description": "Skips uncond on the selected blocks", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoInverseSampler": {"input": {"required": {"model": ["HYVIDEOMODEL"], "hyvid_embeds": ["HYVIDEMBEDS"], "samples": ["LATENT", {"tooltip": "init Latents to use for video2video process"}], "steps": ["INT", {"default": 30, "min": 1}], "embedded_guidance_scale": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 30.0, "step": 0.01}], "flow_shift": ["FLOAT", {"default": 1.0, "min": 1.0, "max": 30.0, "step": 0.01}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "force_offload": ["BOOLEAN", {"default": true}], "gamma": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01}], "start_step": ["INT", {"default": 0, "min": 0}], "end_step": ["INT", {"default": 18, "min": 0}], "gamma_trend": [["constant", "linear_increase", "linear_decrease"], {"default": "constant"}]}, "optional": {"interpolation_curve": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "forceInput": true, "tooltip": "The strength of the inversed latents along time, in latent space"}]}}, "input_order": {"required": ["model", "hyvid_embeds", "samples", "steps", "embedded_guidance_scale", "flow_shift", "seed", "force_offload", "gamma", "start_step", "end_step", "gamma_trend"], "optional": ["interpolation_curve"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "HyVideoInverseSampler", "display_name": "HunyuanVideo Inverse Sampler", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoReSampler": {"input": {"required": {"model": ["HYVIDEOMODEL"], "hyvid_embeds": ["HYVIDEMBEDS"], "samples": ["LATENT", {"tooltip": "init Latents to use for video2video process"}], "inversed_latents": ["LATENT", {"tooltip": "inversed latents from HyVideoInverseSampler"}], "steps": ["INT", {"default": 30, "min": 1}], "embedded_guidance_scale": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 30.0, "step": 0.01}], "flow_shift": ["FLOAT", {"default": 1.0, "min": 1.0, "max": 30.0, "step": 0.01}], "force_offload": ["BOOLEAN", {"default": true}], "start_step": ["INT", {"default": 0, "min": 0, "tooltip": "The step to start the effect of the inversed latents"}], "end_step": ["INT", {"default": 18, "min": 0, "tooltip": "The step to end the effect of the inversed latents"}], "eta_base": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "The base value of the eta, overall strength of the effect from the inversed latents"}], "eta_trend": [["constant", "linear_increase", "linear_decrease"], {"default": "constant", "tooltip": "The trend of the eta value over steps"}]}, "optional": {"interpolation_curve": ["FLOAT", {"forceInput": true, "tooltip": "The strength of the inversed latents along time, in latent space"}], "feta_args": ["FETAARGS"]}}, "input_order": {"required": ["model", "hyvid_embeds", "samples", "inversed_latents", "steps", "embedded_guidance_scale", "flow_shift", "force_offload", "start_step", "end_step", "eta_base", "eta_trend"], "optional": ["interpolation_curve", "feta_args"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "HyVideoReSampler", "display_name": "HunyuanVideo ReSampler", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoEmptyTextEmbeds": {"input": {"required": {}}, "input_order": {"required": []}, "output": ["HYVIDEMBEDS"], "output_is_list": [false], "output_name": ["hyvid_embeds"], "name": "HyVideoEmptyTextEmbeds", "display_name": "HunyuanVideo Empty Text Embeds", "description": "Empty Text Embeds for HunyuanVideoWrapper, to avoid having to encode prompts for inverse sampling", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false}, "HyVideoPromptMixSampler": {"input": {"required": {"model": ["HYVIDEOMODEL"], "hyvid_embeds": ["HYVIDEMBEDS"], "hyvid_embeds_2": ["HYVIDEMBEDS"], "width": ["INT", {"default": 512, "min": 1}], "height": ["INT", {"default": 512, "min": 1}], "num_frames": ["INT", {"default": 17, "min": 1}], "steps": ["INT", {"default": 30, "min": 1}], "embedded_guidance_scale": ["FLOAT", {"default": 6.0, "min": 0.0, "max": 30.0, "step": 0.01}], "flow_shift": ["FLOAT", {"default": 9.0, "min": 1.0, "max": 30.0, "step": 0.01}], "force_offload": ["BOOLEAN", {"default": true}], "seed": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615}], "alpha": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.01, "tooltip": "Adjusts the blending sharpness"}]}, "optional": {"interpolation_curve": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.01, "forceInput": true, "tooltip": "The strength of the inversed latents along time, in latent space"}], "feta_args": ["FETAARGS"]}}, "input_order": {"required": ["model", "hyvid_embeds", "hyvid_embeds_2", "width", "height", "num_frames", "steps", "embedded_guidance_scale", "flow_shift", "force_offload", "seed", "alpha"], "optional": ["interpolation_curve", "feta_args"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["samples"], "name": "HyVideoPromptMixSampler", "display_name": "HunyuanVideo Prompt Mix Sampler", "description": "", "python_module": "custom_nodes.ComfyUI-HunyuanVideoWrapper", "category": "HunyuanVideoWrapper", "output_node": false, "experimental": true}, "VHS_VideoCombine": {"input": {"required": {"images": ["IMAGE"], "frame_rate": ["FLOAT", {"default": 8, "min": 1, "step": 1}], "loop_count": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "filename_prefix": ["STRING", {"default": "AnimateDiff"}], "format": [["image/gif", "image/webp", "video/nvenc_av1-mp4", "video/16bit-png", "video/nvenc_hevc-mp4", "video/av1-webm", "video/ffmpeg-gif", "video/8bit-png", "video/ffv1-mkv", "video/h264-mp4", "video/h265-mp4", "video/webm", "video/nvenc_h264-mp4", "video/ProRes"], {"formats": {"video/nvenc_av1-mp4": [["pix_fmt", ["yuv420p", "p010le"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/nvenc_hevc-mp4": [["pix_fmt", ["yuv420p", "p010le"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/av1-webm": [["pix_fmt", ["yuv420p10le", "yuv420p"]], ["crf", "INT", {"default": 23, "min": 0, "max": 100, "step": 1}], ["input_color_depth", ["8bit", "16bit"]], ["save_metadata", "BOOLEAN", {"default": true}]], "video/ffmpeg-gif": [["dither", ["bayer", "heckbert", "floyd_steinberg", "sierra2", "sierra2_4a", "sierra3", "burkes", "atkinson", "none"], {"default": "sierra2_4a"}, "[0:v] split [a][b]; [a] palettegen=reserve_transparent=on:transparency_color=ffffff [p]; [b][p] paletteuse=dither=$val"]], "video/ffv1-mkv": [["level", ["0", "1", "3"], {"default": "3"}], ["coder", ["0", "1", "2"], {"default": "1"}], ["context", ["0", "1"], {"default": "1"}], ["gop_size", "INT", {"default": 1, "min": 1, "max": 300, "step": 1}], ["slices", ["4", "6", "9", "12", "16", "20", "24", "30"], {"default": "16"}], ["slicecrc", ["0", "1"], {"default": "1"}], ["pix_fmt", ["rgba64le", "bgra", "yuv420p", "yuv422p", "yuv444p", "yuva420p", "yuva422p", "yuva444p", "yuv420p10le", "yuv422p10le", "yuv444p10le", "yuv420p12le", "yuv422p12le", "yuv444p12le", "yuv420p14le", "yuv422p14le", "yuv444p14le", "yuv420p16le", "yuv422p16le", "yuv444p16le", "gray", "gray10le", "gray12le", "gray16le"], {"default": "rgba64le"}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]], "video/h264-mp4": [["pix_fmt", ["yuv420p", "yuv420p10le"]], ["crf", "INT", {"default": 19, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]], "video/h265-mp4": [["pix_fmt", ["yuv420p10le", "yuv420p"]], ["crf", "INT", {"default": 22, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/webm": [["pix_fmt", ["yuv420p", "yuva420p"]], ["crf", "INT", {"default": 20, "min": 0, "max": 100, "step": 1}], ["save_metadata", "BOOLEAN", {"default": true}], ["trim_to_audio", "BOOLEAN", {"default": false}]], "video/nvenc_h264-mp4": [["pix_fmt", ["yuv420p", "p010le"]], ["bitrate", "INT", {"default": 10, "min": 1, "max": 999, "step": 1}], ["megabit", "BOOLEAN", {"default": true}], ["save_metadata", "BOOLEAN", {"default": true}]], "video/ProRes": [["profile", ["lt", "standard", "hq", "4444", "4444xq"], {"default": "hq"}]], "image/webp": [["lossless", "BOOLEAN", {"default": true}]]}}], "pingpong": ["BOOLEAN", {"default": false}], "save_output": ["BOOLEAN", {"default": true}]}, "optional": {"audio": ["AUDIO"], "meta_batch": ["VHS_BatchManager"], "vae": ["VAE"]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["images", "frame_rate", "loop_count", "filename_prefix", "format", "pingpong", "save_output"], "optional": ["audio", "meta_batch", "vae"], "hidden": ["prompt", "extra_pnginfo", "unique_id"]}, "output": ["VHS_FILENAMES"], "output_is_list": [false], "output_name": ["Filenames"], "name": "VHS_VideoCombine", "display_name": "Video Combine \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Combine \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine an image sequence into a video</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be turned into a video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: (optional) audio to add to the video</div></div><div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long image sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided, the node will take latents as input instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Unlike on Load Video, this isn't always a strict upgrade over using a standalone VAE Decode.</div><div style=\"font-size: 1em\">If you have multiple Video Combine outputs, then the VAE decode will be performed for each output node increasing execution time</div><div style=\"font-size: 1em\">If you make any change to output settings on the Video Combine (such as changing the output format), the VAE decode will be performed again as the decoded result is (by design) not cached</div></div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frame_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_rate: The frame rate which will be used for the output video. Consider converting this to an input and connecting this to a Load Video with Video Info(Loaded)->fps. When including audio, failure to properly set this will result in audio desync</div></div><div vhs_title=\"loop_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loop_count: The number of additional times the video should repeat. Can cause performance issues when used with long (100+ frames) sequences</div></div><div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A prefix to add to the name of the output filename. This can include subfolders or format strings.</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: The output format to use. Formats starting with, 'image' are saved with PIL, but formats starting with 'video' utilize the video_formats system. 'video' options require ffmpeg and selecting one frequently adds additional options to the node.</div></div><div vhs_title=\"pingpong\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pingpong: Play the video normally, then repeat the video in reverse so that it 'pingpongs' back and forth. This is frequently used to minimize the appearance of skips on very short animations.</div></div><div vhs_title=\"save_output\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_output: Specifies if output files should be saved to the output folder, or the temporary output folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the processed result. If advanced previews is enabled, the output is always converted to a format viewable from the browser. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div><div vhs_title=\"Common Format Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Common Format Widgets: <div vhs_title=\"crf\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crf: Determines how much to prioritize quality over filesize. Numbers vary between formats, but on each format that includes it, the default value provides visually loss less output</div></div><div vhs_title=\"pix_fmt\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pix_fmt: The pixel format to use for output. Alternative options will often have higher quality at the cost of increased file size and reduced compatibility with external software.<div style=\"font-size: 1em\"><div vhs_title=\"yuv420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p: The most common and default format</div></div><div vhs_title=\"yuv420p10le\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuv420p10le: Use 10 bit color depth. This can improve color quality when combined with 16bit input color depth</div></div><div vhs_title=\"yuva420p\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">yuva420p: Include transparency in the output video</div></div></div></div></div><div vhs_title=\"input_color_depth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">input_color_depth: VHS supports outputting 16bit images. While this produces higher quality output, the difference usually isn't visible without postprocessing and it significantly increases file size and processing time.</div></div><div vhs_title=\"save_metadata\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">save_metadata: Determines if metadata for the workflow should be included in the output video file</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": true}, "VHS_LoadVideo": {"input": {"required": {"video": [[]], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "INT", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "frame_count", "audio", "video_info"], "name": "VHS_LoadVideo", "display_name": "Load Video (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoPath": {"input": {"required": {"video": ["STRING", {"placeholder": "X://insert/path/here.mp4", "vhs_path_extensions": ["webm", "mp4", "mkv", "gif", "mov"]}], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "skip_first_frames": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "skip_first_frames", "select_every_nth"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "INT", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "frame_count", "audio", "video_info"], "name": "VHS_LoadVideoPath", "display_name": "Load Video (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoFFmpeg": {"input": {"required": {"video": [[]], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 0.001, "widgetType": "VHSTIMESTAMP"}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "start_time"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "MASK", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "mask", "audio", "video_info"], "name": "VHS_LoadVideoFFmpeg", "display_name": "Load Video FFmpeg (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video FFmpeg \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from the input folder using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded. Lists all files with a video extension in the ComfyUI/Input folder</div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"choose video to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose video to upload: An upload button is provided to upload local files to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. If advanced previews is enabled, this preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadVideoFFmpegPath": {"input": {"required": {"video": ["STRING", {"placeholder": "X://insert/path/here.mp4", "vhs_path_extensions": ["webm", "mp4", "mkv", "gif", "mov"]}], "force_rate": ["FLOAT", {"default": 0, "min": 0, "max": 60, "step": 1, "disable": 0}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "disable": 0}], "frame_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1, "disable": 0}], "start_time": ["FLOAT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 0.001, "widgetType": "VHSTIMESTAMP"}]}, "optional": {"meta_batch": ["VHS_BatchManager"], "vae": ["VAE"], "format": [["None", "AnimateDiff", "Mochi", "LTXV", "Hunyuan", "Cosmos", "Wan"], {"default": "AnimateDiff", "formats": {"None": {}, "AnimateDiff": {"target_rate": 8, "dim": [8, 0, 512, 512]}, "Mochi": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [6, 1]}, "LTXV": {"target_rate": 24, "dim": [32, 0, 768, 512], "frames": [8, 1]}, "Hunyuan": {"target_rate": 24, "dim": [16, 0, 848, 480], "frames": [4, 1]}, "Cosmos": {"target_rate": 24, "dim": [16, 0, 1280, 704], "frames": [8, 1]}, "Wan": {"target_rate": 16, "dim": [8, 0, 832, 480], "frames": [4, 1]}}}]}, "hidden": {"force_size": "STRING", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["video", "force_rate", "custom_width", "custom_height", "frame_load_cap", "start_time"], "optional": ["meta_batch", "vae", "format"], "hidden": ["force_size", "unique_id"]}, "output": ["IMAGE", "MASK", "AUDIO", "VHS_VIDEOINFO"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE", "mask", "audio", "video_info"], "name": "VHS_LoadVideoFFmpegPath", "display_name": "Load Video FFmpeg (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Video FFmpeg (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a video from an arbitrary path using ffmpeg instead of opencv</div></div><div style=\"font-size: 0.8em\">Provides faster execution speed, transparency support, and allows specifying start time in seconds</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images. This drastically reduces the required RAM (not VRAM) when working with long (100+ frames) sequences<div style=\"font-size: 1em\">Using this is strongly encouraged unless connecting to a node that requires a blue image connection such as Apply Controllnet</div></div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: Transparency data from the loaded video</div></div><div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio from the loaded video</div></div><div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: Exposes additional info about the video such as the source frame rate, or the total length</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The loaded images pre-converted to latents. Only available when a vae is connected</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"video\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video: The video file to be loaded.<div style=\"font-size: 1em\">You can also select an image to load it as a single frame</div><div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_rate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_rate: Drops or duplicates frames so that the produced output has the target frame rate. Many motion models are trained on videos of a specific frame rate and will give better results if input matches that frame rate. If set to 0, all frames are returned. May give unusual results with inputs that have a variable frame rate like animated gifs. Reducing this value can also greatly reduce the execution time and memory requirements.</div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Previously was used to provide suggested resolutions. Instead, custom_width and custom_height can be disabled by setting to 0.</div></div><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"frame_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_load_cap: The maximum number of frames to load. If 0, all frames are loaded.</div></div><div vhs_title=\"skip_first_frames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_frames: A number of frames which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Similar to frame rate. Keeps only the first of every n frames and discard the rest. Has better compatibility with variable frame rate inputs such as gifs. When combined with force_rate, select_every_nth_applies after force_rate so the resulting output has a frame rate equivalent to force_rate/select_every_nth. select_every_nth does not apply to skip_first_frames</div></div><div vhs_title=\"format\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">format: Updates other widgets so that only values supported by the given format can be entered and provides recommended defaults.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the frame_load_cap, force_rate, skip_first_frames, and select_every_nth values chosen. If the video has audio, it will also be previewed when moused over. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImagePath": {"input": {"required": {"image": ["STRING", {"placeholder": "X://insert/path/here.png", "vhs_path_extensions": [".pgm", ".jpg", ".tif", ".bmp", ".ppm", ".webp", ".tiff", ".png", ".jpeg"]}], "custom_width": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 8, "disable": 0}], "custom_height": ["INT", {"default": 0, "min": 0, "max": 8192, "step": 8, "disable": 0}]}, "optional": {"vae": ["VAE"]}, "hidden": {"force_size": "STRING"}}, "input_order": {"required": ["image", "custom_width", "custom_height"], "optional": ["vae"], "hidden": ["force_size"]}, "output": ["IMAGE", "MASK"], "output_is_list": [false, false], "output_name": ["IMAGE", "mask"], "name": "VHS_LoadImagePath", "display_name": "Load Image (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Image (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Load a single image from a given path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: (optional) If provided the node will output latents instead of images.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"image\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image: The image file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"force_size\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">force_size: Allows for conveniently scaling the input without requiring an additional node. Provides options to maintain aspect ratio or conveniently target common training formats for Animate Diff<div style=\"font-size: 1em\"><div vhs_title=\"custom_width\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_width: Allows for an arbitrary width to be entered, cropping to maintain aspect ratio if both are set</div></div><div vhs_title=\"custom_height\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">custom_height: Allows for an arbitrary height to be entered, cropping to maintain aspect ratio if both are set</div></div></div></div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImages": {"input": {"required": {"directory": [["3d"]]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "meta_batch": ["VHS_BatchManager"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "skip_first_images", "select_every_nth", "meta_batch"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "frame_count"], "name": "VHS_LoadImages", "display_name": "Load Images (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from a subdirectory of the input folder</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files</div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: A timestamp, in seconds from the start of the video, to start loading frames from. </div></div><div vhs_title=\"choose folder to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose folder to upload: An upload button is provided to upload a local folder containing images to the input folder</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadImagesPath": {"input": {"required": {"directory": ["STRING", {"placeholder": "X://path/to/images", "vhs_path_extensions": []}]}, "optional": {"image_load_cap": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "meta_batch": ["VHS_BatchManager"]}, "hidden": {"unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["directory"], "optional": ["image_load_cap", "skip_first_images", "select_every_nth", "meta_batch"], "hidden": ["unique_id"]}, "output": ["IMAGE", "MASK", "INT"], "output_is_list": [false, false, false], "output_name": ["IMAGE", "MASK", "frame_count"], "name": "VHS_LoadImagesPath", "display_name": "Load Images (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Images (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads a sequence of images from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: (optional) Connect to a Meta Batch manager to divide extremely long sequences into sub batches. See the documentation for Meta Batch Manager</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The loaded images</div></div><div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The alpha channel of the loaded images.</div></div><div vhs_title=\"frame_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frame_count: The length of images just returned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"directory\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">directory: The directory images will be loaded from. Filtered to process jpg, png, ppm, bmp, tif, and webp files<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"image_load_cap\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">image_load_cap: The maximum number of images to load. If 0, all images are loaded.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of images which are discarded before producing output.</div></div><div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: Keeps only the first of every n frames and discard the rest.</div></div><div vhs_title=\"videopreview\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">videopreview: Displays a preview for the selected video input. Will only be shown if Advanced Previews is enabled. This preview will reflect the image_load_cap, skip_first_images, and select_every_nth values chosen. Additional preview options can be accessed with right click.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_LoadAudio": {"input": {"required": {"audio_file": ["STRING", {"default": "input/", "vhs_path_extensions": ["wav", "mp3", "ogg", "m4a", "flac"]}]}, "optional": {"seek_seconds": ["FLOAT", {"default": 0, "min": 0, "widgetType": "VHSTIMESTAMP"}], "duration": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01, "widgetType": "VHSTIMESTAMP"}]}}, "input_order": {"required": ["audio_file"], "optional": ["seek_seconds", "duration"]}, "output": ["AUDIO", "FLOAT"], "output_is_list": [false, false], "output_name": ["audio", "duration"], "name": "VHS_LoadAudio", "display_name": "Load Audio (Path)\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Audio (Path) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from an arbitrary path</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio_file\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio_file: The audio file to be loaded.<div style=\"font-size: 1em\">This is a VHS_PATH input. When edited, it provides a list of possible valid files or directories</div><div style=\"font-size: 1em\"><video preload=\"none\" src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/729b7185-1fca-41d8-bc8d-a770bb2a5ce6 muted loop controls controlslist=\"nodownload noremoteplayback noplaybackrate\" style=\"width: 0px; min-width: 100%\" class=\"VHS_loopedvideo\"></div><div style=\"font-size: 1em\">The current top-most completion may be selected with Tab</div><div style=\"font-size: 1em\">You can navigate up a directory by pressing Ctrl+B (or Ctrl+W if supported by browser)</div><div style=\"font-size: 1em\">The filter on suggested file types can be disabled by pressing Ctrl+G.</div><div style=\"font-size: 1em\">If converted to an input, this functions as a string</div></div></div><div vhs_title=\"seek_seconds\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">seek_seconds: An offset from the start of the sound file that the audio should start from</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_LoadAudioUpload": {"input": {"required": {"audio": [[]]}, "optional": {"start_time": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01, "widgetType": "VHSTIMESTAMP"}], "duration": ["FLOAT", {"default": 0, "min": 0, "max": 10000000, "step": 0.01, "widgetType": "VHSTIMESTAMP"}]}}, "input_order": {"required": ["audio"], "optional": ["start_time", "duration"]}, "output": ["AUDIO", "FLOAT"], "output_is_list": [false, false], "output_name": ["audio", "duration"], "name": "VHS_LoadAudioUpload", "display_name": "Load Audio (Upload)\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Load Audio (Upload) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Loads an audio file from the input directory</div></div><div style=\"font-size: 0.8em\">Very similar in functionality to the built-in LoadAudio. It was originally added before VHS swapped to use Comfy's internal AUDIO format, but provides the additional options for start time and duration</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The loaded audio</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: The audio file to be loaded.</div></div><div vhs_title=\"start_time\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">start_time: An offset from the start of the sound file that the audio should start from</div></div><div vhs_title=\"duration\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">duration: A maximum limit for the audio. Disabled if 0</div></div><div vhs_title=\"choose audio to upload\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">choose audio to upload: An upload button is provided to upload an audio file to the input folder</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_AudioToVHSAudio": {"input": {"required": {"audio": ["AUDIO"]}}, "input_order": {"required": ["audio"]}, "output": ["VHS_AUDIO"], "output_is_list": [false], "output_name": ["vhs_audio"], "name": "VHS_AudioToVHSAudio", "display_name": "Audio to legacy VHS_AUDIO\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Audio to legacy VHS_AUDIO \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">audio: An input in the standardized AUDIO format</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the legacy VHS_AUDIO format for use with external nodes</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_VHSAudioToAudio": {"input": {"required": {"vhs_audio": ["VHS_AUDIO"]}}, "input_order": {"required": ["vhs_audio"]}, "output": ["AUDIO"], "output_is_list": [false], "output_name": ["audio"], "name": "VHS_VHSAudioToAudio", "display_name": "Legacy VHS_AUDIO to Audio\ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Legacy VHS_AUDIO to Audio \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>utility function for compatibility with external nodes</div></div><div style=\"font-size: 0.8em\">VHS used to use an internal VHS_AUDIO format for routing audio between inputs and outputs. This format was intended to only be used internally and was designed with a focus on performance over ease of use. Since ComfyUI now has an internal AUDIO format, VHS now uses this format. However, some custom node packs were made that are external to both ComfyUI and VHS that use VHS_AUDIO. This node was added so that those external nodes can still function</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An input in the legacy VHS_AUDIO format produced by an external node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"vhs_audio\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vhs_audio: An output in the standardized AUDIO format</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/audio", "output_node": false}, "VHS_PruneOutputs": {"input": {"required": {"filenames": ["VHS_FILENAMES"], "options": [["Intermediate", "Intermediate and Utility"]]}}, "input_order": {"required": ["filenames", "options"]}, "output": [], "output_is_list": [], "output_name": [], "name": "VHS_PruneOutputs", "display_name": "Prune Outputs \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Prune Outputs \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Automates deletion of undesired outputs from a Video Combine node.</div></div><div style=\"font-size: 0.8em\">Video Combine produces a number of file outputs in addition to the final output. Some of these, such as a video file without audio included, are implementation limitations and are not feasible to solve. As an alternative, the Prune Outputs node is added to automate the deletion of these file outputs if they are not desired</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A connection from a Video Combine node to indicate which outputs should be pruned</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"options\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">options: Which files should be deleted<div style=\"font-size: 1em\"><div vhs_title=\"Intermediate\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate: Delete any files that were required for intermediate processing but are not the final output, like the no-audio output file when audio is included</div></div><div vhs_title=\"Intermediate and Utility\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Intermediate and Utility: Delete all produced files that aren't the final output, including the first frame png</div></div></div></div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": true}, "VHS_BatchManager": {"input": {"required": {"frames_per_batch": ["INT", {"default": 16, "min": 1, "max": 9007199254740991, "step": 1}]}, "hidden": {"prompt": "PROMPT", "unique_id": "UNIQUE_ID"}}, "input_order": {"required": ["frames_per_batch"], "hidden": ["prompt", "unique_id"]}, "output": ["VHS_BatchManager"], "output_is_list": [false], "output_name": ["meta_batch"], "name": "VHS_BatchManager", "display_name": "Meta Batch Manager \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Meta Batch Manager \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split the processing of a very long video into sets of smaller Meta Batches</div></div><div style=\"font-size: 0.8em\">The Meta Batch Manager allows for extremely long input videos to be processed when all other methods for fitting the content in RAM fail. It does not effect VRAM usage.</div><div style=\"font-size: 0.8em\">It must be connected to at least one Input (a Load Video or Load Images) AND at least one Video Combine</div><div style=\"font-size: 0.8em\"><img src=https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite/assets/4284322/7cb3fb7e-59d8-4cb2-a09f-9c6698de8b1f loading=lazy style=\"width: 0px; min-width: 100%\"></div><div style=\"font-size: 0.8em\">It functions by holding both the inputs and ouputs open between executions, and automatically requeue's the workflow until one of the inputs is unable to provide additional images.</div><div style=\"font-size: 0.8em\">Because each sub execution only contains a subset of the total frames, each sub execution creates a hard window which temporal smoothing can not be applied across. This results in jumps in the output.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"meta_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">meta_batch: Add all connected nodes to this Meta Batch</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"frames_per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">frames_per_batch: How many frames to process for each sub execution. If loading as image, each frame will use about 50MB of RAM (not VRAM), and this can safely be set in the 100-1000 range, depending on available memory. When loading and combining from latent space (no blue image noodles exist), this value can be much higher, around the 2,000 to 20,000 range</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfo": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT", "FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false, false, false, false, false, false], "output_name": ["source_fps\ud83d\udfe8", "source_frame_count\ud83d\udfe8", "source_duration\ud83d\udfe8", "source_width\ud83d\udfe8", "source_height\ud83d\udfe8", "loaded_fps\ud83d\udfe6", "loaded_frame_count\ud83d\udfe6", "loaded_duration\ud83d\udfe6", "loaded_width\ud83d\udfe6", "loaded_height\ud83d\udfe6"], "name": "VHS_VideoInfo", "display_name": "Video Info \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps\ud83d\udfe8: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count\ud83d\udfe8: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration\ud83d\udfe8: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width\ud83d\udfe8: The width</div></div><div vhs_title=\"source_height\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height\ud83d\udfe8: The height</div></div><div vhs_title=\"loaded_fps\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps\ud83d\udfe6: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count\ud83d\udfe6: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration\ud83d\udfe6: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width\ud83d\udfe6: The width of the video after scaling. These coordinates are in image space even if loading to latent space</div></div><div vhs_title=\"loaded_height\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height\ud83d\udfe6: The height of the video after scaling. These coordinates are in image space even if loading to latent space</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfoSource": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["fps\ud83d\udfe8", "frame_count\ud83d\udfe8", "duration\ud83d\udfe8", "width\ud83d\udfe8", "height\ud83d\udfe8"], "name": "VHS_VideoInfoSource", "display_name": "Video Info (Source) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info Source \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself without accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"source_fps\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_fps\ud83d\udfe8: The frame rate of the video</div></div><div vhs_title=\"source_frame_count\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_frame_count\ud83d\udfe8: How many total frames the video contains before accounting for frame rate or select_every_nth</div></div><div vhs_title=\"source_duration\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_duration\ud83d\udfe8: The length of images just returned in seconds</div></div><div vhs_title=\"source_width\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_width\ud83d\udfe8: The original width</div></div><div vhs_title=\"source_height\ud83d\udfe8\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">source_height\ud83d\udfe8: The original height</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VideoInfoLoaded": {"input": {"required": {"video_info": ["VHS_VIDEOINFO"]}}, "input_order": {"required": ["video_info"]}, "output": ["FLOAT", "INT", "FLOAT", "INT", "INT"], "output_is_list": [false, false, false, false, false], "output_name": ["fps\ud83d\udfe6", "frame_count\ud83d\udfe6", "duration\ud83d\udfe6", "width\ud83d\udfe6", "height\ud83d\udfe6"], "name": "VHS_VideoInfoLoaded", "display_name": "Video Info (Loaded) \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Video Info Loaded \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Splits information on a video into a numerous outputs describing the file itself after accounting for load options</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"video_info\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">video_info: A connection to a Load Video node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"loaded_fps\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_fps\ud83d\udfe6: The frame rate after accounting for force_rate and select_every_nth. This output is of particular use as it can be connected to the converted frame_rate input of a Video Combine node to ensure audio remains synchronized.</div></div><div vhs_title=\"loaded_frame_count\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_frame_count\ud83d\udfe6: The number of frames returned by the current execution. Identical to the frame_count returned by the node itself</div></div><div vhs_title=\"loaded_duration\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_duration\ud83d\udfe6: The duration in seconds of returned images after accounting for frame_load_cap</div></div><div vhs_title=\"loaded_width\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_width\ud83d\udfe6: The width of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div><div vhs_title=\"loaded_height\ud83d\udfe6\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">loaded_height\ud83d\udfe6: The height of the video after scaling. This is the dimension of the corresponding image even if loading as a latent directly</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_SelectFilename": {"input": {"required": {"filenames": ["VHS_FILENAMES"], "index": ["INT", {"default": -1, "step": 1, "min": -1}]}}, "input_order": {"required": ["filenames", "index"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["Filename"], "name": "VHS_SelectFilename", "display_name": "Select Filename \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Select Filename \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Select a single filename from the VHS_FILENAMES output by a Video Combine and return it as a string</div></div><div style=\"font-size: 0.8em\">Take care when combining this node with Prune Outputs. The VHS_FILENAMES object is immutable and will always contain the full list of output files, but execution order is undefined behavior (currently, Prune Outputs will generally execute first) and SelectFilename may return a path to a file that no longer exists.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filenames\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filenames: A VHS_FILENAMES from a Video Combine node</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename: A string representation of the full output path for the chosen file</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">index: The index of which file should be selected. The default, -1, chooses the most complete output</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_VAEEncodeBatched": {"input": {"required": {"pixels": ["IMAGE"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1}]}}, "input_order": {"required": ["pixels", "vae", "per_batch"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VHS_VAEEncodeBatched", "display_name": "VAE Encode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Encode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Encode images as latents with a manually specified batch size.</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when encoding images.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Encode or to encode directly from a Load Video</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"pixels\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pixels: The images to be encoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when encoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The encoded latents.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to encode in each batch.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/batched nodes", "output_node": false}, "VHS_VAEDecodeBatched": {"input": {"required": {"samples": ["LATENT"], "vae": ["VAE"], "per_batch": ["INT", {"default": 16, "min": 1}]}}, "input_order": {"required": ["samples", "vae", "per_batch"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VHS_VAEDecodeBatched", "display_name": "VAE Decode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "VAE Decode Batched \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Decode latents to images with a manually specified batch size</div></div><div style=\"font-size: 0.8em\">Some people have ran into VRAM issues when encoding or decoding large batches of images. As a workaround, this node lets you manually set a batch size when decoding latents.</div><div style=\"font-size: 0.8em\">Unless these issues have been encountered, it is simpler to use the native VAE Decode or to decode from a Video Combine directly</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"samples\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">samples: The latents to be decoded.</div></div><div vhs_title=\"vae\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">vae: The VAE to use when decoding.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The decoded images.</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"per_batch\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">per_batch: The maximum number of images to decode in each batch.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/batched nodes", "output_node": false}, "VHS_SplitLatents": {"input": {"required": {"latents": ["LATENT"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["latents", "split_index"]}, "output": ["LATENT", "INT", "LATENT", "INT"], "output_is_list": [false, false, false, false], "output_name": ["LATENT_A", "A_count", "LATENT_B", "B_count"], "name": "VHS_SplitLatents", "display_name": "Split Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of latents into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_A: The first group of latents</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of latents in group A. This will be equal to split_index unless the latents input has length less than split_index</div></div><div vhs_title=\"LATENT_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT_B: The second group of latents</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of latents in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SplitImages": {"input": {"required": {"images": ["IMAGE"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["images", "split_index"]}, "output": ["IMAGE", "INT", "IMAGE", "INT"], "output_is_list": [false, false, false, false], "output_name": ["IMAGE_A", "A_count", "IMAGE_B", "B_count"], "name": "VHS_SplitImages", "display_name": "Split Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of images into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The images to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_A: The first group of images</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of images in group A. This will be equal to split_index unless the images input has length less than split_index</div></div><div vhs_title=\"IMAGE_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE_B: The second group of images</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of images in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SplitMasks": {"input": {"required": {"mask": ["MASK"], "split_index": ["INT", {"default": 0, "step": 1, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["mask", "split_index"]}, "output": ["MASK", "INT", "MASK", "INT"], "output_is_list": [false, false, false, false], "output_name": ["MASK_A", "A_count", "MASK_B", "B_count"], "name": "VHS_SplitMasks", "display_name": "Split Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Split Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Split a set of masks into two groups</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The masks to be split.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_A: The first group of masks</div></div><div vhs_title=\"A_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">A_count: The number of masks in group A. This will be equal to split_index unless the mask input has length less than split_index</div></div><div vhs_title=\"MASK_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK_B: The second group of masks</div></div><div vhs_title=\"B_count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">B_count: The number of masks in group B</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"split_index\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">split_index: The index of the first latent that will be in the second output groups.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_MergeLatents": {"input": {"required": {"latents_A": ["LATENT"], "latents_B": ["LATENT"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["latents_A", "latents_B", "merge_strategy", "scale_method", "crop"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_MergeLatents", "display_name": "Merge Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of latents into a single group of latents</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_A: The first group of latents</div></div><div vhs_title=\"latents_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents_B: The first group of latents</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The combined group of latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_MergeImages": {"input": {"required": {"images_A": ["IMAGE"], "images_B": ["IMAGE"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["images_A", "images_B", "merge_strategy", "scale_method", "crop"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_MergeImages", "display_name": "Merge Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of images into a single group of images</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_A: The first group of images</div></div><div vhs_title=\"images_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images_B: The first group of images</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The combined group of images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_MergeMasks": {"input": {"required": {"mask_A": ["MASK"], "mask_B": ["MASK"], "merge_strategy": [["match A", "match B", "match smaller", "match larger"]], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "bislerp"]], "crop": [["disabled", "center"]]}}, "input_order": {"required": ["mask_A", "mask_B", "merge_strategy", "scale_method", "crop"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_MergeMasks", "display_name": "Merge Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Merge Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Combine two groups of masks into a single group of masks</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask_A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_A: The first group of masks</div></div><div vhs_title=\"mask_B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask_B: The first group of masks</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The combined group of masks</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The length of the combined group</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"merge_strategy\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">merge_strategy: Determines what the output resolution will be if input resolutions don't match<div style=\"font-size: 1em\"><div vhs_title=\"match A\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match A: Always use the resolution for A</div></div><div vhs_title=\"match B\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match B: Always use the resolution for B</div></div><div vhs_title=\"match smaller\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match smaller: Pick the smaller resolution by area</div></div><div vhs_title=\"match larger\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">match larger: Pick the larger resolution by area</div></div></div></div></div><div vhs_title=\"scale_method\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">scale_method: Determines what method to use if scaling is required</div></div><div vhs_title=\"crop\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">crop: When sizes don't match, should the resized image have it's aspect ratio changed, or be cropped to maintain aspect ratio</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_GetLatentCount": {"input": {"required": {"latents": ["LATENT"]}}, "input_order": {"required": ["latents"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetLatentCount", "display_name": "Get Latent Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Latent Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of latents in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_GetImageCount": {"input": {"required": {"images": ["IMAGE"]}}, "input_order": {"required": ["images"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetImageCount", "display_name": "Get Image Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Image Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of images in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_GetMaskCount": {"input": {"required": {"mask": ["MASK"]}}, "input_order": {"required": ["mask"]}, "output": ["INT"], "output_is_list": [false], "output_name": ["count"], "name": "VHS_GetMaskCount", "display_name": "Get Mask Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Get Mask Count \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Return the number of masks in an input as an INT</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of masks in the input</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_DuplicateLatents": {"input": {"required": {"latents": ["LATENT"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["latents", "multiply_by"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_DuplicateLatents", "display_name": "Repeat Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a latent to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The latents to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The latent with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the output. Equal to the length of the input latent * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the latent should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_DuplicateImages": {"input": {"required": {"images": ["IMAGE"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["images", "multiply_by"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_DuplicateImages", "display_name": "Repeat Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a image to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"IMAGES\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGES: The image to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The image with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of image in the output. Equal to the length of the input image * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_DuplicateMasks": {"input": {"required": {"mask": ["MASK"], "multiply_by": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["mask", "multiply_by"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_DuplicateMasks", "display_name": "Repeat Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Repeat Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Append copies of a mask to itself so it repeats</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"masks\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">masks: The masks to be repeated</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The mask with repeats</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the output. Equal to the length of the input mask * multiply_by</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"multiply_by\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">multiply_by: Controls the number of times the mask should repeat. 1, the default, means no change.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_SelectEveryNthLatent": {"input": {"required": {"latents": ["LATENT"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_latents": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["latents", "select_every_nth", "skip_first_latents"]}, "output": ["LATENT", "INT"], "output_is_list": [false, false], "output_name": ["LATENT", "count"], "name": "VHS_SelectEveryNthLatent", "display_name": "Select Every Nth Latent \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Latent \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 latent for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latents: The input latent</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"LATENT\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: The output latents</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of latents in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_latents\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_latents: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the latent into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SelectEveryNthImage": {"input": {"required": {"images": ["IMAGE"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_images": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["images", "select_every_nth", "skip_first_images"]}, "output": ["IMAGE", "INT"], "output_is_list": [false, false], "output_name": ["IMAGE", "count"], "name": "VHS_SelectEveryNthImage", "display_name": "Select Every Nth Image \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Image \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 image for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">images: The input image</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"IMAGE\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">IMAGE: The output images</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of images in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_images\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_images: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the image into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SelectEveryNthMask": {"input": {"required": {"mask": ["MASK"], "select_every_nth": ["INT", {"default": 1, "min": 1, "max": 9007199254740991, "step": 1}], "skip_first_masks": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}}, "input_order": {"required": ["mask", "select_every_nth", "skip_first_masks"]}, "output": ["MASK", "INT"], "output_is_list": [false, false], "output_name": ["MASK", "count"], "name": "VHS_SelectEveryNthMask", "display_name": "Select Every Nth Mask \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Every Nth Mask \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Keep only 1 mask for every interval</div></div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">mask: The input mask</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"MASK\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">MASK: The output mask</div></div><div vhs_title=\"count\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">count: The number of mask in the input</div></div></div></div><div vhs_title=\"Widgets\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Widgets: <div vhs_title=\"select_every_nth\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">select_every_nth: The interval from which one frame is kept. 1 means no frames are skipped.</div></div><div vhs_title=\"skip_first_mask\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">skip_first_mask: A number of frames which that is skipped from the start. This applies before select_every_nth. As a result, multiple copies of the node can each have a different skip_first_frames to divide the mask into groups</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_SelectLatents": {"input": {"required": {"latent": ["LATENT"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["latent", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "VHS_SelectLatents", "display_name": "Select Latents \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/latent", "output_node": false}, "VHS_SelectImages": {"input": {"required": {"image": ["IMAGE"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["image", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "VHS_SelectImages", "display_name": "Select Images \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/image", "output_node": false}, "VHS_SelectMasks": {"input": {"required": {"mask": ["MASK"], "indexes": ["STRING", {"default": "0"}], "err_if_missing": ["BOOLEAN", {"default": true}], "err_if_empty": ["BOOLEAN", {"default": true}]}}, "input_order": {"required": ["mask", "indexes", "err_if_missing", "err_if_empty"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "VHS_SelectMasks", "display_name": "Select Masks \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Use comma-separated indexes to select items in the given order.\nSupports negative indexes, python-style ranges (end index excluded),\nas well as range step.\n\nAcceptable entries (assuming 16 items provided, so idxs 0 to 15 exist):\n0         -> Returns [0]\n-1        -> Returns [15]\n0, 1, 13  -> Returns [0, 1, 13]\n0:5, 13   -> Returns [0, 1, 2, 3, 4, 13]\n0:-1      -> Returns [0, 1, 2, ..., 13, 14]\n0:5:-1    -> Returns [4, 3, 2, 1, 0]\n0:5:2     -> Returns [0, 2, 4]\n::-1     -> Returns [15, 14, 13, ..., 2, 1, 0]\n", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62/mask", "output_node": false}, "VHS_Unbatch": {"input": {"required": {"batched": ["*"]}}, "input_order": {"required": ["batched"]}, "output": ["*"], "output_is_list": [false], "output_name": ["unbatched"], "name": "VHS_Unbatch", "display_name": "Unbatch \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Unbatch \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Unbatch a list of items into a single concatenated item</div></div><div style=\"font-size: 0.8em\">Useful for when you want a single video output from a complex workflow</div><div style=\"font-size: 0.8em\">Has no relation to the Meta Batch system of VHS</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"batched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">batched: Any input which may or may not be batched</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"unbatched\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">unbatched: A single output element. Torch tensors are concatenated across dim 0, all other types are added which functions as concatenation for strings and arrays, but may give undesired results for other types</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false}, "VHS_SelectLatest": {"input": {"required": {"filename_prefix": ["STRING", {"default": "output/AnimateDiff", "vhs_path_extensions": []}], "filename_postfix": ["STRING", {"placeholder": ".webm"}]}}, "input_order": {"required": ["filename_prefix", "filename_postfix"]}, "output": ["STRING"], "output_is_list": [false], "output_name": ["Filename"], "name": "VHS_SelectLatest", "display_name": "Select Latest \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "description": "Select Latest \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62<div style=\"font-size: 0.8em\"><div id=VHS_shortdesc>Experimental virtual node to select the most recently modified file from a given folder</div></div><div style=\"font-size: 0.8em\">Assists in the creation of workflows where outputs from one execution are used elsewhere in subsequent executions.</div><div style=\"font-size: 0.8em\"><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"filename_prefix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_prefix: A path which can consist of a combination of folders and a prefix which candidate files must match</div></div><div vhs_title=\"filename_postfix\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">filename_postfix: A string which chich the selected file must end with. Useful for limiting to a target extension.</div></div></div></div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"Filename\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Filename: A string representing a file path to the most recently modified file.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-VideoHelperSuite", "category": "Video Helper Suite \ud83c\udfa5\ud83c\udd65\ud83c\udd57\ud83c\udd62", "output_node": false, "experimental": true}, "ADE_AnimateDiffLoRALoader": {"input": {"required": {"name": [[]], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"prev_motion_lora": ["MOTION_LORA"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 30}]}}, "input_order": {"required": ["name", "strength"], "optional": ["prev_motion_lora"], "hidden": ["autosize"]}, "output": ["MOTION_LORA"], "output_is_list": [false], "output_name": ["MOTION_LORA"], "name": "ADE_AnimateDiffLoRALoader", "display_name": "Load AnimateDiff LoRA \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53", "output_node": false}, "ADE_AnimateDiffSamplingSettings": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen": [["comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}, "optional": {"noise_layers": ["NOISE_LAYERS"], "iteration_opts": ["ITERATION_OPTS"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}], "adapt_denoise_steps": ["BOOLEAN", {"default": false}], "custom_cfg": ["CUSTOM_CFG"], "sigma_schedule": ["SIGMA_SCHEDULE"], "image_inject": ["IMAGE_INJECT"], "ancestral_opts": ["ANCESTRAL_OPTS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen", "seed_offset"], "optional": ["noise_layers", "iteration_opts", "seed_override", "adapt_denoise_steps", "custom_cfg", "sigma_schedule", "image_inject", "ancestral_opts"], "hidden": ["autosize"]}, "output": ["SAMPLE_SETTINGS"], "output_is_list": [false], "output_name": ["settings"], "name": "ADE_AnimateDiffSamplingSettings", "display_name": "Sample Settings \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53", "output_node": false}, "ADE_AnimateDiffKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_ad_keyframes": ["AD_KEYFRAMES"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "per_block_replace": ["PER_BLOCK"], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_ad_keyframes", "scale_multival", "effect_multival", "per_block_replace", "inherit_missing", "guarantee_steps"], "hidden": ["autosize"]}, "output": ["AD_KEYFRAMES"], "output_is_list": [false], "output_name": ["AD_KEYFRAMES"], "name": "ADE_AnimateDiffKeyframe", "display_name": "AnimateDiff Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53", "output_node": false}, "ADE_MultivalDynamic": {"input": {"required": {"float_val": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["float_val"], "optional": ["mask_optional"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalDynamic", "display_name": "Multival \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalDynamicFloatInput": {"input": {"required": {"float_val": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001, "forceInput": true}]}, "optional": {"mask_optional": ["MASK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["float_val"], "optional": ["mask_optional"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalDynamicFloatInput", "display_name": "Multival [Float List] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalDynamicFloats": {"input": {"required": {"floats": ["FLOATS", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"mask_optional": ["MASK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["floats"], "optional": ["mask_optional"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalDynamicFloats", "display_name": "Multival [Floats] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalScaledMask": {"input": {"required": {"min_float_val": ["FLOAT", {"default": 0.0, "min": 0.0, "step": 0.001}], "max_float_val": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "mask": ["MASK"]}, "optional": {"scaling": [["absolute", "relative"]]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["min_float_val", "max_float_val", "mask"], "optional": ["scaling"], "hidden": ["autosize"]}, "output": ["MULTIVAL"], "output_is_list": [false], "output_name": ["MULTIVAL"], "name": "ADE_MultivalScaledMask", "display_name": "Multival Scaled Mask \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_MultivalConvertToMask": {"input": {"required": {"multival": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["multival"], "hidden": ["autosize"]}, "output": ["MASK"], "output_is_list": [false], "output_name": ["MASK"], "name": "ADE_MultivalConvertToMask", "display_name": "Multival to Mask \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/multival", "output_node": false}, "ADE_StandardStaticContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "relative", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"]}}, "input_order": {"required": ["context_length", "context_overlap"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_StandardStaticContextOptions", "display_name": "Context Options\u25c6Standard Static \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_StandardUniformContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"]}}, "input_order": {"required": ["context_length", "context_stride", "context_overlap"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_StandardUniformContextOptions", "display_name": "Context Options\u25c6Standard Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_LoopedUniformContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}], "closed_loop": ["BOOLEAN", {"default": false}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"]}}, "input_order": {"required": ["context_length", "context_stride", "context_overlap", "closed_loop"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_LoopedUniformContextOptions", "display_name": "Context Options\u25c6Looped Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_ViewsOnlyContextOptions": {"input": {"required": {"view_opts_req": ["VIEW_OPTS"]}, "optional": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["view_opts_req"], "optional": ["start_percent", "guarantee_steps", "prev_context"], "hidden": ["autosize"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_ViewsOnlyContextOptions", "display_name": "Context Options\u25c6Views Only [VRAM\u21c8] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_BatchedContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}]}, "optional": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"]}}, "input_order": {"required": ["context_length"], "optional": ["start_percent", "guarantee_steps", "prev_context"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_BatchedContextOptions", "display_name": "Context Options\u25c6Batched [Non-AD] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts", "output_node": false}, "ADE_AnimateDiffUniformContextOptions": {"input": {"required": {"context_length": ["INT", {"default": 16, "min": 1, "max": 128}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 128}], "context_schedule": [["uniform"]], "closed_loop": ["BOOLEAN", {"default": false}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"], {"default": "flat"}], "use_on_equal_length": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "prev_context": ["CONTEXT_OPTIONS"], "view_opts": ["VIEW_OPTS"], "deprecation_warning": ["ADEWARN", {"text": ""}]}}, "input_order": {"required": ["context_length", "context_stride", "context_overlap", "context_schedule", "closed_loop"], "optional": ["fuse_method", "use_on_equal_length", "start_percent", "guarantee_steps", "prev_context", "view_opts", "deprecation_warning"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_AnimateDiffUniformContextOptions", "display_name": "Context Options\u25c6Looped Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false}, "ADE_VisualizeContextOptionsK": {"input": {"required": {"model": ["MODEL"], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]]}, "optional": {"context_opts": ["CONTEXT_OPTIONS"], "visual_width": ["INT", {"min": 32, "max": 16384, "default": 1440}], "latents_length": ["INT", {"min": 1, "max": 9007199254740991, "default": 32}], "steps": ["INT", {"min": 0, "max": 9007199254740991, "default": 20}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}}, "input_order": {"required": ["model", "sampler_name", "scheduler"], "optional": ["context_opts", "visual_width", "latents_length", "steps", "denoise"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ADE_VisualizeContextOptionsK", "display_name": "Visualize Context Options (K.) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/visualize", "output_node": false}, "ADE_VisualizeContextOptionsKAdv": {"input": {"required": {"model": ["MODEL"], "sampler_name": [["euler", "euler_cfg_pp", "euler_ancestral", "euler_ancestral_cfg_pp", "heun", "heunpp2", "dpm_2", "dpm_2_ancestral", "lms", "dpm_fast", "dpm_adaptive", "dpmpp_2s_ancestral", "dpmpp_2s_ancestral_cfg_pp", "dpmpp_sde", "dpmpp_sde_gpu", "dpmpp_2m", "dpmpp_2m_cfg_pp", "dpmpp_2m_sde", "dpmpp_2m_sde_gpu", "dpmpp_2m_sde_heun", "dpmpp_2m_sde_heun_gpu", "dpmpp_3m_sde", "dpmpp_3m_sde_gpu", "ddpm", "lcm", "ipndm", "ipndm_v", "deis", "res_multistep", "res_multistep_cfg_pp", "res_multistep_ancestral", "res_multistep_ancestral_cfg_pp", "gradient_estimation", "gradient_estimation_cfg_pp", "er_sde", "seeds_2", "seeds_3", "sa_solver", "sa_solver_pece", "ddim", "uni_pc", "uni_pc_bh2"]], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]]}, "optional": {"context_opts": ["CONTEXT_OPTIONS"], "visual_width": ["INT", {"min": 32, "max": 16384, "default": 1440}], "latents_length": ["INT", {"min": 1, "max": 9007199254740991, "default": 32}], "steps": ["INT", {"min": 0, "max": 9007199254740991, "default": 20}], "start_step": ["INT", {"min": 0, "max": 9007199254740991, "default": 0}], "end_step": ["INT", {"min": 1, "max": 9007199254740991, "default": 20}]}}, "input_order": {"required": ["model", "sampler_name", "scheduler"], "optional": ["context_opts", "visual_width", "latents_length", "steps", "start_step", "end_step"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ADE_VisualizeContextOptionsKAdv", "display_name": "Visualize Context Options (K.Adv.) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/visualize", "output_node": false}, "ADE_VisualizeContextOptionsSCustom": {"input": {"required": {"model": ["MODEL"], "sigmas": ["SIGMAS"]}, "optional": {"context_opts": ["CONTEXT_OPTIONS"], "visual_width": ["INT", {"min": 32, "max": 16384, "default": 1440}], "latents_length": ["INT", {"min": 1, "max": 9007199254740991, "default": 32}]}}, "input_order": {"required": ["model", "sigmas"], "optional": ["context_opts", "visual_width", "latents_length"]}, "output": ["IMAGE"], "output_is_list": [false], "output_name": ["IMAGE"], "name": "ADE_VisualizeContextOptionsSCustom", "display_name": "Visualize Context Options (S.Cus.) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/visualize", "output_node": false}, "ADE_StandardStaticViewOptions": {"input": {"required": {"view_length": ["INT", {"default": 16, "min": 1, "max": 128}], "view_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]]}}, "input_order": {"required": ["view_length", "view_overlap"], "optional": ["fuse_method"]}, "output": ["VIEW_OPTS"], "output_is_list": [false], "output_name": ["VIEW_OPTS"], "name": "ADE_StandardStaticViewOptions", "display_name": "View Options\u25c6Standard Static \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/view opts", "output_node": false}, "ADE_StandardUniformViewOptions": {"input": {"required": {"view_length": ["INT", {"default": 16, "min": 1, "max": 128}], "view_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "view_overlap": ["INT", {"default": 4, "min": 0, "max": 128}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]]}}, "input_order": {"required": ["view_length", "view_stride", "view_overlap"], "optional": ["fuse_method"]}, "output": ["VIEW_OPTS"], "output_is_list": [false], "output_name": ["VIEW_OPTS"], "name": "ADE_StandardUniformViewOptions", "display_name": "View Options\u25c6Standard Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/view opts", "output_node": false}, "ADE_LoopedUniformViewOptions": {"input": {"required": {"view_length": ["INT", {"default": 16, "min": 1, "max": 128}], "view_stride": ["INT", {"default": 1, "min": 1, "max": 32}], "view_overlap": ["INT", {"default": 4, "min": 0, "max": 128}], "closed_loop": ["BOOLEAN", {"default": false}]}, "optional": {"fuse_method": [["pyramid", "flat", "overlap-linear", "\ud83d\udd2cdelayed reverse sawtooth", "\ud83d\udd2cpyramid-sigma", "\ud83d\udd2cpyramid-sigma inverse", "\ud83d\udd2cgauss-sigma", "\ud83d\udd2cgauss-sigma inverse", "\ud83d\udd2crandom"]], "use_on_equal_length": ["BOOLEAN", {"default": false}]}}, "input_order": {"required": ["view_length", "view_stride", "view_overlap", "closed_loop"], "optional": ["fuse_method", "use_on_equal_length"]}, "output": ["VIEW_OPTS"], "output_is_list": [false], "output_name": ["VIEW_OPTS"], "name": "ADE_LoopedUniformViewOptions", "display_name": "View Options\u25c6Looped Uniform \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/view opts", "output_node": false}, "ADE_ContextExtras_Set": {"input": {"required": {"context_opts": ["CONTEXT_OPTIONS"]}, "optional": {"context_extras": ["CONTEXT_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["context_opts"], "optional": ["context_extras"], "hidden": ["autosize"]}, "output": ["CONTEXT_OPTIONS"], "output_is_list": [false], "output_name": ["CONTEXT_OPTS"], "name": "ADE_ContextExtras_Set", "display_name": "Set Context Extras \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras", "output_node": false}, "ADE_ContextExtras_ContextRef": {"input": {"required": {}, "optional": {"prev_extras": ["CONTEXT_EXTRAS"], "strength_multival": ["MULTIVAL"], "contextref_mode": ["CONTEXTREF_MODE"], "contextref_tune": ["CONTEXTREF_TUNE"], "contextref_kf": ["CONTEXTREF_KEYFRAME"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_extras", "strength_multival", "contextref_mode", "contextref_tune", "contextref_kf", "start_percent", "end_percent"], "hidden": ["autosize"]}, "output": ["CONTEXT_EXTRAS"], "output_is_list": [false], "output_name": ["CONTEXT_EXTRAS"], "name": "ADE_ContextExtras_ContextRef", "display_name": "Context Extras\u25c6ContextRef \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras", "output_node": false}, "ADE_ContextExtras_ContextRef_ModeFirst": {"input": {"required": {}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "hidden": ["autosize"]}, "output": ["CONTEXTREF_MODE"], "output_is_list": [false], "output_name": ["CONTEXTREF_MODE"], "name": "ADE_ContextExtras_ContextRef_ModeFirst", "display_name": "ContextRef Mode\u25c6First \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_ModeSliding": {"input": {"required": {}, "optional": {"sliding_width": ["INT", {"default": 2, "min": 2, "max": 9007199254740991, "step": 1}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["sliding_width"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_MODE"], "output_is_list": [false], "output_name": ["CONTEXTREF_MODE"], "name": "ADE_ContextExtras_ContextRef_ModeSliding", "display_name": "ContextRef Mode\u25c6Sliding \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_ModeIndexes": {"input": {"required": {}, "optional": {"switch_on_idxs": ["STRING", {"default": ""}], "always_include_0": ["BOOLEAN", {"default": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["switch_on_idxs", "always_include_0"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_MODE"], "output_is_list": [false], "output_name": ["CONTEXTREF_MODE"], "name": "ADE_ContextExtras_ContextRef_ModeIndexes", "display_name": "ContextRef Mode\u25c6Indexes \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_TuneAttn": {"input": {"required": {}, "optional": {"attn_style_fidelity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["attn_style_fidelity", "attn_ref_weight", "attn_strength"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_TUNE"], "output_is_list": [false], "output_name": ["CONTEXTREF_TUNE"], "name": "ADE_ContextExtras_ContextRef_TuneAttn", "display_name": "ContextRef Tune\u25c6Attn \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_TuneAttnAdain": {"input": {"required": {}, "optional": {"attn_style_fidelity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_style_fidelity": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_ref_weight": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}], "adain_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["attn_style_fidelity", "attn_ref_weight", "attn_strength", "adain_style_fidelity", "adain_ref_weight", "adain_strength"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_TUNE"], "output_is_list": [false], "output_name": ["CONTEXTREF_TUNE"], "name": "ADE_ContextExtras_ContextRef_TuneAttnAdain", "display_name": "ContextRef Tune\u25c6Attn+Adain \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_Keyframe": {"input": {"required": {}, "optional": {"prev_kf": ["CONTEXTREF_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mode_replace": ["CONTEXTREF_MODE"], "tune_replace": ["CONTEXTREF_TUNE"], "mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "inherit_missing": ["BOOLEAN", {"default": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_kf", "mult_multival", "mode_replace", "tune_replace", "mult", "start_percent", "guarantee_steps", "inherit_missing"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_KEYFRAME"], "output_is_list": [false], "output_name": ["CONTEXTREF_KF"], "name": "ADE_ContextExtras_ContextRef_Keyframe", "display_name": "ContextRef Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_KeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["CONTEXTREF_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mode_replace": ["CONTEXTREF_MODE"], "tune_replace": ["CONTEXTREF_TUNE"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "mult_start", "mult_end", "interpolation", "intervals", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival", "mode_replace", "tune_replace"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_KEYFRAME"], "output_is_list": [false], "output_name": ["CONTEXTREF_KF"], "name": "ADE_ContextExtras_ContextRef_KeyframeInterpolation", "display_name": "ContextRef Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_ContextRef_KeyframeFromList": {"input": {"required": {"mults_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["CONTEXTREF_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mode_replace": ["CONTEXTREF_MODE"], "tune_replace": ["CONTEXTREF_TUNE"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["mults_float", "start_percent", "end_percent", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival", "mode_replace", "tune_replace"], "hidden": ["autosize"]}, "output": ["CONTEXTREF_KEYFRAME"], "output_is_list": [false], "output_name": ["CONTEXTREF_KF"], "name": "ADE_ContextExtras_ContextRef_KeyframeFromList", "display_name": "ContextRef Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/contextref", "output_node": false}, "ADE_ContextExtras_NaiveReuse": {"input": {"required": {}, "optional": {"prev_extras": ["CONTEXT_EXTRAS"], "strength_multival": ["MULTIVAL"], "naivereuse_kf": ["NAIVEREUSE_KEYFRAME"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 0.15, "min": 0.0, "max": 1.0, "step": 0.001}], "weighted_mean": ["FLOAT", {"default": 0.95, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_extras", "strength_multival", "naivereuse_kf", "start_percent", "end_percent", "weighted_mean"], "hidden": ["autosize"]}, "output": ["CONTEXT_EXTRAS"], "output_is_list": [false], "output_name": ["CONTEXT_EXTRAS"], "name": "ADE_ContextExtras_NaiveReuse", "display_name": "Context Extras\u25c6NaiveReuse \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras", "output_node": false}, "ADE_ContextExtras_NaiveReuse_Keyframe": {"input": {"required": {}, "optional": {"prev_kf": ["NAIVEREUSE_KEYFRAME"], "mult_multival": ["MULTIVAL"], "mult": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}], "inherit_missing": ["BOOLEAN", {"default": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["prev_kf", "mult_multival", "mult", "start_percent", "guarantee_steps", "inherit_missing"], "hidden": ["autosize"]}, "output": ["NAIVEREUSE_KEYFRAME"], "output_is_list": [false], "output_name": ["NAIVEREUSE_KF"], "name": "ADE_ContextExtras_NaiveReuse_Keyframe", "display_name": "NaiveReuse Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/naivereuse", "output_node": false}, "ADE_ContextExtras_NaiveReuse_KeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "mult_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["NAIVEREUSE_KEYFRAME"], "mult_multival": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "mult_start", "mult_end", "interpolation", "intervals", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival"], "hidden": ["autosize"]}, "output": ["NAIVEREUSE_KEYFRAME"], "output_is_list": [false], "output_name": ["NAIVEREUSE_KF"], "name": "ADE_ContextExtras_NaiveReuse_KeyframeInterpolation", "display_name": "NaiveReuse Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/naivereuse", "output_node": false}, "ADE_ContextExtras_NaiveReuse_KeyframeFromList": {"input": {"required": {"mults_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "inherit_missing": ["BOOLEAN", {"default": true}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_kf": ["NAIVEREUSE_KEYFRAME"], "mult_multival": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["mults_float", "start_percent", "end_percent", "inherit_missing", "print_keyframes"], "optional": ["prev_kf", "mult_multival"], "hidden": ["autosize"]}, "output": ["NAIVEREUSE_KEYFRAME"], "output_is_list": [false], "output_name": ["NAIVEREUSE_KF"], "name": "ADE_ContextExtras_NaiveReuse_KeyframeFromList", "display_name": "NaiveReuse Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/context opts/context extras/naivereuse", "output_node": false}, "ADE_IterationOptsDefault": {"input": {"required": {"iterations": ["INT", {"default": 1, "min": 1}]}, "optional": {"iter_batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "iter_seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}}, "input_order": {"required": ["iterations"], "optional": ["iter_batch_offset", "iter_seed_offset"]}, "output": ["ITERATION_OPTS"], "output_is_list": [false], "output_name": ["ITERATION_OPTS"], "name": "ADE_IterationOptsDefault", "display_name": "Default Iteration Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/iteration opts", "output_node": false}, "ADE_IterationOptsFreeInit": {"input": {"required": {"iterations": ["INT", {"default": 2, "min": 1}], "filter": [["gaussian", "butterworth", "ideal", "box"]], "d_s": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.001}], "d_t": ["FLOAT", {"default": 0.25, "min": 0.0, "max": 1.0, "step": 0.001}], "n_butterworth": ["INT", {"default": 4, "min": 1, "max": 100}], "sigma_step": ["INT", {"default": 999, "min": 1, "max": 999}], "apply_to_1st_iter": ["BOOLEAN", {"default": false}], "init_type": [["FreeInit [sampler sigma]", "FreeInit [model sigma]", "DinkInit_v1"]]}, "optional": {"iter_batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "iter_seed_offset": ["INT", {"default": 1, "min": -9007199254740991, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["iterations", "filter", "d_s", "d_t", "n_butterworth", "sigma_step", "apply_to_1st_iter", "init_type"], "optional": ["iter_batch_offset", "iter_seed_offset"], "hidden": ["autosize"]}, "output": ["ITERATION_OPTS"], "output_is_list": [false], "output_name": ["ITERATION_OPTS"], "name": "ADE_IterationOptsFreeInit", "display_name": "FreeInit Iteration Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/iteration opts", "output_node": false}, "ADE_RegisterLoraHook": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "lora_name": [[]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "clip", "lora_name", "strength_model", "strength_clip"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "CLIP", "HOOKS"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "HOOKS"], "name": "ADE_RegisterLoraHook", "display_name": "Register LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true}, "ADE_RegisterLoraHookModelOnly": {"input": {"required": {"model": ["MODEL"], "lora_name": [[]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "lora_name", "strength_model"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "HOOKS"], "output_is_list": [false, false], "output_name": ["MODEL", "HOOKS"], "name": "ADE_RegisterLoraHookModelOnly", "display_name": "Register LoRA Hook (Model Only) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true}, "ADE_RegisterModelAsLoraHook": {"input": {"required": {"model": ["MODEL"], "clip": ["CLIP"], "ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "strength_clip": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "clip", "ckpt_name", "strength_model", "strength_clip"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "CLIP", "HOOKS"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "HOOKS"], "name": "ADE_RegisterModelAsLoraHook", "display_name": "Register Model as LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true, "experimental": true}, "ADE_RegisterModelAsLoraHookModelOnly": {"input": {"required": {"model": ["MODEL"], "ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]], "strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["model", "ckpt_name", "strength_model"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "HOOKS"], "output_is_list": [false, false], "output_name": ["MODEL", "HOOKS"], "name": "ADE_RegisterModelAsLoraHookModelOnly", "display_name": "Register Model as LoRA Hook (MO) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/register lora hooks", "output_node": false, "deprecated": true, "experimental": true}, "ADE_CombineLoraHooks": {"input": {"required": {}, "optional": {"lora_hook_A": ["HOOKS"], "lora_hook_B": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["lora_hook_A", "lora_hook_B", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_CombineLoraHooks", "display_name": "Combine LoRA Hooks [2] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/combine lora hooks", "output_node": false, "deprecated": true}, "ADE_CombineLoraHooksFour": {"input": {"required": {}, "optional": {"lora_hook_A": ["HOOKS"], "lora_hook_B": ["HOOKS"], "lora_hook_C": ["HOOKS"], "lora_hook_D": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["lora_hook_A", "lora_hook_B", "lora_hook_C", "lora_hook_D", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_CombineLoraHooksFour", "display_name": "Combine LoRA Hooks [4] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/combine lora hooks", "output_node": false, "deprecated": true}, "ADE_CombineLoraHooksEight": {"input": {"required": {}, "optional": {"lora_hook_A": ["HOOKS"], "lora_hook_B": ["HOOKS"], "lora_hook_C": ["HOOKS"], "lora_hook_D": ["HOOKS"], "lora_hook_E": ["HOOKS"], "lora_hook_F": ["HOOKS"], "lora_hook_G": ["HOOKS"], "lora_hook_H": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["lora_hook_A", "lora_hook_B", "lora_hook_C", "lora_hook_D", "lora_hook_E", "lora_hook_F", "lora_hook_G", "lora_hook_H", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_CombineLoraHooksEight", "display_name": "Combine LoRA Hooks [8] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/combine lora hooks", "output_node": false, "deprecated": true}, "ADE_SetLoraHookKeyframe": {"input": {"required": {"lora_hook": ["HOOKS"], "hook_kf": ["HOOK_KEYFRAMES"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["lora_hook", "hook_kf"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOKS"], "output_is_list": [false], "output_name": ["HOOKS"], "name": "ADE_SetLoraHookKeyframe", "display_name": "Set LoRA Hook Keyframes \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_AttachLoraHookToCLIP": {"input": {"required": {"clip": ["CLIP"], "lora_hook": ["HOOKS"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["clip", "lora_hook"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["CLIP"], "output_is_list": [false], "output_name": ["hook_CLIP"], "name": "ADE_AttachLoraHookToCLIP", "display_name": "Set CLIP LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_LoraHookKeyframe": {"input": {"required": {"strength_model": ["FLOAT", {"default": 1.0, "min": -20.0, "max": 20.0, "step": 0.01}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["strength_model", "start_percent", "guarantee_steps"], "optional": ["prev_hook_kf", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "ADE_LoraHookKeyframe", "display_name": "LoRA Hook Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/schedule lora hooks", "output_node": false, "deprecated": true}, "ADE_LoraHookKeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "strength_start": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "strength_end": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 5, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "strength_start", "strength_end", "interpolation", "intervals", "print_keyframes"], "optional": ["prev_hook_kf", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "ADE_LoraHookKeyframeInterpolation", "display_name": "LoRA Hook Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/schedule lora hooks", "output_node": false, "deprecated": true}, "ADE_LoraHookKeyframeFromStrengthList": {"input": {"required": {"strengths_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_hook_kf": ["HOOK_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["strengths_float", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_hook_kf", "deprecation_warning"]}, "output": ["HOOK_KEYFRAMES"], "output_is_list": [false], "output_name": ["HOOK_KF"], "name": "ADE_LoraHookKeyframeFromStrengthList", "display_name": "LoRA Hook Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/schedule lora hooks", "output_node": false, "deprecated": true}, "ADE_AttachLoraHookToConditioning": {"input": {"required": {"conditioning": ["CONDITIONING"], "lora_hook": ["HOOKS"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["conditioning", "lora_hook"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_AttachLoraHookToConditioning", "display_name": "Set Model LoRA Hook \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningSetMask": {"input": {"required": {"positive_ADD": ["CONDITIONING"], "negative_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive_ADD", "negative_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningSetMask", "display_name": "Set Props on Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningSetMask": {"input": {"required": {"cond_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cond_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningSetMask", "display_name": "Set Props on Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningSetMaskAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_ADD": ["CONDITIONING"], "negative_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive", "negative", "positive_ADD", "negative_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningSetMaskAndCombine", "display_name": "Set Props and Combine Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningSetMaskAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_ADD": ["CONDITIONING"], "strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "set_cond_area": [["default", "mask bounds"]]}, "optional": {"opt_mask": ["MASK"], "opt_lora_hook": ["HOOKS"], "opt_timesteps": ["TIMESTEPS_RANGE"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cond", "cond_ADD", "strength", "set_cond_area"], "optional": ["opt_mask", "opt_lora_hook", "opt_timesteps", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningSetMaskAndCombine", "display_name": "Set Props and Combine Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningSetUnmaskedAndCombine": {"input": {"required": {"positive": ["CONDITIONING"], "negative": ["CONDITIONING"], "positive_DEFAULT": ["CONDITIONING"], "negative_DEFAULT": ["CONDITIONING"]}, "optional": {"opt_lora_hook": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["positive", "negative", "positive_DEFAULT", "negative_DEFAULT"], "optional": ["opt_lora_hook", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningSetUnmaskedAndCombine", "display_name": "Set Unmasked Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningSetUnmaskedAndCombine": {"input": {"required": {"cond": ["CONDITIONING"], "cond_DEFAULT": ["CONDITIONING"]}, "optional": {"opt_lora_hook": ["HOOKS"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cond", "cond_DEFAULT"], "optional": ["opt_lora_hook", "deprecation_warning"], "hidden": ["autosize"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningSetUnmaskedAndCombine", "display_name": "Set Unmasked Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_PairedConditioningCombine": {"input": {"required": {"positive_A": ["CONDITIONING"], "negative_A": ["CONDITIONING"], "positive_B": ["CONDITIONING"], "negative_B": ["CONDITIONING"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["positive_A", "negative_A", "positive_B", "negative_B"], "optional": ["deprecation_warning"]}, "output": ["CONDITIONING", "CONDITIONING"], "output_is_list": [false, false], "output_name": ["positive", "negative"], "name": "ADE_PairedConditioningCombine", "display_name": "Manual Combine Conds \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_ConditioningCombine": {"input": {"required": {"cond_A": ["CONDITIONING"], "cond_B": ["CONDITIONING"]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}}, "input_order": {"required": ["cond_A", "cond_B"], "optional": ["deprecation_warning"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditioningCombine", "display_name": "Manual Combine Cond \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning/single cond ops", "output_node": false, "deprecated": true}, "ADE_TimestepsConditioning": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated - use native ComfyUI nodes instead."}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent"], "optional": ["deprecation_warning"], "hidden": ["autosize"]}, "output": ["TIMESTEPS_RANGE"], "output_is_list": [false], "output_name": ["TIMESTEPS_RANGE"], "name": "ADE_TimestepsConditioning", "display_name": "Timesteps Conditioning \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/conditioning", "output_node": false, "deprecated": true}, "ADE_NoiseLayerAdd": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}], "noise_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.001}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset", "noise_weight"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerAdd", "display_name": "Noise Layer [Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_NoiseLayerAddWeighted": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}], "noise_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 10.0, "step": 0.001}], "balance_multiplier": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset", "noise_weight", "balance_multiplier"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerAddWeighted", "display_name": "Noise Layer [Add Weighted] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_NoiseLayerNormalizedSum": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}], "noise_weight": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset", "noise_weight"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerNormalizedSum", "display_name": "Noise Layer [Normalized Sum] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_NoiseLayerReplace": {"input": {"required": {"batch_offset": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "noise_type": [["default", "constant", "empty", "repeated_context", "FreeNoise"]], "seed_gen_override": [["use existing", "comfy", "comfy [gpu]", "auto1111", "auto1111 [gpu]"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}, "optional": {"prev_noise_layers": ["NOISE_LAYERS"], "mask_optional": ["MASK"], "seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["batch_offset", "noise_type", "seed_gen_override", "seed_offset"], "optional": ["prev_noise_layers", "mask_optional", "seed_override"], "hidden": ["autosize"]}, "output": ["NOISE_LAYERS"], "output_is_list": [false], "output_name": ["NOISE_LAYERS"], "name": "ADE_NoiseLayerReplace", "display_name": "Noise Layer [Replace] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/noise layers", "output_node": false}, "ADE_AnimateDiffSettings": {"input": {"optional": {"pe_adjust": ["PE_ADJUST"], "weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"optional": ["pe_adjust", "weight_adjust"], "hidden": ["autosize"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffSettings", "display_name": "AnimateDiff Settings \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings", "output_node": false}, "ADE_AdjustPESweetspotStretch": {"input": {"required": {"sweetspot": ["INT", {"default": 16, "min": 0, "max": 9007199254740991}], "new_sweetspot": ["INT", {"default": 16, "min": 0, "max": 9007199254740991}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_pe_adjust": ["PE_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["sweetspot", "new_sweetspot", "print_adjustment"], "optional": ["prev_pe_adjust"], "hidden": ["autosize"]}, "output": ["PE_ADJUST"], "output_is_list": [false], "output_name": ["PE_ADJUST"], "name": "ADE_AdjustPESweetspotStretch", "display_name": "Adjust PE [Sweetspot] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/pe adjust", "output_node": false}, "ADE_AdjustPEFullStretch": {"input": {"required": {"pe_stretch": ["INT", {"default": 0, "min": 0, "max": 9007199254740991}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_pe_adjust": ["PE_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_stretch", "print_adjustment"], "optional": ["prev_pe_adjust"], "hidden": ["autosize"]}, "output": ["PE_ADJUST"], "output_is_list": [false], "output_name": ["PE_ADJUST"], "name": "ADE_AdjustPEFullStretch", "display_name": "Adjust PE [Full Stretch] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/pe adjust", "output_node": false}, "ADE_AdjustPEManual": {"input": {"required": {"cap_initial_pe_length": ["INT", {"default": 0, "min": 0, "step": 1}], "interpolate_pe_to_length": ["INT", {"default": 0, "min": 0, "step": 1}], "initial_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "final_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_pe_adjust": ["PE_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cap_initial_pe_length", "interpolate_pe_to_length", "initial_pe_idx_offset", "final_pe_idx_offset", "print_adjustment"], "optional": ["prev_pe_adjust"], "hidden": ["autosize"]}, "output": ["PE_ADJUST"], "output_is_list": [false], "output_name": ["PE_ADJUST"], "name": "ADE_AdjustPEManual", "display_name": "Adjust PE [Manual] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/pe adjust", "output_node": false}, "ADE_AdjustWeightAllAdd": {"input": {"required": {"all_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["all_ADD", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightAllAdd", "display_name": "Adjust Weight [All\u25c6Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightAllMult": {"input": {"required": {"all_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["all_MULT", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightAllMult", "display_name": "Adjust Weight [All\u25c6Mult] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivAdd": {"input": {"required": {"pe_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "other_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_ADD", "attn_ADD", "other_ADD", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivAdd", "display_name": "Adjust Weight [Indiv\u25c6Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivMult": {"input": {"required": {"pe_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "other_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_MULT", "attn_MULT", "other_MULT", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivMult", "display_name": "Adjust Weight [Indiv\u25c6Mult] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivAttnAdd": {"input": {"required": {"pe_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_q_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_k_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_v_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_out_weight_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "attn_out_bias_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "other_ADD": ["FLOAT", {"default": 0.0, "min": -2.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_ADD", "attn_ADD", "attn_q_ADD", "attn_k_ADD", "attn_v_ADD", "attn_out_weight_ADD", "attn_out_bias_ADD", "other_ADD", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivAttnAdd", "display_name": "Adjust Weight [Indiv-Attn\u25c6Add] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_AdjustWeightIndivAttnMult": {"input": {"required": {"pe_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_q_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_k_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_v_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_out_weight_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "attn_out_bias_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "other_MULT": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 2.0, "step": 1e-06}], "print_adjustment": ["BOOLEAN", {"default": false}]}, "optional": {"prev_weight_adjust": ["WEIGHT_ADJUST"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["pe_MULT", "attn_MULT", "attn_q_MULT", "attn_k_MULT", "attn_v_MULT", "attn_out_weight_MULT", "attn_out_bias_MULT", "other_MULT", "print_adjustment"], "optional": ["prev_weight_adjust"], "hidden": ["autosize"]}, "output": ["WEIGHT_ADJUST"], "output_is_list": [false], "output_name": ["WEIGHT_ADJUST"], "name": "ADE_AdjustWeightIndivAttnMult", "display_name": "Adjust Weight [Indiv-Attn\u25c6Mult] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/ad settings/weight adjust", "output_node": false}, "ADE_CustomCFGSimple": {"input": {"required": {"cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}]}, "optional": {"cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cfg"], "optional": ["cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGSimple", "display_name": "Custom CFG \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFG": {"input": {"required": {"cfg_multival": ["MULTIVAL"]}, "optional": {"cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cfg_multival"], "optional": ["cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFG", "display_name": "Custom CFG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframeSimple": {"input": {"required": {"cfg": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 10}]}}, "input_order": {"required": ["cfg", "start_percent", "guarantee_steps"], "optional": ["prev_custom_cfg", "cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframeSimple", "display_name": "Custom CFG Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframe": {"input": {"required": {"cfg_multival": ["MULTIVAL"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["cfg_multival", "start_percent", "guarantee_steps"], "optional": ["prev_custom_cfg", "cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframe", "display_name": "Custom CFG Keyframe [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframeInterpolation": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "cfg_start": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}], "cfg_end": ["FLOAT", {"default": 8.0, "min": 0.0, "max": 100.0, "step": 0.1}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]], "intervals": ["INT", {"default": 50, "min": 2, "max": 100, "step": 1}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent", "end_percent", "cfg_start", "cfg_end", "interpolation", "intervals", "print_keyframes"], "optional": ["prev_custom_cfg", "cfg_extras"], "hidden": ["autosize"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframeInterpolation", "display_name": "Custom CFG Keyframes Interp. \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CustomCFGKeyframeFromList": {"input": {"required": {"cfgs_float": ["FLOAT", {"default": -1, "min": -1, "step": 0.001, "forceInput": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}], "print_keyframes": ["BOOLEAN", {"default": false}]}, "optional": {"prev_custom_cfg": ["CUSTOM_CFG"], "cfg_extras": ["CFG_EXTRAS"]}}, "input_order": {"required": ["cfgs_float", "start_percent", "end_percent", "print_keyframes"], "optional": ["prev_custom_cfg", "cfg_extras"]}, "output": ["CUSTOM_CFG"], "output_is_list": [false], "output_name": ["CUSTOM_CFG"], "name": "ADE_CustomCFGKeyframeFromList", "display_name": "Custom CFG Keyframes From List \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/custom cfg", "output_node": false}, "ADE_CFGExtrasPAGSimple": {"input": {"required": {"scale": ["FLOAT", {"default": 3.0, "min": 0.0, "max": 100.0, "step": 0.1, "round": 0.01}]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["scale"], "optional": ["prev_extras"], "hidden": ["autosize"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasPAGSimple", "display_name": "CFG Extras\u25c6PAG \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_CFGExtrasPAG": {"input": {"required": {"scale_multival": ["MULTIVAL"]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["scale_multival"], "optional": ["prev_extras"], "hidden": ["autosize"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasPAG", "display_name": "CFG Extras\u25c6PAG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_CFGExtrasRescaleCFGSimple": {"input": {"required": {"multiplier": ["FLOAT", {"default": 0.7, "min": 0.0, "max": 1.0, "step": 0.01}]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 10}]}}, "input_order": {"required": ["multiplier"], "optional": ["prev_extras"], "hidden": ["autosize"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasRescaleCFGSimple", "display_name": "CFG Extras\u25c6RescaleCFG \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_CFGExtrasRescaleCFG": {"input": {"required": {"mult_multival": ["MULTIVAL"]}, "optional": {"prev_extras": ["CFG_EXTRAS"]}}, "input_order": {"required": ["mult_multival"], "optional": ["prev_extras"]}, "output": ["CFG_EXTRAS"], "output_is_list": [false], "output_name": ["CFG_EXTRAS"], "name": "ADE_CFGExtrasRescaleCFG", "display_name": "CFG Extras\u25c6RescaleCFG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/cfg extras", "output_node": false}, "ADE_SigmaSchedule": {"input": {"required": {"beta_schedule": [["sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]]}}, "input_order": {"required": ["beta_schedule"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaSchedule", "display_name": "Create Sigma Schedule \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_RawSigmaSchedule": {"input": {"required": {"raw_beta_schedule": [["linear", "sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]], "linear_start": ["FLOAT", {"default": 0.00085, "min": 0.0, "max": 1.0, "step": 1e-06}], "linear_end": ["FLOAT", {"default": 0.012, "min": 0.0, "max": 1.0, "step": 1e-06}], "sampling": [["eps", "v_prediction", "lcm"]], "lcm_original_timesteps": ["INT", {"default": 50, "min": 1, "max": 1000}], "zsnr": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["raw_beta_schedule", "linear_start", "linear_end", "sampling", "lcm_original_timesteps", "zsnr"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_RawSigmaSchedule", "display_name": "Create Raw Sigma Schedule \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleWeightedAverage": {"input": {"required": {"schedule_A": ["SIGMA_SCHEDULE"], "schedule_B": ["SIGMA_SCHEDULE"], "weight_A": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["schedule_A", "schedule_B", "weight_A"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaScheduleWeightedAverage", "display_name": "Sigma Schedule Weighted Mean \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleWeightedAverageInterp": {"input": {"required": {"schedule_A": ["SIGMA_SCHEDULE"], "schedule_B": ["SIGMA_SCHEDULE"], "weight_A_Start": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}], "weight_A_End": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}], "interpolation": [["linear", "ease_in", "ease_out", "ease_in_out"]]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["schedule_A", "schedule_B", "weight_A_Start", "weight_A_End", "interpolation"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaScheduleWeightedAverageInterp", "display_name": "Sigma Schedule Interp. Mean \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleSplitAndCombine": {"input": {"required": {"schedule_Start": ["SIGMA_SCHEDULE"], "schedule_End": ["SIGMA_SCHEDULE"], "idx_split_percent": ["FLOAT", {"default": 0.5, "min": 0.0, "max": 1.0, "step": 0.001}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["schedule_Start", "schedule_End", "idx_split_percent"], "hidden": ["autosize"]}, "output": ["SIGMA_SCHEDULE"], "output_is_list": [false], "output_name": ["SIGMA_SCHEDULE"], "name": "ADE_SigmaScheduleSplitAndCombine", "display_name": "Sigma Schedule Split Combine \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_SigmaScheduleToSigmas": {"input": {"required": {"sigma_schedule": ["SIGMA_SCHEDULE"], "scheduler": [["simple", "sgm_uniform", "karras", "exponential", "ddim_uniform", "beta", "normal", "linear_quadratic", "kl_optimal"]], "steps": ["INT", {"default": 20, "min": 1, "max": 10000}], "denoise": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.01}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["sigma_schedule", "scheduler", "steps", "denoise"], "hidden": ["autosize"]}, "output": ["SIGMAS"], "output_is_list": [false], "output_name": ["SIGMAS"], "name": "ADE_SigmaScheduleToSigmas", "display_name": "Sigma Schedule To Sigmas \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/sigma schedule", "output_node": false}, "ADE_NoisedImageInjection": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"]}, "optional": {"mask_opt": ["MASK"], "invert_mask": ["BOOLEAN", {"default": false}], "resize_image": ["BOOLEAN", {"default": true}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "guarantee_steps": ["INT", {"default": 1, "min": 1, "max": 9007199254740991}], "img_inject_opts": ["IMAGE_INJECT_OPTIONS"], "strength_multival": ["MULTIVAL"], "prev_image_inject": ["IMAGE_INJECT"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["image", "vae"], "optional": ["mask_opt", "invert_mask", "resize_image", "start_percent", "guarantee_steps", "img_inject_opts", "strength_multival", "prev_image_inject"], "hidden": ["autosize"]}, "output": ["IMAGE_INJECT"], "output_is_list": [false], "output_name": ["IMAGE_INJECT"], "name": "ADE_NoisedImageInjection", "display_name": "Image Injection \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/image inject", "output_node": false}, "ADE_NoisedImageInjectOptions": {"input": {"required": {}, "optional": {"composite_x": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}], "composite_y": ["INT", {"default": 0, "min": 0, "max": 16384, "step": 1}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["composite_x", "composite_y"], "hidden": ["autosize"]}, "output": ["IMAGE_INJECT_OPTIONS"], "output_is_list": [false], "output_name": ["IMG_INJECT_OPTS"], "name": "ADE_NoisedImageInjectOptions", "display_name": "Image Injection Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings/image inject", "output_node": false}, "ADE_AncestralOptions": {"input": {"required": {"noise_type": [["default", "constant"]], "seed_offset": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991}]}, "optional": {"seed_override": ["INT", {"default": 0, "min": 0, "max": 18446744073709551615, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["noise_type", "seed_offset"], "optional": ["seed_override"], "hidden": ["autosize"]}, "output": ["ANCESTRAL_OPTS"], "output_is_list": [false], "output_name": ["ANCESTRAL_OPTS"], "name": "ADE_AncestralOptions", "display_name": "Ancestral Options \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/sample settings", "output_node": false}, "ADE_PromptScheduling": {"input": {"required": {"prompts": ["STRING", {"multiline": true, "default": ""}], "clip": ["CLIP"]}, "optional": {"prepend_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "append_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "values_replace": ["VALUES_REPLACE"], "print_schedule": ["BOOLEAN", {"default": false}], "max_length": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}], "tensor_interp": [["lerp", "slerp"]]}}, "input_order": {"required": ["prompts", "clip"], "optional": ["prepend_text", "append_text", "values_replace", "print_schedule", "max_length", "tensor_interp"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_PromptScheduling", "display_name": "Prompt Scheduling \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Encode a schedule of prompts with automatic interpolation.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": \"your prompt here\", ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = \"your prompt here\", ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The prompts themselves should be surrounded by double quotes (\"your prompt here\"). Portions of prompts can use value schedules provided values_replace.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": \"blue rock on mountain\",</div><div>\"16\": \"green rock in lake\"</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = \"blue rock on mountain\",</div><div>16 = \"green rock in lake\"</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"prompts\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prompts: Write your prompts here.</div></div><div vhs_title=\"clip\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">clip: CLIP to use for encoding prompts.</div></div><div vhs_title=\"values_replace\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values_replace: OPTIONAL, replaces keys from value_replace keys with provided value schedules. Keys in the prompt are written as `some_key`, surrounded by the ` characters.</div></div><div vhs_title=\"prepend_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prepend_text: OPTIONAL, adds text before all prompts.</div></div><div vhs_title=\"append_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">append_text: OPTIONAL, adds text after all prompts.</div></div><div vhs_title=\"max_length\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">max_length: Used to select the intended length of schedule. If set to 0, will use the largest index in the schedule as max_length, but will disable relative indexes (negative and decimal).</div></div><div vhs_title=\"tensor_interp\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">tensor_interp: Selects method of interpolating prompt conds - defaults to lerp.</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div><div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"CONDITIONING\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">CONDITIONING: Encoded prompts.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_PromptSchedulingLatents": {"input": {"required": {"prompts": ["STRING", {"multiline": true, "default": ""}], "clip": ["CLIP"], "latent": ["LATENT"]}, "optional": {"prepend_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "append_text": ["STRING", {"multiline": true, "default": "", "forceInput": true}], "values_replace": ["VALUES_REPLACE"], "print_schedule": ["BOOLEAN", {"default": false}], "tensor_interp": [["lerp", "slerp"]]}}, "input_order": {"required": ["prompts", "clip", "latent"], "optional": ["prepend_text", "append_text", "values_replace", "print_schedule", "tensor_interp"]}, "output": ["CONDITIONING", "LATENT"], "output_is_list": [false, false], "output_name": ["CONDITIONING", "LATENT"], "name": "ADE_PromptSchedulingLatents", "display_name": "Prompt Scheduling [Latents] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Encode a schedule of prompts with automatic interpolation, its length matching passed-in latent count.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": \"your prompt here\", ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = \"your prompt here\", ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The prompts themselves should be surrounded by double quotes (\"your prompt here\"). Portions of prompts can use value schedules provided values_replace.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": \"blue rock on mountain\",</div><div>\"16\": \"green rock in lake\"</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = \"blue rock on mountain\",</div><div>16 = \"green rock in lake\"</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"prompts\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prompts: Write your prompts here.</div></div><div vhs_title=\"clip\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">clip: CLIP to use for encoding prompts.</div></div><div vhs_title=\"latent\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latent: Used to get the amount of frames (max_length) to use for scheduling.</div></div><div vhs_title=\"values_replace\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values_replace: OPTIONAL, replaces keys from value_replace keys with provided value schedules. Keys in the prompt are written as `some_key`, surrounded by the ` characters.</div></div><div vhs_title=\"prepend_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prepend_text: OPTIONAL, adds text before all prompts.</div></div><div vhs_title=\"append_text\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">append_text: OPTIONAL, adds text after all prompts.</div></div><div vhs_title=\"tensor_interp\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">tensor_interp: Selects method of interpolating prompt conds - defaults to lerp.</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div><div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"CONDITIONING\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">CONDITIONING: Encoded prompts.</div></div><div vhs_title=\"LATENT\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">LATENT: Unmodified input latents; can be used as pipe, or can be ignored.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ValueScheduling": {"input": {"required": {"values": ["STRING", {"multiline": true, "default": ""}]}, "optional": {"print_schedule": ["BOOLEAN", {"default": false}], "max_length": ["INT", {"default": 0, "min": 0, "max": 9007199254740991, "step": 1}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["values"], "optional": ["print_schedule", "max_length"], "hidden": ["autosize"]}, "output": ["FLOAT", "FLOATS", "INT", "INTS"], "output_is_list": [false, false, false, false], "output_name": ["FLOAT", "FLOATS", "INT", "INTS"], "name": "ADE_ValueScheduling", "display_name": "Value Scheduling \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Create a list of values with automatic interpolation.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": float/int_value, ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = float/int_value, ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The values can be written without any special formatting.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": 1.0,</div><div>\"16\": 1.3</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = 1.0,</div><div>16 = 1.3</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"values\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values: Write your values here.</div></div><div vhs_title=\"max_length\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">max_length: Used to select the intended length of schedule. If set to 0, will use the largest index in the schedule as max_length, but will disable relative indexes (negative and decimal).</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ValueSchedulingLatents": {"input": {"required": {"values": ["STRING", {"multiline": true, "default": ""}], "latent": ["LATENT"]}, "optional": {"print_schedule": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["values", "latent"], "optional": ["print_schedule"], "hidden": ["autosize"]}, "output": ["FLOAT", "FLOATS", "INT", "INTS"], "output_is_list": [false, false, false, false], "output_name": ["FLOAT", "FLOATS", "INT", "INTS"], "name": "ADE_ValueSchedulingLatents", "display_name": "Value Scheduling [Latents] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Create a list of values with automatic interpolation, its length matching passed-in latent count.</div></div><div><div vhs_title=\"Format\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Format: <div>Scheduling supports two formats: JSON and pythonic.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"idx\": float/int_value, ...</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>idx = float/int_value, ...</div></div></div></div><div>The idx is the index of the frame - first frame is 0, last frame is max_frames-1. An idx may be the following:</div><div><div vhs_title=\"allowed idxs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">allowed idxs: <div vhs_title=\"single\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">single: A positive integer (e.g. 0, 2) schedules value for frame. A negative integer (e.g. -1, -5) schedules value for frame from the end (-1 would be the last frame). A decimal (e.g. 0.5, 1.0) selects frame based relative location in whole schedule (0.5 would be halfway, 1.0 would be last frame).</div></div><div vhs_title=\"range\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">range: Using rules above, single:single chooses uninterpolated prompts from start idx (included) to end idx (excluded). Examples -> 0:12, 0:-5, 2:0.5</div></div><div vhs_title=\"hold\" style=\"display: flex; font-size: 1em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">hold: Putting a colon after a single idx stops interpolation until the next provided index. Examples -> 0:, 0.5:, 16: </div></div></div></div></div><div>The values can be written without any special formatting.</div><div><div vhs_title=\"JSON\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">JSON: <div>\"0\": 1.0,</div><div>\"16\": 1.3</div></div></div><div vhs_title=\"pythonic\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">pythonic: <div>0 = 1.0,</div><div>16 = 1.3</div></div></div></div></div></div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"values\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">values: Write your values here.</div></div><div vhs_title=\"latent\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">latent: Used to get the amount of frames (max_length) to use for scheduling.</div></div><div vhs_title=\"print_schedule\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">print_schedule: When True, prints output values for each frame.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ConditionExtraction": {"input": {"required": {"conditioning": ["CONDITIONING"], "index": ["INT", {"default": 0, "min": 0, "step": 1}]}}, "input_order": {"required": ["conditioning", "index"]}, "output": ["CONDITIONING"], "output_is_list": [false], "output_name": ["CONDITIONING"], "name": "ADE_ConditionExtraction", "display_name": "Condition Step Extraction \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Extract a single conditioning step from a schedule of prompts.</div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"conditioning\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">conditioning: Encoded prompts. The output of a Prompt Scheduling node.</div></div><div vhs_title=\"index\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">index: The index to extract. Must be within the range [0,N] where N is the length of scheduled prompts.</div></div></div></div></div><div><div vhs_title=\"Outputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse VHS_precollapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Outputs: <div vhs_title=\"CONDITIONING\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">CONDITIONING: Encoded prompts.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ValuesReplace": {"input": {"required": {"value_key": ["STRING", {"default": ""}], "floats": ["FLOATS"]}, "optional": {"prev_replace": ["VALUES_REPLACE"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["value_key", "floats"], "optional": ["prev_replace"], "hidden": ["autosize"]}, "output": ["VALUES_REPLACE"], "output_is_list": [false], "output_name": ["VALUES_REPLACE"], "name": "ADE_ValuesReplace", "display_name": "Add Values Replace \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Add a values schedule bound to a key to be used in Prompt Scheduling node.</div></div><div><div vhs_title=\"Inputs\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">Inputs: <div vhs_title=\"value_key\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">value_key: Key to use for value schedule in Prompt Scheduling node. Can only contain a-z, A-Z, 0-9, and _ characters. In Prompt Scheduling, keys can be referred to as `some_key`, where the key is surrounded by ` characters.</div></div><div vhs_title=\"floats\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">floats: List of floats, likely outputted by a Value Scheduling node.</div></div><div vhs_title=\"prev_replace\" style=\"display: flex; font-size: 0.8em\" class=\"VHS_collapse\"><div style=\"color: #AAA; height: 1.5em;\">[<span style=\"font-family: monospace\">-</span>]</div><div style=\"width: 100%\">prev_replace: OPTIONAL, other values_replace can be chained.</div></div></div></div></div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_FloatToFloats": {"input": {"required": {"FLOAT": ["FLOAT", {"default": 39, "forceInput": true}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["FLOAT"], "hidden": ["autosize"]}, "output": ["FLOATS"], "output_is_list": [false], "output_name": ["FLOATS"], "name": "ADE_FloatToFloats", "display_name": "Float to Floats \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/scheduling", "output_node": false}, "ADE_ADBlockCombo": {"input": {"required": {}, "optional": {"effect": ["MULTIVAL"], "scale": ["MULTIVAL"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect", "scale"], "hidden": ["autosize"]}, "output": ["AD_BLOCK"], "output_is_list": [false], "output_name": ["AD_BLOCK"], "name": "ADE_ADBlockCombo", "display_name": "AD Block \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_ADBlockIndiv": {"input": {"required": {}, "optional": {"effect": ["MULTIVAL"], "scale_0": ["MULTIVAL"], "scale_1": ["MULTIVAL"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect", "scale_0", "scale_1", "autosize"]}, "output": ["AD_BLOCK"], "output_is_list": [false], "output_name": ["AD_BLOCK"], "name": "ADE_ADBlockIndiv", "display_name": "AD Block+ \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlockHighLevel": {"input": {"required": {}, "optional": {"down": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down", "mid", "up", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlockHighLevel", "display_name": "AD Per Block \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SD15_MidLevel": {"input": {"required": {}, "optional": {"down_0": ["AD_BLOCK"], "down_1": ["AD_BLOCK"], "down_2": ["AD_BLOCK"], "down_3": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0": ["AD_BLOCK"], "up_1": ["AD_BLOCK"], "up_2": ["AD_BLOCK"], "up_3": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0", "down_1", "down_2", "down_3", "mid", "up_0", "up_1", "up_2", "up_3", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SD15_MidLevel", "display_name": "AD Per Block+ (SD1.5) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SD15_LowLevel": {"input": {"required": {}, "optional": {"down_0__0": ["AD_BLOCK"], "down_0__1": ["AD_BLOCK"], "down_1__0": ["AD_BLOCK"], "down_1__1": ["AD_BLOCK"], "down_2__0": ["AD_BLOCK"], "down_2__1": ["AD_BLOCK"], "down_3__0": ["AD_BLOCK"], "down_3__1": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0__0": ["AD_BLOCK"], "up_0__1": ["AD_BLOCK"], "up_0__2": ["AD_BLOCK"], "up_1__0": ["AD_BLOCK"], "up_1__1": ["AD_BLOCK"], "up_1__2": ["AD_BLOCK"], "up_2__0": ["AD_BLOCK"], "up_2__1": ["AD_BLOCK"], "up_2__2": ["AD_BLOCK"], "up_3__0": ["AD_BLOCK"], "up_3__1": ["AD_BLOCK"], "up_3__2": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0__0", "down_0__1", "down_1__0", "down_1__1", "down_2__0", "down_2__1", "down_3__0", "down_3__1", "mid", "up_0__0", "up_0__1", "up_0__2", "up_1__0", "up_1__1", "up_1__2", "up_2__0", "up_2__1", "up_2__2", "up_3__0", "up_3__1", "up_3__2", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SD15_LowLevel", "display_name": "AD Per Block++ (SD1.5) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SD15_FromFloats": {"input": {"required": {}, "optional": {"effect_21_floats": ["FLOATS"], "scale_21_floats": ["FLOATS"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect_21_floats", "scale_21_floats", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SD15_FromFloats", "display_name": "AD Per Block Floats (SD1.5) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Use Floats from Value Schedules to select SD1.5 effect/scale values for blocks.</div></div><div>SD1.5 Motion Modules contain 21 blocks:</div><div>idx 0 - start of down blocks (down_0__0)</div><div>idx 7 - end of down blocks   (down_3__1)</div><div>idx 8 - mid block            (mid)</div><div>idx 9 - start of up blocks   (up_0__0)</div><div>idx 20 - end of up blocks    (up_3__2)</div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SDXL_MidLevel": {"input": {"required": {}, "optional": {"down_0": ["AD_BLOCK"], "down_1": ["AD_BLOCK"], "down_2": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0": ["AD_BLOCK"], "up_1": ["AD_BLOCK"], "up_2": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0", "down_1", "down_2", "mid", "up_0", "up_1", "up_2", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SDXL_MidLevel", "display_name": "AD Per Block+ (SDXL) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SDXL_LowLevel": {"input": {"required": {}, "optional": {"down_0__0": ["AD_BLOCK"], "down_0__1": ["AD_BLOCK"], "down_1__0": ["AD_BLOCK"], "down_1__1": ["AD_BLOCK"], "down_2__0": ["AD_BLOCK"], "down_2__1": ["AD_BLOCK"], "mid": ["AD_BLOCK"], "up_0__0": ["AD_BLOCK"], "up_0__1": ["AD_BLOCK"], "up_0__2": ["AD_BLOCK"], "up_1__0": ["AD_BLOCK"], "up_1__1": ["AD_BLOCK"], "up_1__2": ["AD_BLOCK"], "up_2__0": ["AD_BLOCK"], "up_2__1": ["AD_BLOCK"], "up_2__2": ["AD_BLOCK"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["down_0__0", "down_0__1", "down_1__0", "down_1__1", "down_2__0", "down_2__1", "mid", "up_0__0", "up_0__1", "up_0__2", "up_1__0", "up_1__1", "up_1__2", "up_2__0", "up_2__1", "up_2__2", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SDXL_LowLevel", "display_name": "AD Per Block++ (SDXL) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_PerBlock_SDXL_FromFloats": {"input": {"required": {}, "optional": {"effect_16_floats": ["FLOATS"], "scale_16_floats": ["FLOATS"], "autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": [], "optional": ["effect_16_floats", "scale_16_floats", "autosize"]}, "output": ["PER_BLOCK"], "output_is_list": [false], "output_name": ["PER_BLOCK"], "name": "ADE_PerBlock_SDXL_FromFloats", "display_name": "AD Per Block Floats (SDXL) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "<div><div id=VHS_shortdesc style=\"font-size: .8em\">Use Floats from Value Schedules to select SDXL effect/scale values for blocks.</div></div><div>SDXL Motion Modules contain 16 blocks:</div><div>idx 0 - start of down blocks (down_0__0)</div><div>idx 5 - end of down blocks   (down_2__1)</div><div>idx 6 - mid block            (mid)</div><div>idx 7 - start of up blocks   (up_0__0)</div><div>idx 15 - end of up blocks    (up_2__2)</div>", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/per block", "output_node": false}, "ADE_AnimateDiffUnload": {"input": {"required": {"model": ["MODEL"]}}, "input_order": {"required": ["model"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_AnimateDiffUnload", "display_name": "AnimateDiff Unload \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_EmptyLatentImageLarge": {"input": {"required": {"width": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "height": ["INT", {"default": 512, "min": 64, "max": 16384, "step": 8}], "batch_size": ["INT", {"default": 1, "min": 1, "max": 262144}]}}, "input_order": {"required": ["width", "height", "batch_size"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ADE_EmptyLatentImageLarge", "display_name": "Empty Latent Image (Big Batch) \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "CheckpointLoaderSimpleWithNoiseSelect": {"input": {"required": {"ckpt_name": [["realisticVisionV51_v51VAE.safetensors", "realvisxlV40.safetensors"]], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "use existing"}]}, "optional": {"use_custom_scale_factor": ["BOOLEAN", {"default": false}], "scale_factor": ["FLOAT", {"default": 0.18215, "min": 0.0, "max": 1.0, "step": 1e-05}]}}, "input_order": {"required": ["ckpt_name", "beta_schedule"], "optional": ["use_custom_scale_factor", "scale_factor"]}, "output": ["MODEL", "CLIP", "VAE"], "output_is_list": [false, false, false], "output_name": ["MODEL", "CLIP", "VAE"], "name": "CheckpointLoaderSimpleWithNoiseSelect", "display_name": "Load Checkpoint w/ Noise Select \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_PerturbedAttentionGuidanceMultival": {"input": {"required": {"model": ["MODEL"], "scale_multival": ["MULTIVAL"]}}, "input_order": {"required": ["model", "scale_multival"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_PerturbedAttentionGuidanceMultival", "display_name": "PerturbedAttnGuide [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_RescaleCFGMultival": {"input": {"required": {"model": ["MODEL"], "mult_multival": ["MULTIVAL"]}}, "input_order": {"required": ["model", "mult_multival"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_RescaleCFGMultival", "display_name": "RescaleCFG [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/extras", "output_node": false}, "ADE_AnimateDiffLoaderGen1": {"input": {"required": {"model": ["MODEL"], "model_name": [["mm_sd_v15_v2.ckpt"]], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "autoselect"}]}, "optional": {"context_options": ["CONTEXT_OPTIONS"], "motion_lora": ["MOTION_LORA"], "ad_settings": ["AD_SETTINGS"], "ad_keyframes": ["AD_KEYFRAMES"], "sample_settings": ["SAMPLE_SETTINGS"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "per_block": ["PER_BLOCK"]}}, "input_order": {"required": ["model", "model_name", "beta_schedule"], "optional": ["context_options", "motion_lora", "ad_settings", "ad_keyframes", "sample_settings", "scale_multival", "effect_multival", "per_block"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_AnimateDiffLoaderGen1", "display_name": "AnimateDiff Loader \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2460 Gen1 nodes \u2460", "output_node": false}, "ADE_UseEvolvedSampling": {"input": {"required": {"model": ["MODEL"], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "autoselect"}]}, "optional": {"m_models": ["M_MODELS"], "context_options": ["CONTEXT_OPTIONS"], "sample_settings": ["SAMPLE_SETTINGS"]}}, "input_order": {"required": ["model", "beta_schedule"], "optional": ["m_models", "context_options", "sample_settings"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_UseEvolvedSampling", "display_name": "Use Evolved Sampling \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_ApplyAnimateDiffModelSimple": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model"], "optional": ["motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModelSimple", "display_name": "Apply AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_ApplyAnimateDiffModel": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model", "start_percent", "end_percent"], "optional": ["motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "prev_m_models", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModel", "display_name": "Apply AnimateDiff Model (Adv.) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_LoadAnimateDiffModel": {"input": {"required": {"model_name": [["mm_sd_v15_v2.ckpt"]]}, "optional": {"ad_settings": ["AD_SETTINGS"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 50}]}}, "input_order": {"required": ["model_name"], "optional": ["ad_settings"], "hidden": ["autosize"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_LoadAnimateDiffModel", "display_name": "Load AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461", "output_node": false}, "ADE_ApplyAnimateLCMI2VModel": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "ref_latent": ["LATENT"], "ref_drift": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 10.0, "step": 0.001}], "apply_ref_when_disabled": ["BOOLEAN", {"default": false}], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model", "ref_latent", "ref_drift", "apply_ref_when_disabled", "start_percent", "end_percent"], "optional": ["motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "prev_m_models", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateLCMI2VModel", "display_name": "Apply AnimateLCM-I2V Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V", "output_node": false}, "ADE_LoadAnimateLCMI2VModel": {"input": {"required": {"model_name": [["mm_sd_v15_v2.ckpt"]]}, "optional": {"ad_settings": ["AD_SETTINGS"]}}, "input_order": {"required": ["model_name"], "optional": ["ad_settings"]}, "output": ["MOTION_MODEL_ADE", "MOTION_MODEL_ADE"], "output_is_list": [false, false], "output_name": ["MOTION_MODEL", "encoder_only"], "name": "ADE_LoadAnimateLCMI2VModel", "display_name": "Load AnimateLCM-I2V Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V", "output_node": false}, "ADE_UpscaleAndVAEEncode": {"input": {"required": {"image": ["IMAGE"], "vae": ["VAE"], "latent_size": ["LATENT"], "scale_method": [["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]], "crop": [["disabled", "center"], {"default": "center"}]}}, "input_order": {"required": ["image", "vae", "latent_size", "scale_method", "crop"]}, "output": ["LATENT"], "output_is_list": [false], "output_name": ["LATENT"], "name": "ADE_UpscaleAndVAEEncode", "display_name": "Scale Ref Image and VAE Encode \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V", "output_node": false}, "ADE_InjectI2VIntoAnimateDiffModel": {"input": {"required": {"model_name": [["mm_sd_v15_v2.ckpt"]], "motion_model": ["MOTION_MODEL_ADE"]}, "optional": {"ad_settings": ["AD_SETTINGS"], "deprecation_warning": ["ADEWARN", {"text": "Experimental. Don't expect to work.", "warn_type": "experimental", "color": "#CFC"}]}}, "input_order": {"required": ["model_name", "motion_model"], "optional": ["ad_settings", "deprecation_warning"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_InjectI2VIntoAnimateDiffModel", "display_name": "\ud83e\uddeaInject I2V into AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/AnimateLCM-I2V/\ud83e\uddeaexperimental", "output_node": false}, "ADE_ApplyAnimateDiffModelWithCameraCtrl": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "cameractrl_poses": ["CAMERACTRL_POSES"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "cameractrl_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}}, "input_order": {"required": ["motion_model", "cameractrl_poses", "start_percent", "end_percent"], "optional": ["motion_lora", "scale_multival", "effect_multival", "cameractrl_multival", "ad_keyframes", "prev_m_models", "per_block"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModelWithCameraCtrl", "display_name": "Apply AnimateDiff+CameraCtrl Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl", "output_node": false}, "ADE_LoadAnimateDiffModelWithCameraCtrl": {"input": {"required": {"model_name": [["mm_sd_v15_v2.ckpt"]], "camera_ctrl": [["mm_sd_v15_v2.ckpt"]]}, "optional": {"ad_settings": ["AD_SETTINGS"]}}, "input_order": {"required": ["model_name", "camera_ctrl"], "optional": ["ad_settings"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_LoadAnimateDiffModelWithCameraCtrl", "display_name": "Load AnimateDiff+CameraCtrl Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl", "output_node": false}, "ADE_CameraCtrlAnimateDiffKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_ad_keyframes": ["AD_KEYFRAMES"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "cameractrl_multival": ["MULTIVAL"], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_ad_keyframes", "scale_multival", "effect_multival", "cameractrl_multival", "inherit_missing", "guarantee_steps"], "hidden": ["autosize"]}, "output": ["AD_KEYFRAMES"], "output_is_list": [false], "output_name": ["AD_KEYFRAMES"], "name": "ADE_CameraCtrlAnimateDiffKeyframe", "display_name": "AnimateDiff+CameraCtrl Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl", "output_node": false}, "ADE_LoadCameraPoses": {"input": {"required": {"pose_filename": [[]]}}, "input_order": {"required": ["pose_filename"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_LoadCameraPoses", "display_name": "Load CameraCtrl Poses (File) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_LoadCameraPosesFromPath": {"input": {"optional": {"file_path": ["STRING", {"default": "X://path/to/pose_file.txt"}]}}, "input_order": {"optional": ["file_path"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_LoadCameraPosesFromPath", "display_name": "Load CameraCtrl Poses (Path) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraPoseBasic": {"input": {"required": {"motion_type": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "speed": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "frame_length": ["INT", {"default": 16}]}, "optional": {"prev_poses": ["CAMERACTRL_POSES"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_type", "speed", "frame_length"], "optional": ["prev_poses"], "hidden": ["autosize"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraPoseBasic", "display_name": "Create CameraCtrl Poses \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraPoseCombo": {"input": {"required": {"motion_type1": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type2": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type3": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type4": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type5": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "motion_type6": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "speed": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "frame_length": ["INT", {"default": 16}]}, "optional": {"prev_poses": ["CAMERACTRL_POSES"]}}, "input_order": {"required": ["motion_type1", "motion_type2", "motion_type3", "motion_type4", "motion_type5", "motion_type6", "speed", "frame_length"], "optional": ["prev_poses"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraPoseCombo", "display_name": "Create CameraCtrl Poses (Combo) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraPoseAdvanced": {"input": {"required": {"motion_type1": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength1": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type2": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength2": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type3": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength3": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type4": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength4": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type5": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength5": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "motion_type6": [["Static", "Pan Up", "Pan Down", "Pan Left", "Pan Right", "Zoom In", "Zoom Out", "Roll Clockwise", "Roll Anticlockwise", "Tilt Down", "Tilt Up", "Tilt Left", "Tilt Right"]], "strength6": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.01}], "speed": ["FLOAT", {"default": 1.0, "min": -100.0, "max": 100.0, "step": 0.01}], "frame_length": ["INT", {"default": 16}]}, "optional": {"prev_poses": ["CAMERACTRL_POSES"]}}, "input_order": {"required": ["motion_type1", "strength1", "motion_type2", "strength2", "motion_type3", "strength3", "motion_type4", "strength4", "motion_type5", "strength5", "motion_type6", "strength6", "speed", "frame_length"], "optional": ["prev_poses"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraPoseAdvanced", "display_name": "Create CameraCtrl Poses (Adv.) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_CameraManualPoseAppend": {"input": {"required": {"poses_first": ["CAMERACTRL_POSES"], "poses_last": ["CAMERACTRL_POSES"]}}, "input_order": {"required": ["poses_first", "poses_last"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_CameraManualPoseAppend", "display_name": "Manual Append CameraCtrl Poses \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_ReplaceCameraParameters": {"input": {"required": {"poses": ["CAMERACTRL_POSES"], "fx": ["FLOAT", {"default": 0.474812461, "min": 0, "max": 1, "step": 1e-09}], "fy": ["FLOAT", {"default": 0.844111024, "min": 0, "max": 1, "step": 1e-09}], "cx": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}], "cy": ["FLOAT", {"default": 0.5, "min": 0, "max": 1, "step": 0.01}]}}, "input_order": {"required": ["poses", "fx", "fy", "cx", "cy"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_ReplaceCameraParameters", "display_name": "Replace Camera Parameters \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_ReplaceOriginalPoseAspectRatio": {"input": {"required": {"poses": ["CAMERACTRL_POSES"], "orig_pose_width": ["INT", {"default": 1280, "min": 1, "max": 9007199254740991}], "orig_pose_height": ["INT", {"default": 720, "min": 1, "max": 9007199254740991}]}}, "input_order": {"required": ["poses", "orig_pose_width", "orig_pose_height"]}, "output": ["CAMERACTRL_POSES"], "output_is_list": [false], "output_name": ["CAMERACTRL_POSES"], "name": "ADE_ReplaceOriginalPoseAspectRatio", "display_name": "Replace Orig. Pose Aspect Ratio \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/CameraCtrl/poses", "output_node": false}, "ADE_ApplyAnimateDiffModelWithPIA": {"input": {"required": {"motion_model": ["MOTION_MODEL_ADE"], "image": ["IMAGE"], "vae": ["VAE"], "start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}], "end_percent": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"pia_input": ["PIA_INPUT"], "motion_lora": ["MOTION_LORA"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "ad_keyframes": ["AD_KEYFRAMES"], "prev_m_models": ["M_MODELS"], "per_block": ["PER_BLOCK"]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["motion_model", "image", "vae", "start_percent", "end_percent"], "optional": ["pia_input", "motion_lora", "scale_multival", "effect_multival", "ad_keyframes", "prev_m_models", "per_block"], "hidden": ["autosize"]}, "output": ["M_MODELS"], "output_is_list": [false], "output_name": ["M_MODELS"], "name": "ADE_ApplyAnimateDiffModelWithPIA", "display_name": "Apply AnimateDiff-PIA Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_InputPIA_Multival": {"input": {"required": {"multival": ["MULTIVAL"]}}, "input_order": {"required": ["multival"]}, "output": ["PIA_INPUT"], "output_is_list": [false], "output_name": ["PIA_INPUT"], "name": "ADE_InputPIA_Multival", "display_name": "PIA Input [Multival] \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_InputPIA_PaperPresets": {"input": {"required": {"preset": [["Animation (Small Motion)", "Animation (Medium Motion)", "Animation (Large Motion)", "Loop (Small Motion)", "Loop (Medium Motion)", "Loop (Large Motion)", "Style Transfer (Small Motion)", "Style Transfer (Medium Motion)", "Style Transfer (Large Motion)"]], "batch_index": ["INT", {"default": 0, "min": -9007199254740991, "max": 9007199254740991, "step": 1}]}, "optional": {"mult_multival": ["MULTIVAL"], "print_values": ["BOOLEAN", {"default": false}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["preset", "batch_index"], "optional": ["mult_multival", "print_values"], "hidden": ["autosize"]}, "output": ["PIA_INPUT"], "output_is_list": [false], "output_name": ["PIA_INPUT"], "name": "ADE_InputPIA_PaperPresets", "display_name": "PIA Input [Paper Presets] \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_PIA_AnimateDiffKeyframe": {"input": {"required": {"start_percent": ["FLOAT", {"default": 0.0, "min": 0.0, "max": 1.0, "step": 0.001}]}, "optional": {"prev_ad_keyframes": ["AD_KEYFRAMES"], "scale_multival": ["MULTIVAL"], "effect_multival": ["MULTIVAL"], "pia_input": ["PIA_INPUT"], "inherit_missing": ["BOOLEAN", {"default": true}], "guarantee_steps": ["INT", {"default": 1, "min": 0, "max": 9007199254740991}]}, "hidden": {"autosize": ["ADEAUTOSIZE", {"padding": 0}]}}, "input_order": {"required": ["start_percent"], "optional": ["prev_ad_keyframes", "scale_multival", "effect_multival", "pia_input", "inherit_missing", "guarantee_steps"], "hidden": ["autosize"]}, "output": ["AD_KEYFRAMES"], "output_is_list": [false], "output_name": ["AD_KEYFRAMES"], "name": "ADE_PIA_AnimateDiffKeyframe", "display_name": "AnimateDiff-PIA Keyframe \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA", "output_node": false}, "ADE_InjectPIAIntoAnimateDiffModel": {"input": {"required": {"model_name": [["mm_sd_v15_v2.ckpt"]], "motion_model": ["MOTION_MODEL_ADE"]}, "optional": {"ad_settings": ["AD_SETTINGS"], "deprecation_warning": ["ADEWARN", {"text": "Experimental. Don't expect to work.", "warn_type": "experimental", "color": "#CFC"}]}}, "input_order": {"required": ["model_name", "motion_model"], "optional": ["ad_settings", "deprecation_warning"]}, "output": ["MOTION_MODEL_ADE"], "output_is_list": [false], "output_name": ["MOTION_MODEL"], "name": "ADE_InjectPIAIntoAnimateDiffModel", "display_name": "\ud83e\uddeaInject PIA into AnimateDiff Model \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2461", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2461 Gen2 nodes \u2461/PIA/\ud83e\uddeaexperimental", "output_node": false}, "ADE_AnimateDiffLoaderWithContext": {"input": {"required": {"model": ["MODEL"], "model_name": [["mm_sd_v15_v2.ckpt"]], "beta_schedule": [["autoselect", "use existing", "sqrt_linear (AnimateDiff)", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"], {"default": "autoselect"}]}, "optional": {"context_options": ["CONTEXT_OPTIONS"], "motion_lora": ["MOTION_LORA"], "ad_settings": ["AD_SETTINGS"], "sample_settings": ["SAMPLE_SETTINGS"], "motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "apply_v2_models_properly": ["BOOLEAN", {"default": true}], "ad_keyframes": ["AD_KEYFRAMES"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated; use AnimateDiff Loader instead."}]}}, "input_order": {"required": ["model", "model_name", "beta_schedule"], "optional": ["context_options", "motion_lora", "ad_settings", "sample_settings", "motion_scale", "apply_v2_models_properly", "ad_keyframes", "deprecation_warning"]}, "output": ["MODEL"], "output_is_list": [false], "output_name": ["MODEL"], "name": "ADE_AnimateDiffLoaderWithContext", "display_name": "AnimateDiff Loader [Legacy] \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "Animate Diff \ud83c\udfad\ud83c\udd50\ud83c\udd53/\u2460 Gen1 nodes \u2460", "output_node": false, "deprecated": true}, "AnimateDiffLoaderV1": {"input": {"required": {"model": ["MODEL"], "latents": ["LATENT"], "model_name": [["mm_sd_v15_v2.ckpt"]], "unlimited_area_hack": ["BOOLEAN", {"default": false}], "beta_schedule": [["sqrt_linear (AnimateDiff)", "use existing", "autoselect", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["model", "latents", "model_name", "unlimited_area_hack", "beta_schedule"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "LATENT"], "output_is_list": [false, false], "output_name": ["MODEL", "LATENT"], "name": "AnimateDiffLoaderV1", "display_name": "\ud83d\udeabAnimateDiff Loader [DEPRECATED] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffLoaderV1Advanced": {"input": {"required": {"model": ["MODEL"], "latents": ["LATENT"], "model_name": [["mm_sd_v15_v2.ckpt"]], "unlimited_area_hack": ["BOOLEAN", {"default": false}], "context_length": ["INT", {"default": 16, "min": 0, "max": 1000}], "context_stride": ["INT", {"default": 1, "min": 1, "max": 1000}], "context_overlap": ["INT", {"default": 4, "min": 0, "max": 1000}], "context_schedule": [["uniform"]], "closed_loop": ["BOOLEAN", {"default": false}], "beta_schedule": [["sqrt_linear (AnimateDiff)", "use existing", "autoselect", "linear (AnimateDiff-SDXL)", "linear (HotshotXL/default)", "avg(sqrt_linear,linear)", "lcm avg(sqrt_linear,linear)", "lcm", "lcm[100_ots]", "lcm >> sqrt_linear", "sqrt", "cosine", "squaredcos_cap_v2"]]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["model", "latents", "model_name", "unlimited_area_hack", "context_length", "context_stride", "context_overlap", "context_schedule", "closed_loop", "beta_schedule"], "optional": ["deprecation_warning"]}, "output": ["MODEL", "LATENT"], "output_is_list": [false, false], "output_name": ["MODEL", "LATENT"], "name": "ADE_AnimateDiffLoaderV1Advanced", "display_name": "\ud83d\udeabAnimateDiff Loader (Advanced) [DEPRECATED] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffCombine": {"input": {"required": {"images": ["IMAGE"], "frame_rate": ["INT", {"default": 8, "min": 1, "max": 24, "step": 1}], "loop_count": ["INT", {"default": 0, "min": 0, "max": 100, "step": 1}], "filename_prefix": ["STRING", {"default": "AnimateDiff"}], "format": [["image/gif", "image/webp", "video/av1-webm", "video/h264-mp4", "video/h265-mp4", "video/webm"]], "pingpong": ["BOOLEAN", {"default": false}], "save_image": ["BOOLEAN", {"default": true}]}, "optional": {"deprecation_warning": ["ADEWARN", {"text": "Deprecated. Use VHS Video Combine"}]}, "hidden": {"prompt": "PROMPT", "extra_pnginfo": "EXTRA_PNGINFO"}}, "input_order": {"required": ["images", "frame_rate", "loop_count", "filename_prefix", "format", "pingpong", "save_image"], "optional": ["deprecation_warning"], "hidden": ["prompt", "extra_pnginfo"]}, "output": ["GIF"], "output_is_list": [false], "output_name": ["GIF"], "name": "ADE_AnimateDiffCombine", "display_name": "\ud83d\udeabAnimateDiff Combine [DEPRECATED, Use Video Combine (VHS) Instead!] \ud83c\udfad\ud83c\udd50\ud83c\udd53", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": true, "deprecated": true}, "ADE_AnimateDiffModelSettings_Release": {"input": {"required": {"min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}]}, "optional": {"mask_motion_scale": ["MASK"], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["min_motion_scale", "max_motion_scale"], "optional": ["mask_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettings_Release", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffModelSettingsSimple": {"input": {"required": {"motion_pe_stretch": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"mask_motion_scale": ["MASK"], "min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["motion_pe_stretch"], "optional": ["mask_motion_scale", "min_motion_scale", "max_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettingsSimple", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings (Simple) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffModelSettings": {"input": {"required": {"pe_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "other_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "motion_pe_stretch": ["INT", {"default": 0, "min": 0, "step": 1}], "cap_initial_pe_length": ["INT", {"default": 0, "min": 0, "step": 1}], "interpolate_pe_to_length": ["INT", {"default": 0, "min": 0, "step": 1}], "initial_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "final_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"mask_motion_scale": ["MASK"], "min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["pe_strength", "attn_strength", "other_strength", "motion_pe_stretch", "cap_initial_pe_length", "interpolate_pe_to_length", "initial_pe_idx_offset", "final_pe_idx_offset"], "optional": ["mask_motion_scale", "min_motion_scale", "max_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettings", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings (Advanced) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}, "ADE_AnimateDiffModelSettingsAdvancedAttnStrengths": {"input": {"required": {"pe_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_q_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_k_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_v_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_out_weight_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "attn_out_bias_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "other_strength": ["FLOAT", {"default": 1.0, "min": 0.0, "max": 10.0, "step": 0.0001}], "motion_pe_stretch": ["INT", {"default": 0, "min": 0, "step": 1}], "cap_initial_pe_length": ["INT", {"default": 0, "min": 0, "step": 1}], "interpolate_pe_to_length": ["INT", {"default": 0, "min": 0, "step": 1}], "initial_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}], "final_pe_idx_offset": ["INT", {"default": 0, "min": 0, "step": 1}]}, "optional": {"mask_motion_scale": ["MASK"], "min_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "max_motion_scale": ["FLOAT", {"default": 1.0, "min": 0.0, "step": 0.001}], "deprecation_warning": ["ADEWARN", {"text": "Deprecated"}]}}, "input_order": {"required": ["pe_strength", "attn_strength", "attn_q_strength", "attn_k_strength", "attn_v_strength", "attn_out_weight_strength", "attn_out_bias_strength", "other_strength", "motion_pe_stretch", "cap_initial_pe_length", "interpolate_pe_to_length", "initial_pe_idx_offset", "final_pe_idx_offset"], "optional": ["mask_motion_scale", "min_motion_scale", "max_motion_scale", "deprecation_warning"]}, "output": ["AD_SETTINGS"], "output_is_list": [false], "output_name": ["AD_SETTINGS"], "name": "ADE_AnimateDiffModelSettingsAdvancedAttnStrengths", "display_name": "\ud83d\udeab[DEPR] Motion Model Settings (Adv. Attn) \ud83c\udfad\ud83c\udd50\ud83c\udd53\u2460", "description": "", "python_module": "custom_nodes.ComfyUI-AnimateDiff-Evolved", "category": "", "output_node": false, "deprecated": true}}
